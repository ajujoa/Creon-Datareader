import os
import sqlite3
from datetime import datetime
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")
import time
from pathlib import Path
import json
### TA íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•œ ë³¼ë¦°ì ¸ ë°´ë“œ ê³„ì‚° í•¨ìˆ˜
import ta
#from ta.volatility import BollingerBands
#from ta.Trend import EMAIndicator
#from ta import add_all_ta_features
#from ta.Trend import ADXIndicator
from pykrx import stock
from exchange_calendars import get_calendar
import multiprocessing
from concurrent.futures import ProcessPoolExecutor
from functools import partial
from tqdm import tqdm

import matplotlib.pyplot as plt


# í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
current_datetime = datetime.now()
formatted_date = current_datetime.strftime("%m%d-%H%M")
excel_filename = formatted_date + ".xlsx"


total_result_df_all = pd.DataFrame()
total_result_df_all.name = 'total_result_df_all'
total_result_df = pd.DataFrame()
total_result_df.name = 'total_result_df'

#ì¼ë´‰ ë“± ë°ì´í„° ë¶ˆëŸ¬ì˜¬ ê¸°ì¤€ ë‚ ì§œ.
krx_calendar = get_calendar("XKRX")

############################################################


# ì´ˆê¸° ì„¤ì •
Total_result2 = pd.DataFrame(columns=['Stock Code', 'Plus Count', 'Minus Count', 'Total Rows', 'Total Profit'])
Total_result3 = pd.DataFrame(columns=['date', 'table_name', 'buy_price', 'sell_price', 'result', 'profit'])
tables_count = 0

# ì „ì—­ ë³€ìˆ˜ë¡œ í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì„¤ì •
MAX_WORKERS = 10  # ê¸°ë³¸ê°’ ì„¤ì •
CHUNK_SIZE = 20  # í•œ ë²ˆì— ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜

def save_results(results, folder_path, condition_set=1):
    """
    ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ (ìœ íš¨í•œ ê²°ê³¼ë§Œ ì €ì¥)
    
    :param results: ì €ì¥í•  ê²°ê³¼ ë°ì´í„°
    :param folder_path: ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ê²½ë¡œ
    :param condition_set: ì‚¬ìš©ëœ ì¡°ê±´ ì„¸íŠ¸ ë²ˆí˜¸
    :return: ì €ì¥ëœ íŒŒì¼ì˜ ê²½ë¡œ ë˜ëŠ” None (ì €ì¥í•  ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°)
    """
    # valid_datesê°€ ìˆëŠ” ê²°ê³¼ë§Œ í•„í„°ë§
    valid_results = [result for result in results if result.get('valid_dates')]
    
    # ì €ì¥í•  ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ íŒŒì¼ì„ ì €ì¥í•˜ì§€ ì•ŠìŒ
    if not valid_results:
        print("ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë‚ ì§œê°€ ë°œê²¬ëœ ì¢…ëª©ì´ ì—†ì–´ íŒŒì¼ì„ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    folder_name = folder_path.name
    
    # ê²°ê³¼ë¥¼ ì €ì¥í•  results í´ë” ìƒì„±
    result_dir = folder_path / 'results'
    result_dir.mkdir(exist_ok=True)
    
    # ì¡°ê±´ ì„¸íŠ¸ ì´ë¦„ ë§¤í•‘
    condition_names = {
        1: "ê¸°ì¡´ì¡°ê±´",
        2: "ì¶”ê°€1ì¡°ê±´", 
        3: "ì¶”ê°€2ì¡°ê±´"
    }
    condition_name = condition_names.get(condition_set, "ì•Œìˆ˜ì—†ìŒ")
    
    # ë” íš¨ìœ¨ì ì¸ JSON êµ¬ì¡°ë¡œ ë³€í™˜
    efficient_results = {
        "analysis_info": {
            "timestamp": timestamp,
            "folder": folder_name,
            "condition_set": condition_set,
            "condition_name": condition_name,
            "total_stocks_found": len(valid_results),
            "total_valid_dates": sum(len(result.get('valid_dates', [])) for result in valid_results)
        },
        "stocks": {}
    }
    
    # ì¢…ëª©ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì €ì¥
    for result in valid_results:
        code = result.get('code', '')
        if code not in efficient_results["stocks"]:
            efficient_results["stocks"][code] = {
                "dates": result.get('valid_dates', []),
                "file_source": result.get('file_name', ''),
                "processed_time": result.get('processed_time', '')
            }
        else:
            # ê°™ì€ ì¢…ëª©ì´ ì—¬ëŸ¬ ë²ˆ ë‚˜íƒ€ë‚  ê²½ìš° ë‚ ì§œ ë³‘í•© (ì¤‘ë³µ ì œê±°)
            existing_dates = set(efficient_results["stocks"][code]["dates"])
            new_dates = set(result.get('valid_dates', []))
            efficient_results["stocks"][code]["dates"] = sorted(list(existing_dates | new_dates))
    
    result_file = result_dir / f"analysis_result_{folder_name}_{condition_name}_{timestamp}.json"
    
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(efficient_results, f, ensure_ascii=False, indent=2)
    
    print(f"ìœ íš¨í•œ ê²°ê³¼ {len(valid_results)}ê°œ ì¢…ëª©ì„ {result_file.name}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    return result_file

def process_table(code_num, df):
    print(code_num)
    table_name = code_num
    
    # ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜
    daily_df = convert_to_daily(df)
    
    if not daily_df.empty:
        # ì¡°ê±´ ê²€ìƒ‰
        valid_dates = check_conditions(daily_df)
        
        if valid_dates:
            print(f"\n{code_num} ì¢…ëª©ì˜ ì¡°ê±´ ë§Œì¡± ë‚ ì§œ:")
            for date in valid_dates:
                print(date)
    
    return

#ê°œì¥ì¼ ê¸°ì¤€ -Xì¼ êµ¬í•˜ëŠ”ê±°. í…ŒìŠ¤íŠ¸
def delta_days(days):
    
    xkrx_calendar = get_calendar('XKRX')
    
    start_date = datetime.datetime.now()
    end_date = start_date - days * xkrx_calendar.day  # ì£¼ì‹ ê°œì¥ì¼ ê¸°ì¤€ 250ì¼ ì´ì „
    end_date = end_date.strftime("%Y%m%d")
    
    return end_date

### ë¶„ë´‰ ë°ì´í„°ë¥¼ ë” í° ì‹œê°„ ë‹¨ìœ„ë¡œ ë³€í™˜
def resample_candles(df, multiplier):
    """
    ë¶„ë´‰ ë°ì´í„°ë¥¼ ë” í° ì‹œê°„ ë‹¨ìœ„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ë¶ˆì™„ì „í•œ ë´‰(ë°ì´í„°ê°€ ë¶€ì¡±í•œ ì²«/ë§ˆì§€ë§‰ ë´‰)ì€ ì œê±°í•©ë‹ˆë‹¤.
    
    :param df: pandas DataFrame, 'date' ì—´ì´ datetime í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    :param multiplier: ë³€í™˜í•  ì‹œê°„ ë‹¨ìœ„ì˜ ë°°ìˆ˜ (ì˜ˆ: 1ë¶„ë´‰ì—ì„œ 3ë¶„ë´‰ìœ¼ë¡œ ë³€í™˜í•  ë•ŒëŠ” 3)
    :return: ë³€í™˜ëœ DataFrame
    """
    # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ë³µì‚¬
    df_copy = df.copy()
    
    # 'date' ì—´ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì´ë¯¸ ë³€í™˜ë˜ì–´ ìˆì„ ìˆ˜ë„ ìˆìŒ)
    if not pd.api.types.is_datetime64_any_dtype(df_copy['date']):
        df_copy['date'] = pd.to_datetime(df_copy['date'], format='%Y%m%d%H%M')

    # datetimeì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
    df_copy.set_index('date', inplace=True)
    
    # ë°ì´í„° ì •ë ¬ (ì‹œê°„ìˆœ)
    df_copy = df_copy.sort_index()
    
    # ì§€ì •ëœ ì‹œê°„ ë‹¨ìœ„ë¡œ ë°ì´í„° ì¬êµ¬ì„±
    resampled_df = df_copy.resample(f'{multiplier}T').agg({
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    })
    
    # NaN ê°’ì´ ìˆëŠ” í–‰ ì œê±° (ë¶ˆì™„ì „í•œ ë´‰ ì œê±°)
    # open, high, low, close ì¤‘ í•˜ë‚˜ë¼ë„ NaNì´ë©´ í•´ë‹¹ ë´‰ì€ ë¶ˆì™„ì „í•¨
    resampled_df = resampled_df.dropna(subset=['open', 'high', 'low', 'close'])
    
    # ê±°ë˜ëŸ‰ì´ 0ì¸ ë´‰ë„ ì œê±°
    resampled_df = resampled_df[resampled_df['volume'] > 0]
    
    # ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
    resampled_df.reset_index(inplace=True)
    
    print(f"ë¦¬ìƒ˜í”Œë§ ì™„ë£Œ: {len(df)}ë´‰ -> {len(resampled_df)}ë´‰ (ë°°ìˆ˜: {multiplier})")
    
    return resampled_df

### RSI ê³„ì‚° í•¨ìˆ˜
def calculate_rsi(data, period=12):
    delta = data['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()

    rs = gain / loss
    rsi = round(100 - (100 / (1 + rs)), 1)
    return rsi

def TA_bol_band(data, Period=20, num_of_std=2):
    '''
    TA íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•˜ì—¬ ë³¼ë¦°ì ¸ ë°´ë“œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    :param data: pandas DataFrame, 'close' ì—´ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    :param Period: ì´ë™ í‰ê· ì„ ê³„ì‚°í•  ê¸°ê°„.
    :param num_of_std: í‘œì¤€í¸ì°¨ì˜ ë°°ìˆ˜.
    :return: ë³¼ë¦°ì ¸ ë°´ë“œê°€ ì¶”ê°€ëœ DataFrame.
    '''
    middle_band_label = 'BB_M_' + str(Period)
    upper_band_label = 'BB_H_' + str(Period)
    lower_band_label = 'BB_L_' + str(Period)
    Sum_BB_label = 'Sum_BB_' + str(Period)

    # TA íŒ¨í‚¤ì§€ì˜ BollingerBands ê¸°ëŠ¥ì„ ì´ìš©
    indicator_bb = ta.volatility.BollingerBands(close=data['close'], window=Period, window_dev=num_of_std)

    # ë³¼ë¦°ì ¸ ë°´ë“œ ê³„ì‚°
    BB_M = indicator_bb.bollinger_mavg()
    BB_H = indicator_bb.bollinger_hband()
    BB_L = indicator_bb.bollinger_lband()
    #data[middle_band_label] = round(BB_M, 2)
    data[upper_band_label] = round(BB_H, 2)
    data[lower_band_label] = round(BB_L, 2)

    # ë³¼ë¦°ì € ë°´ë“œì™€ ì¢…ê°€ì˜ ë°±ë¶„ìœ¨ ì°¨ì´ ê³„ì‚°
    high_diff_percent = abs((data['close'] - BB_H) / data['close']) * 100
    low_diff_percent = abs((data['close'] - BB_L) / data['close']) * 100
    Sum_BB = high_diff_percent + low_diff_percent
    data[Sum_BB_label] = round(Sum_BB, 2)


    return data

# ADX (Average Directional movement index)
def TA_ADX(data, Period=12):

    ADX_label = 'ADX_' + str(Period)
    

    # TA íŒ¨í‚¤ì§€ì˜ ADX ê¸°ëŠ¥ì„ ì´ìš©
    Indicator_ADX = ta.trend.ADXIndicator(high=data['high'], low=data['low'], close=data['close'], window=Period)

    # ADX ê³„ì‚°
    ADX = Indicator_ADX.adx()
    data[ADX_label] = round(ADX, 2)

    return data

def calculate_stochslow(data, k_period=18, d_period=5, k_period2=6):
    # ê¸°ì¡´ %K ê³„ì‚°ì„ ìœ„í•œ low_min, high_max
    low_min = data['low'].rolling(window=k_period).min()
    high_max = data['high'].rolling(window=k_period).max()

    # k_period2ë¥¼ ì‚¬ìš©í•œ ìƒˆë¡œìš´ low_min, high_max ê³„ì‚°
    low_min_sum = low_min.rolling(window=k_period2).sum()
    high_max_sum = high_max.rolling(window=k_period2).sum()

    # ìˆ˜ì •ëœ %K ê³„ì‚°
    data['%K'] = ((data['close'] - low_min_sum) / (high_max_sum - low_min_sum)) * 100

    # %D ê³„ì‚° (%Kì˜ ì´ë™ í‰ê· )
    data['%D'] = data['%K'].rolling(window=d_period).mean()

    return data

def tax(price):
    result = round(price*0.0023, 0)
    return result


def calculate_max_quantity(close_price, total_amount=100000):
    """
    ì£¼ì–´ì§„ ì¢…ê°€(close price)ì™€ ì´ ê¸ˆì•¡ì„ ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ€ ë§¤ìˆ˜ ìˆ˜ëŸ‰ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

    :param close_price: ë§¤ìˆ˜í•  ì£¼ì‹ì˜ ì¢…ê°€
    :param total_amount: ë§¤ìˆ˜ì— ì‚¬ìš©í•  ì´ ê¸ˆì•¡
    :return: ë§¤ìˆ˜í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ì£¼ì‹ ìˆ˜ëŸ‰
    """
    if close_price <= 0:
        return 0

    max_quantity = total_amount // close_price  # ì†Œìˆ˜ì  ì´í•˜ë¥¼ ë²„ë¦¬ê³  ì •ìˆ˜ ë¶€ë¶„ë§Œ ì·¨í•¨
    return max_quantity

def export_to_excel(df, file_name):
    """
    ì£¼ì–´ì§„ ë°ì´í„°í”„ë ˆì„ì„ Excel íŒŒì¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤.

    :param df: ë‚´ë³´ë‚¼ ë°ì´í„°í”„ë ˆì„
    :param file_name: ìƒì„±ë  Excel íŒŒì¼ì˜ ì´ë¦„ (í™•ì¥ì '.xlsx' í¬í•¨)
    """
    try:
        # ë°ì´í„°í”„ë ˆì„ì„ Excel íŒŒì¼ë¡œ ì €ì¥
        df.to_excel(file_name, index=False)
        print(f"{file_name}ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"Excel íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

def bol_dolpa(df):
    df['BB_H_12_per'] = ((df['BB_H_12']/df['close'])-1)*100
    df['BB_H_50_per'] = ((df['BB_H_50']/df['close'])-1)*100
    df['BB_H_100_per'] = ((df['BB_H_100']/df['close'])-1)*100 
    

def detect_time_interval(df):
    """
    ë°ì´í„°ì˜ ì‹œê°„ ê°„ê²©ì„ ê°ì§€í•˜ëŠ” í•¨ìˆ˜
    
    :param df: pandas DataFrame, 'date' ì—´ì´ datetime í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    :return: (ì‹œê°„ ê°„ê²©(ë¶„), ì‹œì‘ ì‹œê°„)
    """
    # 09ì‹œ~10ì‹œ ì‚¬ì´ì˜ ë°ì´í„°ë§Œ í•„í„°ë§
    morning_data = df[df['date'].dt.hour == 9].copy()
    if morning_data.empty:
        return None, None
    
    # ì‹œê°„ ì •ë ¬
    morning_data = morning_data.sort_values('date')
    
    # ì—°ì†ëœ í–‰ ê°„ì˜ ì‹œê°„ ì°¨ì´ ê³„ì‚°
    time_diffs = morning_data['date'].diff().dt.total_seconds() / 60
    
    # ê°€ì¥ ë¹ˆë²ˆí•œ ì‹œê°„ ê°„ê²© ì°¾ê¸°
    most_common_interval = time_diffs.mode().iloc[0]
    
    # ì‹œì‘ ì‹œê°„ ì°¾ê¸°
    start_time = morning_data['date'].min().time()
    
    return most_common_interval, start_time

def convert_to_daily(df):
    """
    ë¶„ë´‰ ë°ì´í„°ë¥¼ ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ê¸°ì¡´ ì¼ë´‰(09:00~15:30)ê³¼ ë§¤ë§¤ìš© ì¼ë´‰(09:00~15:10) ì»¬ëŸ¼ì„ ëª¨ë‘ ìƒì„±í•©ë‹ˆë‹¤.
    
    :param df: pandas DataFrame, 'date' ì—´ì´ datetime í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    :return: ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜ëœ DataFrame (15:10 ì»¬ëŸ¼ í¬í•¨)
    """
    # ì‹œê°„ ê°„ê²©ê³¼ ì‹œì‘ ì‹œê°„ ê°ì§€
    interval, detected_start_time = detect_time_interval(df)
    
    if interval is None:
        print("09ì‹œ~10ì‹œ ì‚¬ì´ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    # ê±°ë˜ ì‹œê°„ëŒ€ ì„¤ì •
    market_start = pd.Timestamp('09:00:00').time()
    market_end_full = pd.Timestamp('15:30:00').time()  # ì™„ì „í•œ ì¼ë´‰ìš©
    market_end_1510 = pd.Timestamp('15:10:00').time()  # ë§¤ë§¤ìš© ì¼ë´‰
    
    # ì „ì²´ ê±°ë˜ ì‹œê°„ëŒ€ ë°ì´í„° (09:00~15:30)
    df_full = df[
        (df['date'].dt.time >= market_start) & 
        (df['date'].dt.time <= market_end_full)
    ].copy()
    
    # 15:10ê¹Œì§€ ë°ì´í„° (09:00~15:10)  
    df_1510 = df[
        (df['date'].dt.time >= market_start) & 
        (df['date'].dt.time <= market_end_1510)
    ].copy()
    
    # ë°ì´í„°ê°€ ìˆëŠ”ì§€ë§Œ ê°„ë‹¨íˆ í™•ì¸
    if df_full.empty or df_1510.empty:
        print("ê±°ë˜ ì‹œê°„ëŒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    print(f"ì „ì²´ ë°ì´í„°: {len(df_full)}ê±´, 15:10ê¹Œì§€ ë°ì´í„°: {len(df_1510)}ê±´")
    
    # ì™„ì „í•œ ì¼ë´‰ ë°ì´í„° ìƒì„± (09:00~15:30)
    daily_df_full = df_full.groupby(df_full['date'].dt.date).agg({
        'open': 'first',    # ì‹œê°€: í•´ë‹¹ ë‚ ì§œì˜ ì²« ê°€ê²©
        'high': 'max',      # ê³ ê°€: í•´ë‹¹ ë‚ ì§œì˜ ìµœê³  ê°€ê²©
        'low': 'min',       # ì €ê°€: í•´ë‹¹ ë‚ ì§œì˜ ìµœì € ê°€ê²©
        'close': 'last',    # ì¢…ê°€: í•´ë‹¹ ë‚ ì§œì˜ ë§ˆì§€ë§‰ ê°€ê²©
        'volume': 'sum'     # ê±°ë˜ëŸ‰: í•´ë‹¹ ë‚ ì§œì˜ ì´ ê±°ë˜ëŸ‰
    }).reset_index()
    
    # 15:10ê¹Œì§€ ì¼ë´‰ ë°ì´í„° ìƒì„± (09:00~15:10)
    daily_df_1510 = df_1510.groupby(df_1510['date'].dt.date).agg({
        'open': 'first',    
        'high': 'max',      
        'low': 'min',       
        'close': 'last',    
        'volume': 'sum'     
    }).reset_index()
    
    # 15:10 ì»¬ëŸ¼ëª… ë³€ê²½
    daily_df_1510 = daily_df_1510.rename(columns={
        'open': 'open_1510',
        'high': 'high_1510',
        'low': 'low_1510',
        'close': 'close_1510',
        'volume': 'volume_1510'
    })
    
    # ë‘ ë°ì´í„°í”„ë ˆì„ ë³‘í•©
    daily_df = pd.merge(daily_df_full, daily_df_1510, on='date', how='inner')
    
    # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
    daily_df['date'] = pd.to_datetime(daily_df['date'])
    
    # ê±°ë˜ëŸ‰ì´ 0ì¸ ë‚ ì§œ ì œì™¸ (ì „ì²´ ê±°ë˜ëŸ‰ ê¸°ì¤€)
    daily_df = daily_df[daily_df['volume'] > 0]
    
    # ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬
    daily_df = daily_df.sort_values('date')
    
    print(f"ì¼ë´‰ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(daily_df)}ì¼")
    
    return daily_df

def calculate_ema(data, period):
    """
    ì§€ìˆ˜ì´ë™í‰ê· (EMA)ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    
    :param data: ê°€ê²© ë°ì´í„° Series
    :param period: EMA ê¸°ê°„
    :return: EMA Series
    """
    return data.ewm(span=period, adjust=False).mean()

def check_conditions(daily_df, condition_set=1):
    """
    ìˆ˜ì •ëœ ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜ (ë‹¹ì¼ì€ 15:10 ë°ì´í„° ì‚¬ìš©)
    
    :param daily_df: ì¼ë´‰ ë°ì´í„° DataFrame (15:10 ì»¬ëŸ¼ í¬í•¨)
    :param condition_set: ì¡°ê±´ ì„¸íŠ¸ ì„ íƒ (1: ê¸°ì¡´, 2: ì¶”ê°€1, 3: ì¶”ê°€2)
    :return: ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë‚ ì§œ ë¦¬ìŠ¤íŠ¸
    """
    # EMA ê³„ì‚° (ì „ë‚ ê¹Œì§€ëŠ” ì¼ë°˜ ì¢…ê°€, ë‹¹ì¼ì€ 15:10 ì¢…ê°€ ì‚¬ìš©)
    daily_df['EMA22'] = calculate_ema(daily_df['close'], 22)
    daily_df['EMA60'] = calculate_ema(daily_df['close'], 60)
    daily_df['EMA120'] = calculate_ema(daily_df['close'], 120)
    daily_df['MA22'] = daily_df['close'].rolling(window=22).mean()
    daily_df['MA50'] = daily_df['close'].rolling(window=50).mean()  # 50ì¼ì„  ì¶”ê°€
    
    # 15:10 ê¸°ì¤€ MA ê³„ì‚° (ë‹¹ì¼ ì¡°ê±´ í™•ì¸ìš©)
    daily_df['MA22_1510'] = daily_df['close_1510'].rolling(window=22).mean()
    
    # ìµœê·¼ Në´‰ ìµœê³ ê°€ ê³„ì‚° (ë‹¹ì¼ì€ 15:10 ê¸°ì¤€)
    daily_df['recent_high_1510'] = daily_df['close_1510'].rolling(window=10).max()
    
    # ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë‚ ì§œ ì°¾ê¸°
    valid_dates = []
    
    print(f"\n=== ì¡°ê±´ ì„¸íŠ¸ {condition_set} ì ìš© ===")
    if condition_set == 1:
        print("ê¸°ì¡´ ì¡°ê±´: 8~2ë´‰ì „ ìƒìŠ¹ì„¸, 2ë´‰ì „/1ë´‰ì „ êµì°¨ íŒ¨í„´")
    elif condition_set == 2:
        print("ì¶”ê°€1 ì¡°ê±´: 9~3ë´‰ì „ ìƒìŠ¹ì„¸, 3ë´‰ì „/2-1ë´‰ì „ êµì°¨ íŒ¨í„´")
    elif condition_set == 3:
        print("ì¶”ê°€2 ì¡°ê±´: 10~4ë´‰ì „ ìƒìŠ¹ì„¸, 4ë´‰ì „/3-1ë´‰ì „ êµì°¨ íŒ¨í„´")
    
    for idx in range(120, len(daily_df)):  # ìµœì†Œ 120ì¼ ë°ì´í„° í•„ìš”
        current_row = daily_df.iloc[idx]
        prev_row = daily_df.iloc[idx-1]
        
        try:
            # ì¡°ê±´ ì„¸íŠ¸ì— ë”°ë¥¸ ì¡°ê±´ 1: ê³¼ê±° ìƒìŠ¹ì„¸ í™•ì¸
            if condition_set == 1:
                # ê¸°ì¡´: 8ë´‰ì „ë¶€í„° 2ë´‰ì „ê¹Œì§€ ì¢…ê°€ > EMA22
                condition_1 = all(
                    daily_df.iloc[idx-i]['close'] > daily_df.iloc[idx-i]['EMA22']
                    for i in range(2, 9)  # 2ë´‰ì „ë¶€í„° 8ë´‰ì „ê¹Œì§€
                )
            elif condition_set == 2:
                # ì¶”ê°€1: 9ë´‰ì „ë¶€í„° 3ë´‰ì „ê¹Œì§€ ì¢…ê°€ > EMA22
                condition_1 = all(
                    daily_df.iloc[idx-i]['close'] > daily_df.iloc[idx-i]['EMA22']
                    for i in range(3, 10)  # 3ë´‰ì „ë¶€í„° 9ë´‰ì „ê¹Œì§€
                )
            elif condition_set == 3:
                # ì¶”ê°€2: 10ë´‰ì „ë¶€í„° 4ë´‰ì „ê¹Œì§€ ì¢…ê°€ > EMA22
                condition_1 = all(
                    daily_df.iloc[idx-i]['close'] > daily_df.iloc[idx-i]['EMA22']
                    for i in range(4, 11)  # 4ë´‰ì „ë¶€í„° 10ë´‰ì „ê¹Œì§€
                )
            
            # ì¡°ê±´ 2: 1ë´‰ì „ EMA22 > EMA60 > EMA120 (ëª¨ë“  ì¡°ê±´ ì„¸íŠ¸ ê³µí†µ)
            condition_2 = (
                prev_row['EMA22'] > prev_row['EMA60'] > prev_row['EMA120']
            )
            
            # ì¡°ê±´ 3: êµì°¨ íŒ¨í„´ (ì¡°ê±´ ì„¸íŠ¸ë³„ë¡œ ë‹¤ë¦„)
            if condition_set == 1:
                # ê¸°ì¡´: 2ë´‰ì „(ì¢…ê°€>EMA22>EMA120) & 1ë´‰ì „(EMA22>ì¢…ê°€>EMA120)
                prev2_row = daily_df.iloc[idx-2]
                condition_3a = (
                    prev2_row['close'] > prev2_row['EMA22'] > prev2_row['EMA120']
                )
                condition_3b = (
                    prev_row['EMA22'] > prev_row['close'] > prev_row['EMA120']
                )
                condition_3 = condition_3a and condition_3b
                
            elif condition_set == 2:
                # ì¶”ê°€1: 3ë´‰ì „(ì¢…ê°€>EMA22>EMA120) & 2-1ë´‰ì „(EMA22>ì¢…ê°€>EMA120)
                prev3_row = daily_df.iloc[idx-3]
                prev2_row = daily_df.iloc[idx-2]
                condition_3a = (
                    prev3_row['close'] > prev3_row['EMA22'] > prev3_row['EMA120']
                )
                condition_3b = (
                    prev2_row['EMA22'] > prev2_row['close'] > prev2_row['EMA120']
                )
                condition_3c = (
                    prev_row['EMA22'] > prev_row['close'] > prev_row['EMA120']
                )
                condition_3 = condition_3a and condition_3b and condition_3c
                
            elif condition_set == 3:
                # ì¶”ê°€2: 4ë´‰ì „(ì¢…ê°€>EMA22>EMA120) & 3-1ë´‰ì „(EMA22>ì¢…ê°€>EMA120)
                prev4_row = daily_df.iloc[idx-4]
                prev3_row = daily_df.iloc[idx-3]
                prev2_row = daily_df.iloc[idx-2]
                condition_3a = (
                    prev4_row['close'] > prev4_row['EMA22'] > prev4_row['EMA120']
                )
                condition_3b = (
                    prev3_row['EMA22'] > prev3_row['close'] > prev3_row['EMA120']
                )
                condition_3c = (
                    prev2_row['EMA22'] > prev2_row['close'] > prev2_row['EMA120']
                )
                condition_3d = (
                    prev_row['EMA22'] > prev_row['close'] > prev_row['EMA120']
                )
                condition_3 = condition_3a and condition_3b and condition_3c and condition_3d
            
            # ì¡°ê±´ 4: ê¸°ì¤€ì¼ close_1510 > MA22_1510 (ëŒíŒŒ) - ëª¨ë“  ì¡°ê±´ ì„¸íŠ¸ ê³µí†µ
            condition_4 = (
                current_row['close_1510'] > current_row['MA22_1510']
            )
            
            # ì¡°ê±´ 5: ê¸°ì¤€ì¼ ìµœê·¼10ë´‰ìµœê³ ê°€ < (close_1510 * 1.3) - ëª¨ë“  ì¡°ê±´ ì„¸íŠ¸ ê³µí†µ
            condition_5 = (
                current_row['recent_high_1510'] < (current_row['close_1510'] * 1.3)
            )
            
            # ì¡°ê±´ 6: ê¸°ì¤€ì¼ ìƒìŠ¹ë¥  5%-15% (ë‹¹ì¼ 15:10 vs ì „ë‚  15:30) - ëª¨ë“  ì¡°ê±´ ì„¸íŠ¸ ê³µí†µ
            price_increase = (current_row['close_1510'] / prev_row['close'] - 1) * 100
            condition_6 = 5 <= price_increase <= 15
            
            # ì¡°ê±´ 7: ìµì ˆê°€ê°€ ë§¤ìˆ˜ê°€ë³´ë‹¤ 8% ì´ìƒ ë†’ìŒ - ëª¨ë“  ì¡°ê±´ ì„¸íŠ¸ ê³µí†µ
            # ìµì ˆê°€ ê³„ì‚° (calculate_exit_prices ë¡œì§ê³¼ ë™ì¼)
            candle_center = (current_row['open_1510'] + current_row['close_1510']) / 2
            buy_price = current_row['close_1510']
            stop_loss = current_row['MA50']
            
            # 50ì¼ì„  ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
            if pd.isna(stop_loss):
                continue
                
            # ìµì ˆê°€ ê³„ì‚°
            if candle_center > stop_loss:
                take_profit = candle_center + ((candle_center - stop_loss) * 1.5)
            else:
                take_profit = buy_price * 1.05
                
            # ìµì ˆê°€ê°€ ë§¤ìˆ˜ê°€ë³´ë‹¤ ë‚®ìœ¼ë©´ 5% ìµì ˆë¡œ ì¡°ì •
            if take_profit <= buy_price:
                take_profit = buy_price * 1.05
                
            # ìµì ˆê°€ê°€ ë§¤ìˆ˜ê°€ë³´ë‹¤ 8% ì´ìƒ ë†’ì€ì§€ í™•ì¸
            condition_7 = take_profit >= buy_price * 1.08
            
            # ëª¨ë“  ì¡°ê±´ ë§Œì¡± ì‹œ í•´ë‹¹ ë‚ ì§œ ì¶”ê°€
            if (condition_1 and condition_2 and condition_3 and 
                condition_4 and condition_5 and condition_6 and condition_7):
                valid_dates.append(current_row['date'].strftime('%Y-%m-%d'))
                
        except Exception as e:
            print(f"ë‚ ì§œ {current_row['date']} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            continue
    
    return valid_dates

def process_single_file(file, selected_folder, condition_set=1):
    """
    ë‹¨ì¼ íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ (ì¡°ê±´ ê²€ìƒ‰ + ë°±í…ŒìŠ¤íŒ…)
    """
    try:
        # JSON íŒŒì¼ ì½ê¸°
        with open(file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # JSON êµ¬ì¡° í™•ì¸
        if 'meta' not in data or 'data' not in data:
            return {
                'code': file.name,
                'error': 'JSON íŒŒì¼ êµ¬ì¡° ì˜¤ë¥˜: meta ë˜ëŠ” data ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None
            }
        
        # ì¢…ëª© ì½”ë“œ ì¶”ì¶œ (meta ì„¹ì…˜ì—ì„œ)
        code = data['meta'].get('code', file.name)
        
        # ì°¨íŠ¸ ë°ì´í„°ë§Œ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        chart_data = data['data']
        if not chart_data:
            return {
                'code': code,
                'error': 'ì°¨íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None
            }
        
        df = pd.DataFrame(chart_data)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return {
                'code': code,
                'error': f'í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None
            }
        
        # date ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        try:
            df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d%H%M')
        except Exception as date_error:
            # ë‹¤ë¥¸ ë‚ ì§œ í˜•ì‹ ì‹œë„
            try:
                df['date'] = pd.to_datetime(df['date'])
            except Exception:
                return {
                    'code': code,
                    'error': f'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì˜¤ë¥˜: {str(date_error)}. ì²« ë²ˆì§¸ date ê°’: {df["date"].iloc[0] if len(df) > 0 else "ì—†ìŒ"}',
                    'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'backtest_result': None
                }
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        df = df[required_columns]
        
        # ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜
        daily_df = convert_to_daily(df)
        
        if daily_df.empty:
            return {
                'code': code,
                'valid_dates': [],
                'file_name': file.name,
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None
            }
        
        # ì¡°ê±´ ê²€ìƒ‰ ì‹¤í–‰ (ì¡°ê±´ ì„¸íŠ¸ ì „ë‹¬)
        valid_dates = check_conditions(daily_df, condition_set)
        
        # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ (ì¡°ê±´ ë§Œì¡± ë‚ ì§œê°€ ìˆì„ ë•Œë§Œ)
        backtest_result = None
        if valid_dates:
            # ì¢…ëª© ì½”ë“œë¥¼ daily_dfì— ì¶”ê°€ (ë°±í…ŒìŠ¤íŒ…ì—ì„œ ì‚¬ìš©)
            daily_df['code'] = code
            
            # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
            backtest_df = backtest_strategy(daily_df, df, valid_dates)
            
            if not backtest_df.empty:
                # ì¢…ëª©ë²ˆí˜¸ ì»¬ëŸ¼ ì—…ë°ì´íŠ¸
                backtest_df['ì¢…ëª©ë²ˆí˜¸'] = code
                
                # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ì €ì¥
                backtest_file = save_backtest_results(backtest_df, selected_folder, code, condition_set)
                
                backtest_result = {
                    'total_trades': len(backtest_df),
                    'win_rate': len(backtest_df[backtest_df['ìˆ˜ìµë¥ '] > 0]) / len(backtest_df) * 100 if len(backtest_df) > 0 else 0,
                    'avg_return': backtest_df['ìˆ˜ìµë¥ '].mean() if len(backtest_df) > 0 else 0,
                    'file_saved': backtest_file.name if backtest_file else None
                }
        
        result = {
            'code': code,
            'valid_dates': valid_dates if valid_dates else [],
            'file_name': file.name,
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'backtest_result': backtest_result
        }
        return result
        
    except Exception as e:
        return {
            'code': file.name,
            'error': f'íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}',
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'backtest_result': None
        }

def process_chunk(chunk_files, selected_folder, condition_set=1):
    """
    íŒŒì¼ ì²­í¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    """
    chunk_results = []
    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_file = {
            executor.submit(process_single_file, file, selected_folder, condition_set): file 
            for file in chunk_files
        }
        
        for future in future_to_file:
            result = future.result()
            if result:
                chunk_results.append(result)
    
    return chunk_results

def test_resample_candles(file, target_interval):
    """
    ë‹¨ì¼ íŒŒì¼ì˜ ë¶„ë´‰ ë°ì´í„°ë¥¼ ì§€ì •ëœ ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ëŠ” í•¨ìˆ˜
    
    :param file: í…ŒìŠ¤íŠ¸í•  JSON íŒŒì¼ ê²½ë¡œ
    :param target_interval: ëª©í‘œ ì‹œê°„ ê°„ê²© (ë¶„)
    :return: í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # JSON íŒŒì¼ ì½ê¸°
        with open(file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # JSON êµ¬ì¡° í™•ì¸
        if 'meta' not in data or 'data' not in data:
            return {
                'code': file.name,
                'status': 'error',
                'message': 'JSON íŒŒì¼ êµ¬ì¡° ì˜¤ë¥˜: meta ë˜ëŠ” data ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤'
            }
        
        # ì¢…ëª© ì½”ë“œ ì¶”ì¶œ
        code = data['meta'].get('code', file.name)
        
        # ì°¨íŠ¸ ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        chart_data = data['data']
        if not chart_data:
            return {
                'code': code,
                'status': 'error',
                'message': 'ì°¨íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤'
            }
        
        df = pd.DataFrame(chart_data)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return {
                'code': code,
                'status': 'error',
                'message': f'í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}'
            }
        
        # date ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        try:
            df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d%H%M')
        except Exception as date_error:
            # ë‹¤ë¥¸ ë‚ ì§œ í˜•ì‹ ì‹œë„
            try:
                df['date'] = pd.to_datetime(df['date'])
            except Exception:
                return {
                    'code': code,
                    'status': 'error',
                    'message': f'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì˜¤ë¥˜: {str(date_error)}. ì²« ë²ˆì§¸ date ê°’: {df["date"].iloc[0] if len(df) > 0 else "ì—†ìŒ"}'
                }
        
        df = df[required_columns]
        
        # í˜„ì¬ ë°ì´í„°ì˜ ì‹œê°„ ê°„ê²© ê°ì§€
        current_interval, start_time = detect_time_interval(df)
        
        if current_interval is None:
            return {
                'code': code,
                'status': 'error',
                'message': 'ì‹œê°„ ê°„ê²©ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }
        
        # ëª©í‘œ ê°„ê²©ì´ í˜„ì¬ ê°„ê²©ì˜ ë°°ìˆ˜ì¸ì§€ í™•ì¸
        if target_interval % current_interval != 0:
            return {
                'code': code,
                'status': 'invalid',
                'current_interval': int(current_interval),
                'target_interval': target_interval,
                'message': f'í˜„ì¬ ê²€ìƒ‰ëœ ë°ì´í„°ê°€ {int(current_interval)}ë¶„ ì°¨íŠ¸ ë°ì´í„°ì…ë‹ˆë‹¤. {int(current_interval)}ë¶„ ê¸°ì¤€ ë°°ìˆ˜ë¡œë§Œ ë°ì´í„° ìˆ˜ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.'
            }
        
        # ë¦¬ìƒ˜í”Œë§ ì‹¤í–‰ ì „ ì›ë³¸ ë°ì´í„° ì •ë³´ ìˆ˜ì§‘
        original_count = len(df)
        original_first_time = df['date'].min()
        original_last_time = df['date'].max()
        
        # ë¦¬ìƒ˜í”Œë§ ì‹¤í–‰
        multiplier = int(target_interval / current_interval)
        resampled_df = resample_candles(df.copy(), multiplier)
        
        # ê²°ê³¼ í†µê³„
        resampled_count = len(resampled_df)
        removed_count = original_count - (resampled_count * multiplier)
        
        # ë¦¬ìƒ˜í”Œë§ í›„ ë°ì´í„° ì •ë³´
        resampled_first_time = resampled_df['date'].min() if not resampled_df.empty else None
        resampled_last_time = resampled_df['date'].max() if not resampled_df.empty else None
        
        # ë¶ˆì™„ì „í•œ ë´‰ ê°ì§€ ì •ë³´
        incomplete_info = ""
        if removed_count > 0:
            incomplete_info = f" (ë¶ˆì™„ì „í•œ ë´‰ {removed_count}ê°œ ì œê±°ë¨)"
        
        return {
            'code': code,
            'status': 'success',
            'current_interval': int(current_interval),
            'target_interval': target_interval,
            'multiplier': multiplier,
            'original_count': original_count,
            'resampled_count': resampled_count,
            'removed_count': removed_count,
            'original_time_range': f"{original_first_time.strftime('%Y-%m-%d %H:%M')} ~ {original_last_time.strftime('%Y-%m-%d %H:%M')}",
            'resampled_time_range': f"{resampled_first_time.strftime('%Y-%m-%d %H:%M')} ~ {resampled_last_time.strftime('%Y-%m-%d %H:%M')}" if resampled_first_time else "ì—†ìŒ",
            'incomplete_info': incomplete_info,
            'data_sample': resampled_df.head(3).to_dict('records') if not resampled_df.empty else []
        }
        
    except Exception as e:
        return {
            'code': file.name,
            'status': 'error',
            'message': f'ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}'
        }

def test_resample_with_analysis(selected_folder, target_interval, condition_set=1):
    """
    ë¦¬ìƒ˜í”Œë§ëœ ë°ì´í„°ë¡œ ì¡°ê±´ ê²€ìƒ‰ê³¼ ë°±í…ŒìŠ¤íŒ…ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    :param selected_folder: ì„ íƒëœ í´ë” ê²½ë¡œ
    :param target_interval: ëª©í‘œ ì‹œê°„ ê°„ê²© (ë¶„)
    :param condition_set: ì¡°ê±´ ì„¸íŠ¸ ë²ˆí˜¸
    :return: ë¶„ì„ ê²°ê³¼
    """
    # í´ë” ë‚´ì˜ JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    json_files = list(selected_folder.glob('*.json'))
    if not json_files:
        print("ì„ íƒí•œ í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    print(f"\n=== {target_interval}ë¶„ë´‰ ë¦¬ìƒ˜í”Œë§ ë¶„ì„ ì‹œì‘ ===")
    print(f"ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(json_files)}")
    
    results = []
    valid_files = []
    invalid_files = []
    
    # 1ë‹¨ê³„: ë¦¬ìƒ˜í”Œë§ ê°€ëŠ¥ì„± í™•ì¸
    print("\n1ë‹¨ê³„: ë¦¬ìƒ˜í”Œë§ ê°€ëŠ¥ì„± í™•ì¸ ì¤‘...")
    
    for file in tqdm(json_files, desc="íŒŒì¼ ê²€ì¦"):
        test_result = test_resample_candles(file, target_interval)
        
        if test_result['status'] == 'success':
            valid_files.append(file)
            # ë¶ˆì™„ì „í•œ ë´‰ì´ ì œê±°ëœ ê²½ìš° ì •ë³´ ì¶œë ¥
            if test_result.get('removed_count', 0) > 0:
                print(f"\nğŸ“Š {test_result['code']}: {test_result['incomplete_info']}")
                print(f"   ì›ë³¸: {test_result['original_time_range']}")
                print(f"   ë³€í™˜: {test_result['resampled_time_range']}")
        elif test_result['status'] == 'invalid':
            invalid_files.append(test_result)
            if len(invalid_files) == 1:  # ì²« ë²ˆì§¸ ì˜¤ë¥˜ë§Œ ì¶œë ¥
                print(f"\nâš ï¸ {test_result['message']}")
        else:
            print(f"\nâŒ {test_result['code']}: {test_result['message']}")
    
    print(f"\nê²€ì¦ ì™„ë£Œ: ì²˜ë¦¬ ê°€ëŠ¥ íŒŒì¼ {len(valid_files)}ê°œ, ë¶ˆê°€ëŠ¥ íŒŒì¼ {len(invalid_files)}ê°œ")
    
    if not valid_files:
        print("ì²˜ë¦¬ ê°€ëŠ¥í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    if invalid_files:
        print(f"ì²˜ë¦¬ ë¶ˆê°€ëŠ¥í•œ íŒŒì¼ì´ {len(invalid_files)}ê°œ ìˆìŠµë‹ˆë‹¤.")
        print("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
        user_input = input().lower()
        if user_input != 'y':
            print("ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return []
    
    # 2ë‹¨ê³„: ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
    print(f"\n2ë‹¨ê³„: {len(valid_files)}ê°œ íŒŒì¼ë¡œ ì¡°ê±´ ê²€ìƒ‰ ë° ë°±í…ŒìŠ¤íŒ… ìˆ˜í–‰...")
    
    # íŒŒì¼ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
    file_chunks = [valid_files[i:i + CHUNK_SIZE] for i in range(0, len(valid_files), CHUNK_SIZE)]
    
    # ë¦¬ìƒ˜í”Œë§ ë²„ì „ì˜ í”„ë¡œì„¸ìŠ¤ í•¨ìˆ˜ ì‚¬ìš©
    with tqdm(total=len(valid_files), desc="ë¶„ì„ ì§„í–‰") as pbar:
        for chunk in file_chunks:
            chunk_results = process_chunk_with_resampling(chunk, selected_folder, target_interval, condition_set)
            results.extend(chunk_results)
            pbar.update(len(chunk))
    
    return results

def process_single_file_with_resampling(file, selected_folder, target_interval, condition_set=1):
    """
    ë¦¬ìƒ˜í”Œë§ì„ ì ìš©í•œ ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
    """
    try:
        # JSON íŒŒì¼ ì½ê¸°
        with open(file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # JSON êµ¬ì¡° í™•ì¸
        if 'meta' not in data or 'data' not in data:
            return {
                'code': file.name,
                'error': 'JSON íŒŒì¼ êµ¬ì¡° ì˜¤ë¥˜: meta ë˜ëŠ” data ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None,
                'resample_info': ''
            }
        
        # ì¢…ëª© ì½”ë“œ ì¶”ì¶œ
        code = data['meta'].get('code', file.name)
        
        # ì°¨íŠ¸ ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        chart_data = data['data']
        if not chart_data:
            return {
                'code': code,
                'error': 'ì°¨íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None,
                'resample_info': ''
            }
        
        df = pd.DataFrame(chart_data)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return {
                'code': code,
                'error': f'í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None,
                'resample_info': ''
            }
        
        # date ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        try:
            df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d%H%M')
        except Exception as date_error:
            # ë‹¤ë¥¸ ë‚ ì§œ í˜•ì‹ ì‹œë„
            try:
                df['date'] = pd.to_datetime(df['date'])
            except Exception:
                return {
                    'code': code,
                    'error': f'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì˜¤ë¥˜: {str(date_error)}. ì²« ë²ˆì§¸ date ê°’: {df["date"].iloc[0] if len(df) > 0 else "ì—†ìŒ"}',
                    'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'backtest_result': None,
                    'resample_info': ''
                }
        
        df = df[required_columns]
        
        # í˜„ì¬ ë°ì´í„°ì˜ ì‹œê°„ ê°„ê²© ê°ì§€
        current_interval, _ = detect_time_interval(df)
        
        # ë¦¬ìƒ˜í”Œë§ (ëª©í‘œ ê°„ê²©ì´ í˜„ì¬ ê°„ê²©ê³¼ ë‹¤ë¥¸ ê²½ìš°ì—ë§Œ)
        if target_interval != current_interval:
            multiplier = int(target_interval / current_interval)
            df = resample_candles(df, multiplier)
        
        # ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜ (15:10 ì»¬ëŸ¼ í¬í•¨)
        daily_df = convert_to_daily(df)
        
        if daily_df.empty:
            return {
                'code': code,
                'valid_dates': [],
                'file_name': file.name,
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None,
                'resample_info': f"{int(current_interval)}ë¶„ -> {target_interval}ë¶„"
            }
        
        # ì¡°ê±´ ê²€ìƒ‰ ì‹¤í–‰
        valid_dates = check_conditions(daily_df, condition_set)
        
        # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ (ì¡°ê±´ ë§Œì¡± ë‚ ì§œê°€ ìˆì„ ë•Œë§Œ)
        backtest_result = None
        if valid_dates:
            daily_df['code'] = code
            backtest_df = backtest_strategy(daily_df, df, valid_dates)
            
            if not backtest_df.empty:
                backtest_df['ì¢…ëª©ë²ˆí˜¸'] = code
                
                # ë¦¬ìƒ˜í”Œë§ ì •ë³´ë¥¼ í¬í•¨í•œ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backtest_dir = selected_folder / 'backtest_resampled'
                backtest_dir.mkdir(exist_ok=True)
                
                condition_names = {1: "ê¸°ì¡´ì¡°ê±´", 2: "ì¶”ê°€1ì¡°ê±´", 3: "ì¶”ê°€2ì¡°ê±´"}
                condition_name = condition_names.get(condition_set, "ì•Œìˆ˜ì—†ìŒ")
                
                excel_file = backtest_dir / f"backtest_{code}_{target_interval}ë¶„_{condition_name}_{timestamp}.xlsx"
                
                # í†µê³„ ì •ë³´ ìƒì„±
                total_trades = len(backtest_df)
                win_trades = len(backtest_df[backtest_df['ìˆ˜ìµë¥ '] > 0])
                win_rate = (win_trades / total_trades * 100) if total_trades > 0 else 0
                avg_return = backtest_df['ìˆ˜ìµë¥ '].mean() if total_trades > 0 else 0
                
                stats_df = pd.DataFrame({
                    'í•­ëª©': ['ì´ ê±°ë˜ìˆ˜', 'ìˆ˜ìµ ê±°ë˜', 'ì†ì‹¤ ê±°ë˜', 'ìŠ¹ë¥ (%)', 'í‰ê·  ìˆ˜ìµë¥ (%)', 'ì¡°ê±´ì„¸íŠ¸', 'ë¦¬ìƒ˜í”Œë§'],
                    'ê°’': [total_trades, win_trades, total_trades - win_trades, round(win_rate, 2), 
                          round(avg_return, 2), condition_name, f"{int(current_interval)}ë¶„ -> {target_interval}ë¶„"]
                })
                
                # ì—‘ì…€ íŒŒì¼ ì €ì¥
                with pd.ExcelWriter(excel_file) as writer:
                    backtest_df.to_excel(writer, sheet_name='ê±°ë˜ë‚´ì—­', index=False)
                    stats_df.to_excel(writer, sheet_name='í†µê³„', index=False)
                
                backtest_result = {
                    'total_trades': total_trades,
                    'win_rate': win_rate,
                    'avg_return': avg_return,
                    'file_saved': excel_file.name
                }
        
        return {
            'code': code,
            'valid_dates': valid_dates if valid_dates else [],
            'file_name': file.name,
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'backtest_result': backtest_result,
            'resample_info': f"{int(current_interval)}ë¶„ -> {target_interval}ë¶„"
        }
        
    except Exception as e:
        return {
            'code': file.name,
            'error': f'íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}',
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'backtest_result': None
        }

def process_chunk_with_resampling(chunk_files, selected_folder, target_interval, condition_set=1):
    """
    ë¦¬ìƒ˜í”Œë§ì´ ì ìš©ëœ íŒŒì¼ ì²­í¬ ì²˜ë¦¬ í•¨ìˆ˜
    """
    chunk_results = []
    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_file = {
            executor.submit(process_single_file_with_resampling, file, selected_folder, target_interval, condition_set): file 
            for file in chunk_files
        }
        
        for future in future_to_file:
            result = future.result()
            if result:
                chunk_results.append(result)
    
    return chunk_results

def calculate_exit_prices(daily_df, current_idx):
    """
    ìµì ˆê°€ì™€ ì†ì ˆê°€ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    """
    current_row = daily_df.iloc[current_idx]
    
    # ë§¤ìˆ˜ê°€: ë‹¹ì¼ 15:10 ì¢…ê°€
    buy_price = current_row['close_1510']
    
    # ì†ì ˆê°€: 50ì¼ì„ 
    stop_loss = current_row['MA50']
    
    # ìµì ˆê°€ ê³„ì‚°
    candle_center = (current_row['open_1510'] + current_row['close_1510']) / 2
    
    if candle_center > stop_loss:
        take_profit = candle_center + ((candle_center - stop_loss) * 1.5)
    else:
        take_profit = buy_price * 1.05
        
    # ìµì ˆê°€ê°€ ë§¤ìˆ˜ê°€ë³´ë‹¤ ë‚®ìœ¼ë©´ 5% ìµì ˆë¡œ ì¡°ì •
    if take_profit <= buy_price:
        take_profit = buy_price * 1.05
        
    return buy_price, take_profit, stop_loss

def backtest_strategy(daily_df, minute_df, valid_dates):
    """
    ë°±í…ŒìŠ¤íŒ…ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    """
    backtest_results = []
    
    # ë‚ ì§œ ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜
    valid_dates_dt = [pd.to_datetime(date) for date in valid_dates]
    
    for target_date in valid_dates_dt:
        # í•´ë‹¹ ë‚ ì§œì˜ ì¼ë´‰ ë°ì´í„° ì°¾ê¸°
        date_mask = daily_df['date'].dt.date == target_date.date()
        if not date_mask.any():
            continue
            
        current_idx = daily_df[date_mask].index[0]
        
        # ìµì ˆê°€, ì†ì ˆê°€ ê³„ì‚°
        buy_price, take_profit, stop_loss = calculate_exit_prices(daily_df, current_idx)
        
        # ë‹¤ìŒ ê±°ë˜ì¼ë“¤ì—ì„œ ìµì ˆ/ì†ì ˆ í™•ì¸
        exit_price = None
        exit_date = None
        exit_type = None
        
        for future_idx in range(current_idx + 1, min(current_idx + 11, len(daily_df))):  # ìµœëŒ€ 10ì¼ê°„ í™•ì¸
            future_row = daily_df.iloc[future_idx]
            
            # ìµì ˆ ì¡°ê±´ í™•ì¸ (ê³ ê°€ê°€ ìµì ˆê°€ ë„ë‹¬)
            if future_row['high'] >= take_profit:
                exit_price = take_profit
                exit_date = future_row['date']
                exit_type = 'ìµì ˆ'
                break
                
            # ì†ì ˆ ì¡°ê±´ í™•ì¸ (ì €ê°€ê°€ ì†ì ˆê°€ ì´í•˜)
            if future_row['low'] <= stop_loss:
                exit_price = stop_loss
                exit_date = future_row['date']
                exit_type = 'ì†ì ˆ'
                break
        
        # 10ì¼ ë‚´ì— ì²­ì‚°ë˜ì§€ ì•Šìœ¼ë©´ ë§ˆì§€ë§‰ ë‚  ì¢…ê°€ë¡œ ì²­ì‚°
        if exit_price is None:
            last_idx = min(current_idx + 10, len(daily_df) - 1)
            exit_price = daily_df.iloc[last_idx]['close']
            exit_date = daily_df.iloc[last_idx]['date']
            exit_type = 'ì‹œê°„ì²­ì‚°'
        
        # ìˆ˜ìµë¥  ê³„ì‚°
        return_rate = (exit_price / buy_price - 1) * 100
        
        # ê²°ê³¼ ì €ì¥
        backtest_results.append({
            'ë§¤ìˆ˜ì¼': target_date.strftime('%Y-%m-%d'),
            'ì²­ì‚°ì¼': exit_date.strftime('%Y-%m-%d'),
            'ë§¤ìˆ˜ê°€': round(buy_price, 0),
            'ì²­ì‚°ê°€': round(exit_price, 0),
            'ìµì ˆê°€': round(take_profit, 0),
            'ì†ì ˆê°€': round(stop_loss, 0),
            'ìˆ˜ìµë¥ ': round(return_rate, 2),
            'ì²­ì‚°ìœ í˜•': exit_type,
            'ì¢…ëª©ë²ˆí˜¸': daily_df.iloc[current_idx].get('code', '')
        })
    
    return pd.DataFrame(backtest_results)

def save_backtest_results(backtest_df, folder_path, code, condition_set):
    """
    ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    """
    if backtest_df.empty:
        return None
        
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # backtest í´ë” ìƒì„±
    backtest_dir = folder_path / 'backtest'
    backtest_dir.mkdir(exist_ok=True)
    
    # ì¡°ê±´ ì´ë¦„ ë§¤í•‘
    condition_names = {1: "ê¸°ì¡´ì¡°ê±´", 2: "ì¶”ê°€1ì¡°ê±´", 3: "ì¶”ê°€2ì¡°ê±´"}
    condition_name = condition_names.get(condition_set, "ì•Œìˆ˜ì—†ìŒ")
    
    # íŒŒì¼ëª… ìƒì„±
    excel_file = backtest_dir / f"backtest_{code}_{condition_name}_{timestamp}.xlsx"
    
    # í†µê³„ ì •ë³´ ìƒì„±
    total_trades = len(backtest_df)
    win_trades = len(backtest_df[backtest_df['ìˆ˜ìµë¥ '] > 0])
    win_rate = (win_trades / total_trades * 100) if total_trades > 0 else 0
    avg_return = backtest_df['ìˆ˜ìµë¥ '].mean() if total_trades > 0 else 0
    
    stats_df = pd.DataFrame({
        'í•­ëª©': ['ì¢…ëª©ì½”ë“œ', 'ì´ ê±°ë˜ìˆ˜', 'ìˆ˜ìµ ê±°ë˜', 'ì†ì‹¤ ê±°ë˜', 'ìŠ¹ë¥ (%)', 'í‰ê·  ìˆ˜ìµë¥ (%)', 'ì¡°ê±´ì„¸íŠ¸'],
        'ê°’': [code, total_trades, win_trades, total_trades - win_trades, 
               round(win_rate, 2), round(avg_return, 2), condition_name]
    })
    
    # Excel íŒŒì¼ ì €ì¥
    with pd.ExcelWriter(excel_file) as writer:
        backtest_df.to_excel(writer, sheet_name='ê±°ë˜ë‚´ì—­', index=False)
        stats_df.to_excel(writer, sheet_name='í†µê³„', index=False)
    
    return excel_file

def combine_all_backtest_results(folder_path, condition_set):
    """
    ëª¨ë“  ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ í†µí•©í•˜ëŠ” í•¨ìˆ˜
    """
    backtest_dir = folder_path / 'backtest'
    if not backtest_dir.exists():
        return None
    
    # ì¡°ê±´ ì„¸íŠ¸ì— í•´ë‹¹í•˜ëŠ” ì—‘ì…€ íŒŒì¼ë“¤ ì°¾ê¸°
    condition_names = {1: "ê¸°ì¡´ì¡°ê±´", 2: "ì¶”ê°€1ì¡°ê±´", 3: "ì¶”ê°€2ì¡°ê±´"}
    condition_name = condition_names.get(condition_set, "ì•Œìˆ˜ì—†ìŒ")
    
    excel_files = list(backtest_dir.glob(f"*{condition_name}*.xlsx"))
    if not excel_files:
        return None
    
    all_trades = []
    
    for excel_file in excel_files:
        try:
            # ê±°ë˜ë‚´ì—­ ì½ê¸°
            trades_df = pd.read_excel(excel_file, sheet_name='ê±°ë˜ë‚´ì—­')
            all_trades.append(trades_df)
            
        except Exception as e:
            print(f"íŒŒì¼ {excel_file.name} ì½ê¸° ì˜¤ë¥˜: {e}")
            continue
    
    if not all_trades:
        return None
    
    # ëª¨ë“  ê±°ë˜ë‚´ì—­ í†µí•©
    combined_trades = pd.concat(all_trades, ignore_index=True)
    
    # ì „ì²´ í†µê³„ ê³„ì‚°
    total_trades = len(combined_trades)
    win_trades = len(combined_trades[combined_trades['ìˆ˜ìµë¥ '] > 0])
    win_rate = (win_trades / total_trades * 100) if total_trades > 0 else 0
    avg_return = combined_trades['ìˆ˜ìµë¥ '].mean() if total_trades > 0 else 0
    total_return = combined_trades['ìˆ˜ìµë¥ '].sum()
    
    overall_stats = pd.DataFrame({
        'í•­ëª©': ['ì „ì²´ ê±°ë˜ìˆ˜', 'ìˆ˜ìµ ê±°ë˜', 'ì†ì‹¤ ê±°ë˜', 'ìŠ¹ë¥ (%)', 'í‰ê·  ìˆ˜ìµë¥ (%)', 'ëˆ„ì  ìˆ˜ìµë¥ (%)', 'ì¡°ê±´ì„¸íŠ¸'],
        'ê°’': [total_trades, win_trades, total_trades - win_trades, 
               round(win_rate, 2), round(avg_return, 2), round(total_return, 2), condition_name]
    })
    
    # í†µí•© íŒŒì¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    combined_file = backtest_dir / f"combined_backtest_{condition_name}_{timestamp}.xlsx"
    
    with pd.ExcelWriter(combined_file) as writer:
        combined_trades.to_excel(writer, sheet_name='ì „ì²´ê±°ë˜ë‚´ì—­', index=False)
        overall_stats.to_excel(writer, sheet_name='ì „ì²´í†µê³„', index=False)
        
        # ì¢…ëª©ë³„ í†µê³„ë„ ì¶”ê°€
        stock_stats = combined_trades.groupby('ì¢…ëª©ë²ˆí˜¸').agg({
            'ìˆ˜ìµë¥ ': ['count', 'mean', 'sum', lambda x: (x > 0).sum()]
        }).round(2)
        stock_stats.columns = ['ê±°ë˜ìˆ˜', 'í‰ê· ìˆ˜ìµë¥ ', 'ëˆ„ì ìˆ˜ìµë¥ ', 'ìˆ˜ìµê±°ë˜ìˆ˜']
        stock_stats['ìŠ¹ë¥ '] = round(stock_stats['ìˆ˜ìµê±°ë˜ìˆ˜'] / stock_stats['ê±°ë˜ìˆ˜'] * 100, 2)
        stock_stats.to_excel(writer, sheet_name='ì¢…ëª©ë³„í†µê³„')
    
    return combined_file

def process_all_conditions(daily_df):
    """
    ëª¨ë“  ì¡°ê±´ ì„¸íŠ¸(1,2,3)ë¥¼ ë™ì‹œì— ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜
    """
    results = {}
    
    for condition_set in [1, 2, 3]:
        valid_dates = check_conditions(daily_df, condition_set)
        results[condition_set] = valid_dates
    
    return results

def process_single_file_all_conditions(file, selected_folder):
    """
    ëª¨ë“  ì¡°ê±´ì„ ë™ì‹œì— ê²€ìƒ‰í•˜ê³  ë°±í…ŒìŠ¤íŒ…í•˜ëŠ” í•¨ìˆ˜ (3ë²ˆ ë©”ë‰´ìš©)
    """
    try:
        # JSON íŒŒì¼ ì½ê¸°
        with open(file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # JSON êµ¬ì¡° í™•ì¸
        if 'meta' not in data or 'data' not in data:
            return {
                'code': file.name,
                'error': 'JSON íŒŒì¼ êµ¬ì¡° ì˜¤ë¥˜: meta ë˜ëŠ” data ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'all_conditions': {}
            }
        
        # ì¢…ëª© ì½”ë“œ ì¶”ì¶œ
        code = data['meta'].get('code', file.name)
        
        # ì°¨íŠ¸ ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        chart_data = data['data']
        if not chart_data:
            return {
                'code': code,
                'error': 'ì°¨íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'all_conditions': {}
            }
        
        df = pd.DataFrame(chart_data)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return {
                'code': code,
                'error': f'í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'all_conditions': {}
            }
        
        # date ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        try:
            df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d%H%M')
        except Exception as date_error:
            try:
                df['date'] = pd.to_datetime(df['date'])
            except Exception:
                return {
                    'code': code,
                    'error': f'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì˜¤ë¥˜: {str(date_error)}',
                    'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'all_conditions': {}
                }
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        df = df[required_columns]
        
        # ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜ (ë¶„ë´‰ ë¦¬ìƒ˜í”Œë§ ì—†ì´ ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©)
        daily_df = convert_to_daily(df)
        
        if daily_df.empty:
            return {
                'code': code,
                'all_conditions': {},
                'file_name': file.name,
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        
        # ëª¨ë“  ì¡°ê±´ ê²€ìƒ‰ ì‹¤í–‰
        all_conditions_results = process_all_conditions(daily_df)
        
        # ê° ì¡°ê±´ë³„ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
        backtest_results = {}
        for condition_set, valid_dates in all_conditions_results.items():
            if valid_dates:
                daily_df['code'] = code
                backtest_df = backtest_strategy(daily_df, df, valid_dates)
                
                if not backtest_df.empty:
                    backtest_df['ì¢…ëª©ë²ˆí˜¸'] = code
                    backtest_results[condition_set] = {
                        'dataframe': backtest_df,
                        'total_trades': len(backtest_df),
                        'win_rate': len(backtest_df[backtest_df['ìˆ˜ìµë¥ '] > 0]) / len(backtest_df) * 100,
                        'avg_return': backtest_df['ìˆ˜ìµë¥ '].mean()
                    }
        
        return {
            'code': code,
            'all_conditions': all_conditions_results,
            'backtest_results': backtest_results,
            'file_name': file.name,
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
    except Exception as e:
        return {
            'code': file.name,
            'error': f'íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}',
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'all_conditions': {}
        }

def execute_integrated_backtest():
    """
    3ë²ˆ ë©”ë‰´: ì „ì²´ ì¡°ê±´ í†µí•© ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ í•¨ìˆ˜
    """
    global MAX_WORKERS, CHUNK_SIZE
    
    # json_data í´ë” ë‚´ì˜ í´ë” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    base_dir = Path('json_data')
    if not base_dir.exists():
        print("json_data í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
        
    folders = [f for f in base_dir.iterdir() if f.is_dir()]
    if not folders:
        print("ë¶„ì„í•  ë°ì´í„° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    # í´ë” ëª©ë¡ í‘œì‹œ
    print("\n=== ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° í´ë” ===")
    for idx, folder in enumerate(folders, 1):
        print(f"{idx}. {folder.name}")
    
    # í´ë” ì„ íƒ
    while True:
        try:
            folder_choice = int(input("\në¶„ì„í•  í´ë” ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: "))
            if 1 <= folder_choice <= len(folders):
                selected_folder = folders[folder_choice - 1]
                break
            else:
                print(f"1ë¶€í„° {len(folders)}ê¹Œì§€ì˜ ë²ˆí˜¸ë§Œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        except ValueError:
            print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    # í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì„¤ì •
    while True:
        try:
            num_workers = int(input(f"\nì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-{multiprocessing.cpu_count()}, ê¸°ë³¸ê°’: {MAX_WORKERS}): ") or MAX_WORKERS)
            if 1 <= num_workers <= multiprocessing.cpu_count():
                MAX_WORKERS = num_workers
                break
            else:
                print(f"1ë¶€í„° {multiprocessing.cpu_count()}ê¹Œì§€ì˜ ìˆ«ìë§Œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        except ValueError:
            print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    # ì„ íƒëœ í´ë” ë‚´ì˜ JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    json_files = list(selected_folder.glob('*.json'))
    if not json_files:
        print("ì„ íƒí•œ í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    print(f"\n=== ì „ì²´ ì¡°ê±´ í†µí•© ë°±í…ŒìŠ¤íŒ… ì‹œì‘ ===")
    print(f"ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(json_files)}")
    print(f"ì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ìˆ˜: {MAX_WORKERS}")
    print("ê¸°ì¡´ì¡°ê±´ + ì¶”ê°€1ì¡°ê±´ + ì¶”ê°€2ì¡°ê±´ì„ ë™ì‹œì— ê²€ìƒ‰í•©ë‹ˆë‹¤.")
    
    # íŒŒì¼ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
    file_chunks = [json_files[i:i + CHUNK_SIZE] for i in range(0, len(json_files), CHUNK_SIZE)]
    
    # ì „ì²´ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    all_results = []
    
    # ê° ì¡°ê±´ë³„ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    all_backtest_results = {1: [], 2: [], 3: []}
    
    # tqdmì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™© í‘œì‹œ
    with tqdm(total=len(json_files), desc="í†µí•© ë¶„ì„ ì§„í–‰") as pbar:
        for chunk in file_chunks:
            # ì²­í¬ë³„ ë³‘ë ¬ ì²˜ë¦¬
            chunk_results = []
            with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
                future_to_file = {
                    executor.submit(process_single_file_all_conditions, file, selected_folder): file 
                    for file in chunk
                }
                
                for future in future_to_file:
                    result = future.result()
                    if result:
                        chunk_results.append(result)
                        
                        # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ìˆ˜ì§‘
                        backtest_results = result.get('backtest_results', {})
                        for condition_set, bt_result in backtest_results.items():
                            all_backtest_results[condition_set].append(bt_result['dataframe'])
            
            all_results.extend(chunk_results)
            pbar.update(len(chunk))
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n=== í†µí•© ë¶„ì„ ê²°ê³¼ ===")
    success_count = 0
    error_count = 0
    condition_stats = {1: 0, 2: 0, 3: 0}
    
    for result in all_results:
        if 'error' in result:
            error_count += 1
            print(f"\n{result['code']} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {result['error']}")
        else:
            success_count += 1
            all_conditions = result.get('all_conditions', {})
            
            for condition_set, valid_dates in all_conditions.items():
                if valid_dates:
                    condition_stats[condition_set] += 1
                    print(f"\n{result['code']} - ì¡°ê±´{condition_set}: {len(valid_dates)}ê°œ ë‚ ì§œ ë°œê²¬")
    
    print(f"\nì²˜ë¦¬ ì™„ë£Œ: ì´ {len(all_results)}ê°œ íŒŒì¼")
    print(f"ì„±ê³µ: {success_count}ê°œ, ì‹¤íŒ¨: {error_count}ê°œ")
    print(f"ì¡°ê±´1 ë§Œì¡± ì¢…ëª©: {condition_stats[1]}ê°œ")
    print(f"ì¡°ê±´2 ë§Œì¡± ì¢…ëª©: {condition_stats[2]}ê°œ")
    print(f"ì¡°ê±´3 ë§Œì¡± ì¢…ëª©: {condition_stats[3]}ê°œ")
    
    # í†µí•© ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ íŒŒì¼ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    integrated_dir = selected_folder / 'integrated_backtest'
    integrated_dir.mkdir(exist_ok=True)
    
    integrated_file = integrated_dir / f"integrated_backtest_all_conditions_{timestamp}.xlsx"
    
    condition_names = {1: "ê¸°ì¡´ì¡°ê±´", 2: "ì¶”ê°€1ì¡°ê±´", 3: "ì¶”ê°€2ì¡°ê±´"}
    
    with pd.ExcelWriter(integrated_file) as writer:
        # ê° ì¡°ê±´ë³„ ì‹œíŠ¸ ìƒì„±
        for condition_set in [1, 2, 3]:
            if all_backtest_results[condition_set]:
                # ëª¨ë“  ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ í†µí•©
                combined_df = pd.concat(all_backtest_results[condition_set], ignore_index=True)
                
                # í†µê³„ ê³„ì‚°
                total_trades = len(combined_df)
                win_trades = len(combined_df[combined_df['ìˆ˜ìµë¥ '] > 0])
                win_rate = (win_trades / total_trades * 100) if total_trades > 0 else 0
                avg_return = combined_df['ìˆ˜ìµë¥ '].mean() if total_trades > 0 else 0
                total_return = combined_df['ìˆ˜ìµë¥ '].sum()
                
                # ê±°ë˜ë‚´ì—­ ì‹œíŠ¸
                sheet_name = f"{condition_names[condition_set]}_ê±°ë˜ë‚´ì—­"
                combined_df.to_excel(writer, sheet_name=sheet_name, index=False)
                
                # í†µê³„ ì‹œíŠ¸
                stats_df = pd.DataFrame({
                    'í•­ëª©': ['ì´ ê±°ë˜ìˆ˜', 'ìˆ˜ìµ ê±°ë˜', 'ì†ì‹¤ ê±°ë˜', 'ìŠ¹ë¥ (%)', 'í‰ê·  ìˆ˜ìµë¥ (%)', 'ëˆ„ì  ìˆ˜ìµë¥ (%)'],
                    'ê°’': [total_trades, win_trades, total_trades - win_trades, 
                           round(win_rate, 2), round(avg_return, 2), round(total_return, 2)]
                })
                
                stats_sheet_name = f"{condition_names[condition_set]}_í†µê³„"
                stats_df.to_excel(writer, sheet_name=stats_sheet_name, index=False)
                
                print(f"\n{condition_names[condition_set]} ë°±í…ŒìŠ¤íŒ… ê²°ê³¼:")
                print(f"  ì´ ê±°ë˜ìˆ˜: {total_trades}ê±´")
                print(f"  ìŠ¹ë¥ : {win_rate:.2f}%")
                print(f"  í‰ê·  ìˆ˜ìµë¥ : {avg_return:.2f}%")
                print(f"  ëˆ„ì  ìˆ˜ìµë¥ : {total_return:.2f}%")
        
        # ì „ì²´ ìš”ì•½ ì‹œíŠ¸ ìƒì„±
        summary_data = []
        for condition_set in [1, 2, 3]:
            if all_backtest_results[condition_set]:
                combined_df = pd.concat(all_backtest_results[condition_set], ignore_index=True)
                total_trades = len(combined_df)
                win_trades = len(combined_df[combined_df['ìˆ˜ìµë¥ '] > 0])
                win_rate = (win_trades / total_trades * 100) if total_trades > 0 else 0
                avg_return = combined_df['ìˆ˜ìµë¥ '].mean() if total_trades > 0 else 0
                total_return = combined_df['ìˆ˜ìµë¥ '].sum()
                
                summary_data.append({
                    'ì¡°ê±´': condition_names[condition_set],
                    'ì¢…ëª©ìˆ˜': condition_stats[condition_set],
                    'ì´ê±°ë˜ìˆ˜': total_trades,
                    'ìˆ˜ìµê±°ë˜': win_trades,
                    'ì†ì‹¤ê±°ë˜': total_trades - win_trades,
                    'ìŠ¹ë¥ (%)': round(win_rate, 2),
                    'í‰ê· ìˆ˜ìµë¥ (%)': round(avg_return, 2),
                    'ëˆ„ì ìˆ˜ìµë¥ (%)': round(total_return, 2)
                })
        
        if summary_data:
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, sheet_name='ì „ì²´ìš”ì•½', index=False)
    
    print(f"\ní†µí•© ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ê°€ {integrated_file.name}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ê°œë³„ ì¢…ëª© íŒŒì¼ë“¤ ì‚­ì œ (ìš”ì²­ì‚¬í•­ 3ë²ˆ)
    print("\nê°œë³„ ì¢…ëª© ë°±í…ŒìŠ¤íŒ… íŒŒì¼ë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤...")
    backtest_dir = selected_folder / 'backtest'
    if backtest_dir.exists():
        individual_files = list(backtest_dir.glob('backtest_*.xlsx'))
        deleted_count = 0
        for file in individual_files:
            try:
                file.unlink()
                deleted_count += 1
            except Exception as e:
                print(f"íŒŒì¼ {file.name} ì‚­ì œ ì‹¤íŒ¨: {e}")
        
        print(f"ê°œë³„ íŒŒì¼ {deleted_count}ê°œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"í†µí•© ê²°ê³¼ íŒŒì¼ë§Œ {integrated_file.name}ì— ë‚¨ê²¨ì¡ŒìŠµë‹ˆë‹¤.")

def main():
    global MAX_WORKERS, CHUNK_SIZE
    
    while True:
        print("\n=== ì£¼ì‹ ë°ì´í„° ë¶„ì„ í”„ë¡œê·¸ë¨ ===")
        print("1. ë°ì´í„° í´ë” ì„ íƒ ë° ë¶„ì„")
        print("2. ë¶„ë´‰ ë¦¬ìƒ˜í”Œë§ í…ŒìŠ¤íŠ¸")
        print("3. ì „ì²´ ì¡°ê±´ í†µí•© ë°±í…ŒìŠ¤íŒ…")
        print("9. í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
        
        choice = input("\në©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš” (1,2,3,9): ")
        
        if choice == '1':
            # ê¸°ì¡´ 1ë²ˆ ë©”ë‰´ ë¡œì§
            # json_data í´ë” ë‚´ì˜ í´ë” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            base_dir = Path('json_data')
            if not base_dir.exists():
                print("json_data í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                continue
                
            folders = [f for f in base_dir.iterdir() if f.is_dir()]
            if not folders:
                print("ë¶„ì„í•  ë°ì´í„° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
                
            # í´ë” ëª©ë¡ í‘œì‹œ
            print("\n=== ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° í´ë” ===")
            for idx, folder in enumerate(folders, 1):
                print(f"{idx}. {folder.name}")
            
            # í´ë” ì„ íƒ
            while True:
                try:
                    folder_choice = int(input("\në¶„ì„í•  í´ë” ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: "))
                    if 1 <= folder_choice <= len(folders):
                        selected_folder = folders[folder_choice - 1]
                        break
                    else:
                        print(f"1ë¶€í„° {len(folders)}ê¹Œì§€ì˜ ë²ˆí˜¸ë§Œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                except ValueError:
                    print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            
            # í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì„¤ì •
            while True:
                try:
                    num_workers = int(input(f"\nì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-{multiprocessing.cpu_count()}, ê¸°ë³¸ê°’: {MAX_WORKERS}): ") or MAX_WORKERS)
                    if 1 <= num_workers <= multiprocessing.cpu_count():
                        MAX_WORKERS = num_workers
                        break
                    else:
                        print(f"1ë¶€í„° {multiprocessing.cpu_count()}ê¹Œì§€ì˜ ìˆ«ìë§Œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                except ValueError:
                    print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            
            # ì¡°ê±´ ì„¸íŠ¸ ì„ íƒ
            print("\n=== ì¡°ê±´ ì„¸íŠ¸ ì„ íƒ ===")
            print("1. ê¸°ì¡´ ì¡°ê±´ (8~2ë´‰ì „ ìƒìŠ¹ì„¸, 2ë´‰ì „/1ë´‰ì „ êµì°¨)")
            print("2. ì¶”ê°€1 ì¡°ê±´ (9~3ë´‰ì „ ìƒìŠ¹ì„¸, 3ë´‰ì „/2-1ë´‰ì „ êµì°¨)")
            print("3. ì¶”ê°€2 ì¡°ê±´ (10~4ë´‰ì „ ìƒìŠ¹ì„¸, 4ë´‰ì „/3-1ë´‰ì „ êµì°¨)")
            
            while True:
                try:
                    condition_choice = int(input("\nì‚¬ìš©í•  ì¡°ê±´ ì„¸íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-3): "))
                    if 1 <= condition_choice <= 3:
                        break
                    else:
                        print("1ë¶€í„° 3ê¹Œì§€ì˜ ë²ˆí˜¸ë§Œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                except ValueError:
                    print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            
            # ì„ íƒëœ í´ë” ë‚´ì˜ JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            json_files = list(selected_folder.glob('*.json'))
            if not json_files:
                print("ì„ íƒí•œ í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                continue
                
            print(f"\n=== {selected_folder.name} í´ë”ì˜ íŒŒì¼ ëª©ë¡ ===")
            for idx, file in enumerate(json_files, 1):
                print(f"{idx}. {file.name}")
            
            # íŒŒì¼ ë¶„ì„ ì‹œì‘
            print("\níŒŒì¼ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            print(f"ì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ìˆ˜: {MAX_WORKERS}")
            print(f"ì¡°ê±´ ì„¸íŠ¸: {condition_choice}")
            print(f"ì²­í¬ í¬ê¸°: {CHUNK_SIZE}")
            
            # íŒŒì¼ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
            file_chunks = [json_files[i:i + CHUNK_SIZE] for i in range(0, len(json_files), CHUNK_SIZE)]
            
            # ì „ì²´ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
            all_results = []
            
            # tqdmì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™© í‘œì‹œ
            with tqdm(total=len(json_files), desc="íŒŒì¼ ì²˜ë¦¬ ì¤‘") as pbar:
                for chunk_idx, chunk in enumerate(file_chunks):
                    chunk_results = process_chunk(chunk, selected_folder, condition_choice)
                    all_results.extend(chunk_results)
                    pbar.update(len(chunk))
            
            # ìµœì¢… ê²°ê³¼ ì €ì¥
            result_file = save_results(all_results, selected_folder, condition_choice)
            
            # ê²°ê³¼ ì¶œë ¥
            print("\n=== ë¶„ì„ ê²°ê³¼ ===")
            success_count = 0
            error_count = 0
            valid_dates_count = 0
            backtest_count = 0
            total_trades = 0
            
            for result in all_results:
                if 'error' in result:
                    error_count += 1
                    print(f"\n{result['code']} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {result['error']}")
                else:
                    success_count += 1
                    if result.get('valid_dates'):
                        valid_dates_count += 1
                        print(f"\n{result['code']} ì¢…ëª©ì˜ ì¡°ê±´ ë§Œì¡± ë‚ ì§œ:")
                        for date in result['valid_dates']:
                            print(f"  - {date}")
                        
                        # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ì¶œë ¥
                        backtest_result = result.get('backtest_result')
                        if backtest_result:
                            backtest_count += 1
                            total_trades += backtest_result['total_trades']
                            print(f"  ë°±í…ŒìŠ¤íŒ…: {backtest_result['total_trades']}ê±´ ê±°ë˜, " +
                                  f"ìŠ¹ë¥  {backtest_result['win_rate']:.1f}%, " +
                                  f"í‰ê·  ìˆ˜ìµë¥  {backtest_result['avg_return']:.2f}%")
            
            print(f"\nì²˜ë¦¬ ì™„ë£Œ: ì´ {len(all_results)}ê°œ íŒŒì¼")
            print(f"ì„±ê³µ: {success_count}ê°œ, ì‹¤íŒ¨: {error_count}ê°œ")
            print(f"ì¡°ê±´ ë§Œì¡± ì¢…ëª©: {valid_dates_count}ê°œ")
            print(f"ë°±í…ŒìŠ¤íŒ… ì™„ë£Œ ì¢…ëª©: {backtest_count}ê°œ")
            print(f"ì´ ê±°ë˜ ê±´ìˆ˜: {total_trades}ê±´")
            
            if result_file:
                print(f"ê²°ê³¼ê°€ {result_file.name}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ í†µí•©
                if backtest_count > 0:
                    print("\në°±í…ŒìŠ¤íŒ… ê²°ê³¼ í†µí•©ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                    combined_backtest_file = combine_all_backtest_results(selected_folder, condition_choice)
                    if combined_backtest_file:
                        print(f"ì „ì²´ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ê°€ {combined_backtest_file.name}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                print("ì €ì¥í•  ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        elif choice == '2':
            # 2ë²ˆ ë©”ë‰´ ë¡œì§ (ë¶„ë´‰ ë¦¬ìƒ˜í”Œë§ í…ŒìŠ¤íŠ¸)
            # json_data í´ë” ë‚´ì˜ í´ë” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            base_dir = Path('json_data')
            if not base_dir.exists():
                print("json_data í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                continue
                
            folders = [f for f in base_dir.iterdir() if f.is_dir()]
            if not folders:
                print("í…ŒìŠ¤íŠ¸í•  ë°ì´í„° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
                
            # í´ë” ëª©ë¡ í‘œì‹œ
            print("\n=== ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° í´ë” ===")
            for idx, folder in enumerate(folders, 1):
                print(f"{idx}. {folder.name}")
            
            # í´ë” ì„ íƒ
            while True:
                try:
                    folder_choice = int(input("\ní…ŒìŠ¤íŠ¸í•  í´ë” ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: "))
                    if 1 <= folder_choice <= len(folders):
                        selected_folder = folders[folder_choice - 1]
                        break
                    else:
                        print(f"1ë¶€í„° {len(folders)}ê¹Œì§€ì˜ ë²ˆí˜¸ë§Œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                except ValueError:
                    print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            
            # í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì„¤ì •
            while True:
                try:
                    num_workers = int(input(f"\nì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-{multiprocessing.cpu_count()}, ê¸°ë³¸ê°’: {MAX_WORKERS}): ") or MAX_WORKERS)
                    if 1 <= num_workers <= multiprocessing.cpu_count():
                        MAX_WORKERS = num_workers
                        break
                    else:
                        print(f"1ë¶€í„° {multiprocessing.cpu_count()}ê¹Œì§€ì˜ ìˆ«ìë§Œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                except ValueError:
                    print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            
            # ì¡°ê±´ ì„¸íŠ¸ ì„ íƒ
            print("\n=== ì¡°ê±´ ì„¸íŠ¸ ì„ íƒ ===")
            print("1. ê¸°ì¡´ ì¡°ê±´ (8~2ë´‰ì „ ìƒìŠ¹ì„¸, 2ë´‰ì „/1ë´‰ì „ êµì°¨)")
            print("2. ì¶”ê°€1 ì¡°ê±´ (9~3ë´‰ì „ ìƒìŠ¹ì„¸, 3ë´‰ì „/2-1ë´‰ì „ êµì°¨)")
            print("3. ì¶”ê°€2 ì¡°ê±´ (10~4ë´‰ì „ ìƒìŠ¹ì„¸, 4ë´‰ì „/3-1ë´‰ì „ êµì°¨)")
            
            while True:
                try:
                    condition_choice = int(input("\nì‚¬ìš©í•  ì¡°ê±´ ì„¸íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-3): "))
                    if 1 <= condition_choice <= 3:
                        break
                    else:
                        print("1ë¶€í„° 3ê¹Œì§€ì˜ ë²ˆí˜¸ë§Œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                except ValueError:
                    print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            
            # ëª©í‘œ ë¶„ë´‰ ê°„ê²© ì„¤ì •
            while True:
                try:
                    target_interval = int(input("\në³€í™˜í•  ë¶„ë´‰ ê°„ê²©ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 10, 15, 30): "))
                    if target_interval > 0:
                        break
                    else:
                        print("ì–‘ìˆ˜ë§Œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                except ValueError:
                    print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            
            # ë¦¬ìƒ˜í”Œë§ ë¶„ì„ ì‹¤í–‰
            print(f"\n{target_interval}ë¶„ë´‰ ë¦¬ìƒ˜í”Œë§ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            results = test_resample_with_analysis(selected_folder, target_interval, condition_choice)
            
            # ê²°ê³¼ ì¶œë ¥
            if results:
                print("\n=== ë¦¬ìƒ˜í”Œë§ ë¶„ì„ ê²°ê³¼ ===")
                success_count = 0
                error_count = 0
                valid_dates_count = 0
                backtest_count = 0
                total_trades = 0
                
                for result in results:
                    if 'error' in result:
                        error_count += 1
                        print(f"\n{result['code']} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {result['error']}")
                    else:
                        success_count += 1
                        print(f"\n{result['code']} ({result.get('resample_info', '')}):")
                        
                        if result.get('valid_dates'):
                            valid_dates_count += 1
                            print(f"  ì¡°ê±´ ë§Œì¡± ë‚ ì§œ: {len(result['valid_dates'])}ê°œ")
                            
                            # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ì¶œë ¥
                            backtest_result = result.get('backtest_result')
                            if backtest_result:
                                backtest_count += 1
                                total_trades += backtest_result['total_trades']
                                print(f"  ë°±í…ŒìŠ¤íŒ…: {backtest_result['total_trades']}ê±´ ê±°ë˜, " +
                                      f"ìŠ¹ë¥  {backtest_result['win_rate']:.1f}%, " +
                                      f"í‰ê·  ìˆ˜ìµë¥  {backtest_result['avg_return']:.2f}%")
                        else:
                            print("  ì¡°ê±´ ë§Œì¡± ë‚ ì§œ ì—†ìŒ")
                
                print(f"\nì²˜ë¦¬ ì™„ë£Œ: ì´ {len(results)}ê°œ íŒŒì¼")
                print(f"ì„±ê³µ: {success_count}ê°œ, ì‹¤íŒ¨: {error_count}ê°œ")
                print(f"ì¡°ê±´ ë§Œì¡± ì¢…ëª©: {valid_dates_count}ê°œ")
                print(f"ë°±í…ŒìŠ¤íŒ… ì™„ë£Œ ì¢…ëª©: {backtest_count}ê°œ")
                print(f"ì´ ê±°ë˜ ê±´ìˆ˜: {total_trades}ê±´")
                
                # ë¦¬ìƒ˜í”Œë§ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ê°€ ìˆìœ¼ë©´ í†µí•© íŒŒì¼ ìƒì„±
                if backtest_count > 0:
                    print(f"\në°±í…ŒìŠ¤íŒ… ê²°ê³¼ëŠ” backtest_resampled í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    print(f"íŒŒì¼ëª…ì— '{target_interval}ë¶„' ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            else:
                print("\në¶„ì„í•  ìˆ˜ ìˆëŠ” íŒŒì¼ì´ ì—†ì—ˆìŠµë‹ˆë‹¤.")
                
        elif choice == '3':
            # 3ë²ˆ ë©”ë‰´: ì „ì²´ ì¡°ê±´ í†µí•© ë°±í…ŒìŠ¤íŒ…
            execute_integrated_backtest()
            
        elif choice == '9':
            print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
            
        else:
            print("\nì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()