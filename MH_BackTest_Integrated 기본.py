import os
import sqlite3
from datetime import datetime
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")
import time
from pathlib import Path
import json
import configparser
### TA íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•œ ë³¼ë¦°ì ¸ ë°´ë“œ ê³„ì‚° í•¨ìˆ˜
import ta
from pykrx import stock
from exchange_calendars import get_calendar
import multiprocessing
from concurrent.futures import ProcessPoolExecutor
from functools import partial
from tqdm import tqdm
import matplotlib.pyplot as plt

# ì „ì—­ ë³€ìˆ˜
MAX_WORKERS = 10
CHUNK_SIZE = 20

def load_config():
    """
    ì„¤ì • íŒŒì¼ì—ì„œ ì¡°ê±´ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    """
    config = configparser.ConfigParser()
    config_file = Path('backtest_config.ini')
    
    # ê¸°ë³¸ ì„¤ì • íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±
    if not config_file.exists():
        create_default_config()
    
    config.read(config_file, encoding='utf-8')
    return config

def safe_get_config(config, section, key, default_value=None):
    """
    ì„¤ì •ê°’ì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì£¼ì„ ì œê±°, ê³µë°± ì œê±°)
    """
    try:
        value = config[section][key]
        # ì£¼ì„ ì œê±° (# ì´í›„ ë¶€ë¶„)
        if '#' in value:
            value = value.split('#')[0]
        # ì•ë’¤ ê³µë°± ì œê±°
        value = value.strip()
        return value
    except (KeyError, TypeError):
        return default_value

def create_default_config():
    """
    ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±
    """
    config = configparser.ConfigParser()
    
    # ê¸°ì¡´ ì¡°ê±´ (ì¡°ê±´ ì„¸íŠ¸ 1)
    config['CONDITION_1'] = {
        'name': 'ê¸°ì¡´ì¡°ê±´',
        'description': '8~2ë´‰ì „ ìƒìŠ¹ì„¸, 2ë´‰ì „/1ë´‰ì „ êµì°¨ íŒ¨í„´',
        'uptrend_start_candle': '8',
        'uptrend_end_candle': '2',
        'cross_pattern_start': '2',
        'cross_pattern_length': '2',
        'min_price_increase': '5.0',
        'max_price_increase': '15.0',
        'min_profit_margin': '8.0'
    }
    
    # ì¶”ê°€1 ì¡°ê±´ (ì¡°ê±´ ì„¸íŠ¸ 2)
    config['CONDITION_2'] = {
        'name': 'ì¶”ê°€1ì¡°ê±´',
        'description': '9~3ë´‰ì „ ìƒìŠ¹ì„¸, 3ë´‰ì „/2-1ë´‰ì „ êµì°¨ íŒ¨í„´',
        'uptrend_start_candle': '9',
        'uptrend_end_candle': '3',
        'cross_pattern_start': '3',
        'cross_pattern_length': '3',
        'min_price_increase': '5.0',
        'max_price_increase': '15.0',
        'min_profit_margin': '8.0'
    }
    
    # ì¶”ê°€2 ì¡°ê±´ (ì¡°ê±´ ì„¸íŠ¸ 3)
    config['CONDITION_3'] = {
        'name': 'ì¶”ê°€2ì¡°ê±´',
        'description': '10~4ë´‰ì „ ìƒìŠ¹ì„¸, 4ë´‰ì „/3-1ë´‰ì „ êµì°¨ íŒ¨í„´',
        'uptrend_start_candle': '10',
        'uptrend_end_candle': '4',
        'cross_pattern_start': '4',
        'cross_pattern_length': '4',
        'min_price_increase': '5.0',
        'max_price_increase': '15.0',
        'min_profit_margin': '8.0'
    }
    
    # ê³µí†µ ì„¤ì •
    config['COMMON'] = {
        'max_workers': str(MAX_WORKERS),
        'chunk_size': str(CHUNK_SIZE),
        'trade_amount': '100000',
        'max_hold_days': '5',
        'tax_rate': '0.0023'
    }
    
    with open('backtest_config.ini', 'w', encoding='utf-8') as configfile:
        config.write(configfile)
    
    print("ê¸°ë³¸ ì„¤ì • íŒŒì¼ 'backtest_config.ini'ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

def detect_time_interval(df):
    """
    ë°ì´í„°ì˜ ì‹œê°„ ê°„ê²©ì„ ê°ì§€í•˜ëŠ” í•¨ìˆ˜
    """
    morning_data = df[df['date'].dt.hour == 9].copy()
    if morning_data.empty:
        return None, None
    
    morning_data = morning_data.sort_values('date')
    time_diffs = morning_data['date'].diff().dt.total_seconds() / 60
    most_common_interval = time_diffs.mode().iloc[0]
    start_time = morning_data['date'].min().time()
    
    return most_common_interval, start_time

def convert_to_daily(df):
    """
    ë¶„ë´‰ ë°ì´í„°ë¥¼ ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜ (15:10 ì»¬ëŸ¼ í¬í•¨)
    """
    interval, detected_start_time = detect_time_interval(df)
    
    if interval is None:
        print("09ì‹œ~10ì‹œ ì‚¬ì´ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    market_start = pd.Timestamp('09:00:00').time()
    market_end_full = pd.Timestamp('15:30:00').time()
    market_end_1510 = pd.Timestamp('15:10:00').time()
    
    df_full = df[
        (df['date'].dt.time >= market_start) & 
        (df['date'].dt.time <= market_end_full)
    ].copy()
    
    df_1510 = df[
        (df['date'].dt.time >= market_start) & 
        (df['date'].dt.time <= market_end_1510)
    ].copy()
    
    if df_full.empty or df_1510.empty:
        print("ê±°ë˜ ì‹œê°„ëŒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    # ì™„ì „í•œ ì¼ë´‰ ë°ì´í„° ìƒì„± (09:00~15:30)
    daily_df_full = df_full.groupby(df_full['date'].dt.date).agg({
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    }).reset_index()
    
    # 15:10ê¹Œì§€ ì¼ë´‰ ë°ì´í„° ìƒì„± (09:00~15:10)
    daily_df_1510 = df_1510.groupby(df_1510['date'].dt.date).agg({
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    }).reset_index()
    
    daily_df_1510 = daily_df_1510.rename(columns={
        'open': 'open_1510',
        'high': 'high_1510',
        'low': 'low_1510',
        'close': 'close_1510',
        'volume': 'volume_1510'
    })
    
    daily_df = pd.merge(daily_df_full, daily_df_1510, on='date', how='inner')
    daily_df['date'] = pd.to_datetime(daily_df['date'])
    daily_df = daily_df[daily_df['volume'] > 0]
    daily_df = daily_df.sort_values('date')
    
    return daily_df

def calculate_ema(data, period):
    """ì§€ìˆ˜ì´ë™í‰ê· (EMA) ê³„ì‚°"""
    return data.ewm(span=period, adjust=False).mean()

def calculate_ma50(daily_df):
    """50ì¼ ì´ë™í‰ê·  ê³„ì‚°"""
    daily_df['MA50'] = daily_df['close'].rolling(window=50).mean()
    return daily_df

def check_conditions(daily_df, condition_set=1):
    """
    ì„¤ì • íŒŒì¼ì˜ ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜
    """
    config = load_config()
    condition_key = f'CONDITION_{condition_set}'
    
    if condition_key not in config:
        print(f"ì¡°ê±´ ì„¸íŠ¸ {condition_set}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    condition = config[condition_key]
    common = config['COMMON']
    
    # ì„¤ì •ì—ì„œ ê°’ ì½ê¸° (ì•ˆì „í•˜ê²Œ)
    uptrend_start = int(safe_get_config(config, condition_key, 'uptrend_start_candle', 8))
    uptrend_end = int(safe_get_config(config, condition_key, 'uptrend_end_candle', 2))
    cross_start = int(safe_get_config(config, condition_key, 'cross_pattern_start', 2))
    cross_length = int(safe_get_config(config, condition_key, 'cross_pattern_length', 2))
    min_increase = float(safe_get_config(config, condition_key, 'min_price_increase', 5.0))
    max_increase = float(safe_get_config(config, condition_key, 'max_price_increase', 15.0))
    min_profit = float(safe_get_config(config, condition_key, 'min_profit_margin', 8.0))
    
    # EMA ê³„ì‚°
    daily_df['EMA22'] = calculate_ema(daily_df['close'], 22)
    daily_df['EMA60'] = calculate_ema(daily_df['close'], 60)
    daily_df['EMA120'] = calculate_ema(daily_df['close'], 120)
    daily_df['MA22'] = daily_df['close'].rolling(window=22).mean()
    daily_df['MA22_1510'] = daily_df['close_1510'].rolling(window=22).mean()
    daily_df['recent_high_1510'] = daily_df['close_1510'].rolling(window=10).max()
    
    valid_dates = []
    
    for idx in range(120, len(daily_df)):
        current_row = daily_df.iloc[idx]
        prev_row = daily_df.iloc[idx-1]
        
        try:
            # ì¡°ê±´ 1: ê³¼ê±° ìƒìŠ¹ì„¸ í™•ì¸ (ì„¤ì • ê¸°ë°˜)
            condition_1 = all(
                daily_df.iloc[idx-i]['close'] > daily_df.iloc[idx-i]['EMA22']
                for i in range(uptrend_end, uptrend_start + 1)
            )
            
            # ì¡°ê±´ 2: 1ë´‰ì „ EMA22 > EMA60 > EMA120
            condition_2 = (
                prev_row['EMA22'] > prev_row['EMA60'] > prev_row['EMA120']
            )
            
            # ì¡°ê±´ 3: êµì°¨ íŒ¨í„´ (ì„¤ì • ê¸°ë°˜)
            condition_3 = True
            
            if cross_length == 2:  # ê¸°ì¡´ì¡°ê±´
                prev2_row = daily_df.iloc[idx-2]
                condition_3a = (
                    prev2_row['close'] > prev2_row['EMA22'] > prev2_row['EMA120']
                )
                condition_3b = (
                    prev_row['EMA22'] > prev_row['close'] > prev_row['EMA120']
                )
                condition_3 = condition_3a and condition_3b
                
            elif cross_length == 3:  # ì¶”ê°€1ì¡°ê±´
                prev3_row = daily_df.iloc[idx-3]
                prev2_row = daily_df.iloc[idx-2]
                condition_3a = (
                    prev3_row['close'] > prev3_row['EMA22'] > prev3_row['EMA120']
                )
                condition_3b = (
                    prev2_row['EMA22'] > prev2_row['close'] > prev2_row['EMA120']
                )
                condition_3c = (
                    prev_row['EMA22'] > prev_row['close'] > prev_row['EMA120']
                )
                condition_3 = condition_3a and condition_3b and condition_3c
                
            elif cross_length == 4:  # ì¶”ê°€2ì¡°ê±´
                prev4_row = daily_df.iloc[idx-4]
                prev3_row = daily_df.iloc[idx-3]
                prev2_row = daily_df.iloc[idx-2]
                condition_3a = (
                    prev4_row['close'] > prev4_row['EMA22'] > prev4_row['EMA120']
                )
                condition_3b = (
                    prev3_row['EMA22'] > prev3_row['close'] > prev3_row['EMA120']
                )
                condition_3c = (
                    prev2_row['EMA22'] > prev2_row['close'] > prev2_row['EMA120']
                )
                condition_3d = (
                    prev_row['EMA22'] > prev_row['close'] > prev_row['EMA120']
                )
                condition_3 = condition_3a and condition_3b and condition_3c and condition_3d
            
            # ì¡°ê±´ 4: ê¸°ì¤€ì¼ close_1510 > MA22_1510 (ëŒíŒŒ)
            condition_4 = (
                current_row['close_1510'] > current_row['MA22_1510']
            )
            
            # ì¡°ê±´ 5: ê¸°ì¤€ì¼ ìµœê·¼10ë´‰ìµœê³ ê°€ < (close_1510 * 1.3)
            condition_5 = (
                current_row['recent_high_1510'] < (current_row['close_1510'] * 1.3)
            )
            
            # ì¡°ê±´ 6: ê¸°ì¤€ì¼ ìƒìŠ¹ë¥  (ì„¤ì • ê¸°ë°˜)
            price_increase = (current_row['close_1510'] / prev_row['close'] - 1) * 100
            condition_6 = min_increase <= price_increase <= max_increase
            
            # ì¡°ê±´ 7: ìµì ˆê°€ê°€ ë§¤ìˆ˜ê°€ë³´ë‹¤ ì„¤ì •% ì´ìƒ ë†’ìŒ
            candle_center = (current_row['open_1510'] + current_row['close_1510']) / 2
            buy_price = current_row['close_1510']
            stop_loss = current_row['MA50']
            
            if pd.isna(stop_loss):
                continue
                
            if candle_center > stop_loss:
                take_profit = candle_center + ((candle_center - stop_loss) * 1.5)
            else:
                take_profit = buy_price * 1.05
                
            if take_profit <= buy_price:
                take_profit = buy_price * 1.05
                
            condition_7 = take_profit >= buy_price * (1 + min_profit / 100)
            
            # ëª¨ë“  ì¡°ê±´ ë§Œì¡± ì‹œ í•´ë‹¹ ë‚ ì§œ ì¶”ê°€
            if (condition_1 and condition_2 and condition_3 and 
                condition_4 and condition_5 and condition_6 and condition_7):
                valid_dates.append(current_row['date'].strftime('%Y-%m-%d'))
                
        except Exception as e:
            continue
    
    return valid_dates

def calculate_exit_prices(buy_row):
    """ë§¤ìˆ˜ì¼ ê¸°ì¤€ìœ¼ë¡œ ì†ì ˆê°€ì™€ ìµì ˆê°€ ê³„ì‚°"""
    candle_center = (buy_row['open_1510'] + buy_row['close_1510']) / 2
    buy_price = buy_row['close_1510']
    stop_loss = buy_row['MA50']
    
    if candle_center > stop_loss:
        take_profit = candle_center + ((candle_center - stop_loss) * 1.5)
    else:
        take_profit = buy_price * 1.05
        
    if take_profit <= buy_price:
        take_profit = buy_price * 1.05
    
    return stop_loss, take_profit

def check_exit_conditions_minute_data(minute_df, buy_date, stop_loss, take_profit, max_hold_days=5):
    """5ë¶„ë´‰ ë°ì´í„°ë¡œ ë§¤ë„ ì¡°ê±´ ì²´í¬"""
    buy_date = pd.to_datetime(buy_date)
    start_date = buy_date + pd.Timedelta(days=1)
    end_date = buy_date + pd.Timedelta(days=max_hold_days)
    
    sell_period = minute_df[
        (minute_df['date'].dt.date >= start_date.date()) &
        (minute_df['date'].dt.date <= end_date.date())
    ].copy()
    
    if sell_period.empty:
        return None, None, "ë°ì´í„°ì—†ìŒ"
    
    for day_num, (date, day_data) in enumerate(sell_period.groupby(sell_period['date'].dt.date), 1):
        day_data = day_data.sort_values('date')
        
        for _, row in day_data.iterrows():
            if row['high'] >= take_profit:
                return pd.to_datetime(date), take_profit, "ìµì ˆ"
            if row['low'] <= stop_loss:
                return pd.to_datetime(date), stop_loss, "ì†ì ˆ"
        
        if day_num >= max_hold_days:
            last_close = day_data.iloc[-1]['close']
            return pd.to_datetime(date), last_close, "ê°•ì œë§¤ë„"
    
    return None, None, "ë¯¸ë§¤ë„"

def backtest_strategy(daily_df, minute_df, valid_dates):
    """ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰"""
    daily_df = calculate_ma50(daily_df)
    results = []
    
    for date_str in valid_dates:
        try:
            buy_date = pd.to_datetime(date_str)
            buy_day_data = daily_df[daily_df['date'].dt.date == buy_date.date()]
            if buy_day_data.empty:
                continue
                
            buy_row = buy_day_data.iloc[0]
            
            if pd.isna(buy_row['MA50']):
                continue
            
            buy_price = buy_row['close_1510']
            stop_loss, take_profit = calculate_exit_prices(buy_row)
            
            sell_date, sell_price, sell_reason = check_exit_conditions_minute_data(
                minute_df, buy_date, stop_loss, take_profit
            )
            
            if sell_date is not None and sell_price is not None:
                hold_days = (sell_date - buy_date).days
                
                result = {
                    'ì¢…ëª©ë²ˆí˜¸': buy_row.get('code', 'Unknown'),
                    'ë§¤ìˆ˜ì¼': buy_date.strftime('%Y-%m-%d'),
                    'ë§¤ìˆ˜ê°’': round(buy_price, 0),
                    'ìµì ˆê°€(ëª©í‘œ)': round(take_profit, 0),
                    'ì†ì ˆê°€(ëª©í‘œ)': round(stop_loss, 0),
                    'ë§¤ë„ì¼': sell_date.strftime('%Y-%m-%d'),
                    'ë§¤ë„ê°’': round(sell_price, 0),
                    'ë³´ìœ ê¸°ê°„': hold_days,
                    'ì†ì ˆìµì ˆ': sell_reason,
                    'ìˆ˜ìµë¥ ': round(((sell_price / buy_price) - 1) * 100, 2)
                }
                results.append(result)
                
        except Exception as e:
            continue
    
    return pd.DataFrame(results)

def process_single_file_all_conditions(file, selected_folder):
    """ë‹¨ì¼ íŒŒì¼ì„ ëª¨ë“  ì¡°ê±´ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    try:
        with open(file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if 'meta' not in data or 'data' not in data:
            return {
                'code': file.name,
                'error': 'JSON íŒŒì¼ êµ¬ì¡° ì˜¤ë¥˜',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        
        code = data['meta'].get('code', file.name)
        chart_data = data['data']
        
        if not chart_data:
            return {
                'code': code,
                'error': 'ì°¨íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        
        df = pd.DataFrame(chart_data)
        required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            return {
                'code': code,
                'error': f'í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        
        try:
            df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d%H%M')
        except Exception as date_error:
            try:
                df['date'] = pd.to_datetime(df['date'])
            except Exception:
                return {
                    'code': code,
                    'error': f'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì˜¤ë¥˜: {str(date_error)}',
                    'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }
        
        df = df[required_columns]
        daily_df = convert_to_daily(df)
        
        if daily_df.empty:
            return {
                'code': code,
                'condition_1': {'valid_dates': []},
                'condition_2': {'valid_dates': []},
                'condition_3': {'valid_dates': []},
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        
        daily_df['code'] = code
        result = {
            'code': code,
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # ê° ì¡°ê±´ë³„ë¡œ ê²€ìƒ‰ ë° ë°±í…ŒìŠ¤íŒ… ìˆ˜í–‰
        for condition_set in [1, 2, 3]:
            condition_key = f'condition_{condition_set}'
            valid_dates = check_conditions(daily_df, condition_set)
            condition_result = {'valid_dates': valid_dates if valid_dates else []}
            
            if valid_dates:
                backtest_df = backtest_strategy(daily_df, df, valid_dates)
                
                if not backtest_df.empty:
                    backtest_df['ì¢…ëª©ë²ˆí˜¸'] = code
                    backtest_file = save_backtest_results_integrated(
                        backtest_df, selected_folder, code, condition_set
                    )
                    
                    condition_result['backtest_result'] = {
                        'total_trades': len(backtest_df),
                        'win_rate': len(backtest_df[backtest_df['ìˆ˜ìµë¥ '] > 0]) / len(backtest_df) * 100 if len(backtest_df) > 0 else 0,
                        'avg_return': backtest_df['ìˆ˜ìµë¥ '].mean() if len(backtest_df) > 0 else 0,
                        'file_saved': backtest_file.name if backtest_file else None
                    }
            
            result[condition_key] = condition_result
        
        return result
        
    except Exception as e:
        return {
            'code': file.name,
            'error': f'íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}',
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

def process_chunk_all_conditions(chunk_files, selected_folder):
    """ëª¨ë“  ì¡°ê±´ìœ¼ë¡œ íŒŒì¼ ì²­í¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    chunk_results = []
    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_file = {
            executor.submit(process_single_file_all_conditions, file, selected_folder): file 
            for file in chunk_files
        }
        
        for future in future_to_file:
            result = future.result()
            if result:
                chunk_results.append(result)
    
    return chunk_results

def save_backtest_results_integrated(results_df, folder_path, stock_code, condition_set):
    """í†µí•© ë°±í…ŒìŠ¤íŒ…ìš© ê²°ê³¼ ì €ì¥ í•¨ìˆ˜"""
    if results_df.empty:
        return None
    
    config = load_config()
    condition_key = f'CONDITION_{condition_set}'
    condition_name = safe_get_config(config, condition_key, 'name', f'ì¡°ê±´{condition_set}')
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backtest_dir = folder_path / 'backtest_integrated'
    backtest_dir.mkdir(exist_ok=True)
    
    excel_file = backtest_dir / f"backtest_{stock_code}_{condition_name}_{timestamp}.xlsx"
    
    total_trades = len(results_df)
    win_trades = len(results_df[results_df['ìˆ˜ìµë¥ '] > 0])
    win_rate = (win_trades / total_trades * 100) if total_trades > 0 else 0
    avg_return = results_df['ìˆ˜ìµë¥ '].mean() if total_trades > 0 else 0
    
    stats_df = pd.DataFrame({
        'í•­ëª©': ['ì´ ê±°ë˜ìˆ˜', 'ìˆ˜ìµ ê±°ë˜', 'ì†ì‹¤ ê±°ë˜', 'ìŠ¹ë¥ (%)', 'í‰ê·  ìˆ˜ìµë¥ (%)', 'ì¡°ê±´ì„¸íŠ¸'],
        'ê°’': [total_trades, win_trades, total_trades - win_trades, round(win_rate, 2), round(avg_return, 2), condition_name]
    })
    
    with pd.ExcelWriter(excel_file) as writer:
        results_df.to_excel(writer, sheet_name='ê±°ë˜ë‚´ì—­', index=False)
        stats_df.to_excel(writer, sheet_name='í†µê³„', index=False)
    
    return excel_file

def combine_integrated_results(all_results, folder_path):
    """ëª¨ë“  ì¡°ê±´ì˜ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ì—‘ì…€ íŒŒì¼ë¡œ í†µí•©"""
    backtest_dir = folder_path / 'backtest_integrated'
    if not backtest_dir.exists():
        return None
    
    config = load_config()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    final_file = backtest_dir / f"TOTAL_í†µí•©ë°±í…ŒìŠ¤íŒ…ê²°ê³¼_{timestamp}.xlsx"
    
    all_condition_data = {}
    
    for condition_set in [1, 2, 3]:
        condition_key = f'CONDITION_{condition_set}'
        condition_name = safe_get_config(config, condition_key, 'name', f'ì¡°ê±´{condition_set}')
        
        excel_files = list(backtest_dir.glob(f'backtest_*{condition_name}*.xlsx'))
        combined_trades = []
        total_stats = {'total_trades': 0, 'win_trades': 0, 'total_return': 0, 'stock_count': 0}
        
        for excel_file in excel_files:
            try:
                trades_df = pd.read_excel(excel_file, sheet_name='ê±°ë˜ë‚´ì—­')
                if not trades_df.empty:
                    combined_trades.append(trades_df)
                    total_stats['total_trades'] += len(trades_df)
                    total_stats['win_trades'] += len(trades_df[trades_df['ìˆ˜ìµë¥ '] > 0])
                    total_stats['total_return'] += trades_df['ìˆ˜ìµë¥ '].sum()
                    total_stats['stock_count'] += 1
            except Exception as e:
                continue
        
        if combined_trades:
            condition_trades = pd.concat(combined_trades, ignore_index=True)
            condition_trades = condition_trades.sort_values(['ì¢…ëª©ë²ˆí˜¸', 'ë§¤ìˆ˜ì¼'])
            
            win_rate = (total_stats['win_trades'] / total_stats['total_trades'] * 100) if total_stats['total_trades'] > 0 else 0
            avg_return = total_stats['total_return'] / total_stats['total_trades'] if total_stats['total_trades'] > 0 else 0
            
            condition_summary = pd.DataFrame({
                'í•­ëª©': ['ì¢…ëª© ìˆ˜', 'ì´ ê±°ë˜ìˆ˜', 'ìˆ˜ìµ ê±°ë˜', 'ì†ì‹¤ ê±°ë˜', 'ìŠ¹ë¥ (%)', 'í‰ê·  ìˆ˜ìµë¥ (%)'],
                'ê°’': [
                    total_stats['stock_count'], total_stats['total_trades'], total_stats['win_trades'],
                    total_stats['total_trades'] - total_stats['win_trades'], round(win_rate, 2), round(avg_return, 2)
                ]
            })
            
            all_condition_data[condition_name] = {
                'trades': condition_trades,
                'summary': condition_summary
            }
    
    if all_condition_data:
        with pd.ExcelWriter(final_file) as writer:
            for condition_name, data in all_condition_data.items():
                data['trades'].to_excel(writer, sheet_name=f'{condition_name}_ê±°ë˜ë‚´ì—­', index=False)
                data['summary'].to_excel(writer, sheet_name=f'{condition_name}_ìš”ì•½', index=False)
            
            overall_summary = []
            for condition_name, data in all_condition_data.items():
                summary_data = data['summary']
                row_data = {'ì¡°ê±´': condition_name}
                for _, row in summary_data.iterrows():
                    row_data[row['í•­ëª©']] = row['ê°’']
                overall_summary.append(row_data)
            
            if overall_summary:
                overall_df = pd.DataFrame(overall_summary)
                overall_df.to_excel(writer, sheet_name='ì „ì²´ìš”ì•½', index=False)
        
        return final_file
    return None

def cleanup_temp_files(folder_path):
    """ì„ì‹œ íŒŒì¼ë“¤ì„ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    backtest_dir = folder_path / 'backtest_integrated'
    if not backtest_dir.exists():
        return
    
    temp_files = [f for f in backtest_dir.glob('*.xlsx') if not f.name.startswith('TOTAL_')]
    deleted_count = 0
    
    for temp_file in temp_files:
        try:
            temp_file.unlink()
            deleted_count += 1
        except Exception as e:
            print(f"íŒŒì¼ {temp_file.name} ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    print(f"ì„ì‹œ íŒŒì¼ {deleted_count}ê°œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

def execute_integrated_backtest():
    """í†µí•© ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ í•¨ìˆ˜"""
    global MAX_WORKERS, CHUNK_SIZE
    
    # ì„¤ì • ë¡œë“œ
    config = load_config()
    common = config['COMMON']
    MAX_WORKERS = int(safe_get_config(config, 'COMMON', 'max_workers', 10))
    CHUNK_SIZE = int(safe_get_config(config, 'COMMON', 'chunk_size', 20))
    
    print("\n=== í†µí•© ë°±í…ŒìŠ¤íŒ… í”„ë¡œê·¸ë¨ ===")
    print("ì„¤ì • íŒŒì¼ì—ì„œ ì¡°ê±´ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    
    # í´ë” ì„ íƒ
    base_dir = Path('json_data')
    if not base_dir.exists():
        print("json_data í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
        
    folders = [f for f in base_dir.iterdir() if f.is_dir()]
    if not folders:
        print("ë¶„ì„í•  ë°ì´í„° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    print("\n=== ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° í´ë” ===")
    for idx, folder in enumerate(folders, 1):
        print(f"{idx}. {folder.name}")
    
    while True:
        try:
            folder_choice = int(input("\në¶„ì„í•  í´ë” ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: "))
            if 1 <= folder_choice <= len(folders):
                selected_folder = folders[folder_choice - 1]
                break
            else:
                print(f"1ë¶€í„° {len(folders)}ê¹Œì§€ì˜ ë²ˆí˜¸ë§Œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        except ValueError:
            print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    # íŒŒì¼ ì²˜ë¦¬
    json_files = list(selected_folder.glob('*.json'))
    if not json_files:
        print("ì„ íƒí•œ í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    print(f"\n=== {selected_folder.name} í´ë” ë¶„ì„ ì‹œì‘ ===")
    print(f"ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(json_files)}")
    print(f"ì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ìˆ˜: {MAX_WORKERS}")
    print(f"ê²€ìƒ‰ ì¡°ê±´: ëª¨ë“  ì¡°ê±´ ë™ì‹œ ì²˜ë¦¬")
    
    # ì¡°ê±´ ì •ë³´ ì¶œë ¥
    for i in [1, 2, 3]:
        condition_key = f'CONDITION_{i}'
        condition_name = safe_get_config(config, condition_key, 'name', f'ì¡°ê±´{i}')
        condition_desc = safe_get_config(config, condition_key, 'description', f'ì¡°ê±´{i} ì„¤ëª…')
        print(f"  - {condition_name}: {condition_desc}")
    
    file_chunks = [json_files[i:i + CHUNK_SIZE] for i in range(0, len(json_files), CHUNK_SIZE)]
    all_results = []
    
    with tqdm(total=len(json_files), desc="í†µí•© ë°±í…ŒìŠ¤íŒ… ì§„í–‰ ì¤‘") as pbar:
        for chunk in file_chunks:
            chunk_results = process_chunk_all_conditions(chunk, selected_folder)
            all_results.extend(chunk_results)
            pbar.update(len(chunk))
    
    # ê²°ê³¼ ë¶„ì„
    print("\n=== ë¶„ì„ ê²°ê³¼ ===")
    success_count = 0
    error_count = 0
    
    condition_stats = {}
    for i in [1, 2, 3]:
        condition_key = f'CONDITION_{i}'
        condition_name = safe_get_config(config, condition_key, 'name', f'ì¡°ê±´{i}')
        condition_stats[i] = {'ì¢…ëª©ìˆ˜': 0, 'ê±°ë˜ìˆ˜': 0, 'ì¡°ê±´ëª…': condition_name}
    
    for result in all_results:
        if 'error' in result:
            error_count += 1
        else:
            success_count += 1
            for condition_set in [1, 2, 3]:
                condition_result = result.get(f'condition_{condition_set}', {})
                if condition_result.get('valid_dates'):
                    condition_stats[condition_set]['ì¢…ëª©ìˆ˜'] += 1
                    backtest_result = condition_result.get('backtest_result')
                    if backtest_result:
                        condition_stats[condition_set]['ê±°ë˜ìˆ˜'] += backtest_result['total_trades']
    
    print(f"ì²˜ë¦¬ ì™„ë£Œ: ì´ {len(all_results)}ê°œ íŒŒì¼")
    print(f"ì„±ê³µ: {success_count}ê°œ, ì‹¤íŒ¨: {error_count}ê°œ")
    
    print("\n=== ì¡°ê±´ë³„ ê²°ê³¼ ìš”ì•½ ===")
    for condition_set, stats in condition_stats.items():
        print(f"{stats['ì¡°ê±´ëª…']}: {stats['ì¢…ëª©ìˆ˜']}ê°œ ì¢…ëª©, {stats['ê±°ë˜ìˆ˜']}ê±´ ê±°ë˜")
    
    # í†µí•© ê²°ê³¼ íŒŒì¼ ìƒì„±
    if success_count > 0:
        print("\ní†µí•© ê²°ê³¼ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        final_file = combine_integrated_results(all_results, selected_folder)
        if final_file:
            print(f"âœ… ìµœì¢… í†µí•© ê²°ê³¼: {final_file.name}")
            cleanup_temp_files(selected_folder)
            print("ğŸ“ ì„ì‹œ íŒŒì¼ë“¤ì´ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("ìƒì„±í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    while True:
        print("\n=== í†µí•© ë°±í…ŒìŠ¤íŒ… í”„ë¡œê·¸ë¨ ===")
        print("1. í†µí•© ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰")
        print("2. ì„¤ì • íŒŒì¼ í™•ì¸/ìˆ˜ì •")
        print("9. í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
        
        choice = input("\në©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš” (1,2,9): ")
        
        if choice == '1':
            execute_integrated_backtest()
        elif choice == '2':
            print("\nì„¤ì • íŒŒì¼ ìœ„ì¹˜: backtest_config.ini")
            print("ë©”ëª¨ì¥ì´ë‚˜ í…ìŠ¤íŠ¸ ì—ë””í„°ë¡œ ìˆ˜ì • í›„ í”„ë¡œê·¸ë¨ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
            input("ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ê³„ì†...")
        elif choice == '9':
            print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        else:
            print("\nì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main() 