import os
import sqlite3
from datetime import datetime
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")
import time
from pathlib import Path
import json
### TA íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•œ ë³¼ë¦°ì ¸ ë°´ë“œ ê³„ì‚° í•¨ìˆ˜
import ta
#from ta.volatility import BollingerBands
#from ta.Trend import EMAIndicator
#from ta import add_all_ta_features
#from ta.Trend import ADXIndicator
from pykrx import stock
from exchange_calendars import get_calendar
import multiprocessing
from concurrent.futures import ProcessPoolExecutor
from functools import partial
from tqdm import tqdm

import matplotlib.pyplot as plt


# í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
current_datetime = datetime.now()
formatted_date = current_datetime.strftime("%m%d-%H%M")
excel_filename = formatted_date + ".xlsx"


total_result_df_all = pd.DataFrame()
total_result_df_all.name = 'total_result_df_all'
total_result_df = pd.DataFrame()
total_result_df.name = 'total_result_df'

#ì¼ë´‰ ë“± ë°ì´í„° ë¶ˆëŸ¬ì˜¬ ê¸°ì¤€ ë‚ ì§œ.
krx_calendar = get_calendar("XKRX")

############################################################


# ì´ˆê¸° ì„¤ì •
Total_result2 = pd.DataFrame(columns=['Stock Code', 'Plus Count', 'Minus Count', 'Total Rows', 'Total Profit'])
Total_result3 = pd.DataFrame(columns=['date', 'table_name', 'buy_price', 'sell_price', 'result', 'profit'])
tables_count = 0

# ì „ì—­ ë³€ìˆ˜ë¡œ í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì„¤ì •
MAX_WORKERS = 8  # ê¸°ë³¸ê°’ ì„¤ì •
CHUNK_SIZE = 20  # í•œ ë²ˆì— ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜

def save_results(results, folder_path, condition_set=1):
    """
    ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ (ìœ íš¨í•œ ê²°ê³¼ë§Œ ì €ì¥)
    
    :param results: ì €ì¥í•  ê²°ê³¼ ë°ì´í„°
    :param folder_path: ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ê²½ë¡œ
    :param condition_set: ì‚¬ìš©ëœ ì¡°ê±´ ì„¸íŠ¸ ë²ˆí˜¸
    :return: ì €ì¥ëœ íŒŒì¼ì˜ ê²½ë¡œ ë˜ëŠ” None (ì €ì¥í•  ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°)
    """
    # valid_datesê°€ ìˆëŠ” ê²°ê³¼ë§Œ í•„í„°ë§
    valid_results = [result for result in results if result.get('valid_dates')]
    
    # ì €ì¥í•  ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ íŒŒì¼ì„ ì €ì¥í•˜ì§€ ì•ŠìŒ
    if not valid_results:
        print("ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë‚ ì§œê°€ ë°œê²¬ëœ ì¢…ëª©ì´ ì—†ì–´ íŒŒì¼ì„ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    folder_name = folder_path.name
    
    # ê²°ê³¼ë¥¼ ì €ì¥í•  results í´ë” ìƒì„±
    result_dir = folder_path / 'results'
    result_dir.mkdir(exist_ok=True)
    
    # ì¡°ê±´ ì„¸íŠ¸ ì´ë¦„ ë§¤í•‘
    condition_names = {
        1: "ê¸°ì¡´ì¡°ê±´",
        2: "ì¶”ê°€1ì¡°ê±´", 
        3: "ì¶”ê°€2ì¡°ê±´"
    }
    condition_name = condition_names.get(condition_set, "ì•Œìˆ˜ì—†ìŒ")
    
    # ë” íš¨ìœ¨ì ì¸ JSON êµ¬ì¡°ë¡œ ë³€í™˜
    efficient_results = {
        "analysis_info": {
            "timestamp": timestamp,
            "folder": folder_name,
            "condition_set": condition_set,
            "condition_name": condition_name,
            "total_stocks_found": len(valid_results),
            "total_valid_dates": sum(len(result.get('valid_dates', [])) for result in valid_results)
        },
        "stocks": {}
    }
    
    # ì¢…ëª©ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì €ì¥
    for result in valid_results:
        code = result.get('code', '')
        if code not in efficient_results["stocks"]:
            efficient_results["stocks"][code] = {
                "dates": result.get('valid_dates', []),
                "file_source": result.get('file_name', ''),
                "processed_time": result.get('processed_time', '')
            }
        else:
            # ê°™ì€ ì¢…ëª©ì´ ì—¬ëŸ¬ ë²ˆ ë‚˜íƒ€ë‚  ê²½ìš° ë‚ ì§œ ë³‘í•© (ì¤‘ë³µ ì œê±°)
            existing_dates = set(efficient_results["stocks"][code]["dates"])
            new_dates = set(result.get('valid_dates', []))
            efficient_results["stocks"][code]["dates"] = sorted(list(existing_dates | new_dates))
    
    result_file = result_dir / f"analysis_result_{folder_name}_{condition_name}_{timestamp}.json"
    
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(efficient_results, f, ensure_ascii=False, indent=2)
    
    print(f"ìœ íš¨í•œ ê²°ê³¼ {len(valid_results)}ê°œ ì¢…ëª©ì„ {result_file.name}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    return result_file

def process_table(code_num, df):
    print(code_num)
    table_name = code_num
    
    # ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜
    daily_df = convert_to_daily(df)
    
    if not daily_df.empty:
        # ì¡°ê±´ ê²€ìƒ‰
        valid_dates = check_conditions(daily_df)
        
        if valid_dates:
            print(f"\n{code_num} ì¢…ëª©ì˜ ì¡°ê±´ ë§Œì¡± ë‚ ì§œ:")
            for date in valid_dates:
                print(date)
    
    return

#ê°œì¥ì¼ ê¸°ì¤€ -Xì¼ êµ¬í•˜ëŠ”ê±°. í…ŒìŠ¤íŠ¸
def delta_days(days):
    
    xkrx_calendar = get_calendar('XKRX')
    
    start_date = datetime.datetime.now()
    end_date = start_date - days * xkrx_calendar.day  # ì£¼ì‹ ê°œì¥ì¼ ê¸°ì¤€ 250ì¼ ì´ì „
    end_date = end_date.strftime("%Y%m%d")
    
    return end_date

### ë¶„ë´‰ ë°ì´í„°ë¥¼ ë” í° ì‹œê°„ ë‹¨ìœ„ë¡œ ë³€í™˜
def resample_candles(df, multiplier):
    """
    ë¶„ë´‰ ë°ì´í„°ë¥¼ ë” í° ì‹œê°„ ë‹¨ìœ„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ë¶ˆì™„ì „í•œ ë´‰(ë°ì´í„°ê°€ ë¶€ì¡±í•œ ì²«/ë§ˆì§€ë§‰ ë´‰)ì€ ì œê±°í•©ë‹ˆë‹¤.
    
    :param df: pandas DataFrame, 'date' ì—´ì´ datetime í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    :param multiplier: ë³€í™˜í•  ì‹œê°„ ë‹¨ìœ„ì˜ ë°°ìˆ˜ (ì˜ˆ: 1ë¶„ë´‰ì—ì„œ 3ë¶„ë´‰ìœ¼ë¡œ ë³€í™˜í•  ë•ŒëŠ” 3)
    :return: ë³€í™˜ëœ DataFrame
    """
    # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ë³µì‚¬
    df_copy = df.copy()
    
    # 'date' ì—´ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì´ë¯¸ ë³€í™˜ë˜ì–´ ìˆì„ ìˆ˜ë„ ìˆìŒ)
    if not pd.api.types.is_datetime64_any_dtype(df_copy['date']):
        df_copy['date'] = pd.to_datetime(df_copy['date'], format='%Y%m%d%H%M')

    # datetimeì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
    df_copy.set_index('date', inplace=True)
    
    # ë°ì´í„° ì •ë ¬ (ì‹œê°„ìˆœ)
    df_copy = df_copy.sort_index()
    
    # ì§€ì •ëœ ì‹œê°„ ë‹¨ìœ„ë¡œ ë°ì´í„° ì¬êµ¬ì„±
    resampled_df = df_copy.resample(f'{multiplier}T').agg({
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    })
    
    # NaN ê°’ì´ ìˆëŠ” í–‰ ì œê±° (ë¶ˆì™„ì „í•œ ë´‰ ì œê±°)
    # open, high, low, close ì¤‘ í•˜ë‚˜ë¼ë„ NaNì´ë©´ í•´ë‹¹ ë´‰ì€ ë¶ˆì™„ì „í•¨
    resampled_df = resampled_df.dropna(subset=['open', 'high', 'low', 'close'])
    
    # ê±°ë˜ëŸ‰ì´ 0ì¸ ë´‰ë„ ì œê±°
    resampled_df = resampled_df[resampled_df['volume'] > 0]
    
    # ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
    resampled_df.reset_index(inplace=True)
    
    print(f"ë¦¬ìƒ˜í”Œë§ ì™„ë£Œ: {len(df)}ë´‰ -> {len(resampled_df)}ë´‰ (ë°°ìˆ˜: {multiplier})")
    
    return resampled_df

### RSI ê³„ì‚° í•¨ìˆ˜
def calculate_rsi(data, period=12):
    delta = data['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()

    rs = gain / loss
    rsi = round(100 - (100 / (1 + rs)), 1)
    return rsi

def TA_bol_band(data, Period=20, num_of_std=2):
    '''
    TA íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•˜ì—¬ ë³¼ë¦°ì ¸ ë°´ë“œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    :param data: pandas DataFrame, 'close' ì—´ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    :param Period: ì´ë™ í‰ê· ì„ ê³„ì‚°í•  ê¸°ê°„.
    :param num_of_std: í‘œì¤€í¸ì°¨ì˜ ë°°ìˆ˜.
    :return: ë³¼ë¦°ì ¸ ë°´ë“œê°€ ì¶”ê°€ëœ DataFrame.
    '''
    middle_band_label = 'BB_M_' + str(Period)
    upper_band_label = 'BB_H_' + str(Period)
    lower_band_label = 'BB_L_' + str(Period)
    Sum_BB_label = 'Sum_BB_' + str(Period)

    # TA íŒ¨í‚¤ì§€ì˜ BollingerBands ê¸°ëŠ¥ì„ ì´ìš©
    indicator_bb = ta.volatility.BollingerBands(close=data['close'], window=Period, window_dev=num_of_std)

    # ë³¼ë¦°ì ¸ ë°´ë“œ ê³„ì‚°
    BB_M = indicator_bb.bollinger_mavg()
    BB_H = indicator_bb.bollinger_hband()
    BB_L = indicator_bb.bollinger_lband()
    #data[middle_band_label] = round(BB_M, 2)
    data[upper_band_label] = round(BB_H, 2)
    data[lower_band_label] = round(BB_L, 2)

    # ë³¼ë¦°ì € ë°´ë“œì™€ ì¢…ê°€ì˜ ë°±ë¶„ìœ¨ ì°¨ì´ ê³„ì‚°
    high_diff_percent = abs((data['close'] - BB_H) / data['close']) * 100
    low_diff_percent = abs((data['close'] - BB_L) / data['close']) * 100
    Sum_BB = high_diff_percent + low_diff_percent
    data[Sum_BB_label] = round(Sum_BB, 2)


    return data

# ADX (Average Directional movement index)
def TA_ADX(data, Period=12):

    ADX_label = 'ADX_' + str(Period)
    

    # TA íŒ¨í‚¤ì§€ì˜ ADX ê¸°ëŠ¥ì„ ì´ìš©
    Indicator_ADX = ta.trend.ADXIndicator(high=data['high'], low=data['low'], close=data['close'], window=Period)

    # ADX ê³„ì‚°
    ADX = Indicator_ADX.adx()
    data[ADX_label] = round(ADX, 2)

    return data

def calculate_stochslow(data, k_period=18, d_period=5, k_period2=6):
    # ê¸°ì¡´ %K ê³„ì‚°ì„ ìœ„í•œ low_min, high_max
    low_min = data['low'].rolling(window=k_period).min()
    high_max = data['high'].rolling(window=k_period).max()

    # k_period2ë¥¼ ì‚¬ìš©í•œ ìƒˆë¡œìš´ low_min, high_max ê³„ì‚°
    low_min_sum = low_min.rolling(window=k_period2).sum()
    high_max_sum = high_max.rolling(window=k_period2).sum()

    # ìˆ˜ì •ëœ %K ê³„ì‚°
    data['%K'] = ((data['close'] - low_min_sum) / (high_max_sum - low_min_sum)) * 100

    # %D ê³„ì‚° (%Kì˜ ì´ë™ í‰ê· )
    data['%D'] = data['%K'].rolling(window=d_period).mean()

    return data

def tax(price):
    result = round(price*0.0023, 0)
    return result


def calculate_max_quantity(close_price, total_amount=100000):
    """
    ì£¼ì–´ì§„ ì¢…ê°€(close price)ì™€ ì´ ê¸ˆì•¡ì„ ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ€ ë§¤ìˆ˜ ìˆ˜ëŸ‰ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

    :param close_price: ë§¤ìˆ˜í•  ì£¼ì‹ì˜ ì¢…ê°€
    :param total_amount: ë§¤ìˆ˜ì— ì‚¬ìš©í•  ì´ ê¸ˆì•¡
    :return: ë§¤ìˆ˜í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ì£¼ì‹ ìˆ˜ëŸ‰
    """
    if close_price <= 0:
        return 0

    max_quantity = total_amount // close_price  # ì†Œìˆ˜ì  ì´í•˜ë¥¼ ë²„ë¦¬ê³  ì •ìˆ˜ ë¶€ë¶„ë§Œ ì·¨í•¨
    return max_quantity

def export_to_excel(df, file_name):
    """
    ì£¼ì–´ì§„ ë°ì´í„°í”„ë ˆì„ì„ Excel íŒŒì¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤.

    :param df: ë‚´ë³´ë‚¼ ë°ì´í„°í”„ë ˆì„
    :param file_name: ìƒì„±ë  Excel íŒŒì¼ì˜ ì´ë¦„ (í™•ì¥ì '.xlsx' í¬í•¨)
    """
    try:
        # ë°ì´í„°í”„ë ˆì„ì„ Excel íŒŒì¼ë¡œ ì €ì¥
        df.to_excel(file_name, index=False)
        print(f"{file_name}ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"Excel íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

def bol_dolpa(df):
    df['BB_H_12_per'] = ((df['BB_H_12']/df['close'])-1)*100
    df['BB_H_50_per'] = ((df['BB_H_50']/df['close'])-1)*100
    df['BB_H_100_per'] = ((df['BB_H_100']/df['close'])-1)*100 
    

def detect_time_interval(df):
    """
    ë°ì´í„°ì˜ ì‹œê°„ ê°„ê²©ì„ ê°ì§€í•˜ëŠ” í•¨ìˆ˜
    
    :param df: pandas DataFrame, 'date' ì—´ì´ datetime í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    :return: (ì‹œê°„ ê°„ê²©(ë¶„), ì‹œì‘ ì‹œê°„)
    """
    # 09ì‹œ~10ì‹œ ì‚¬ì´ì˜ ë°ì´í„°ë§Œ í•„í„°ë§
    morning_data = df[df['date'].dt.hour == 9].copy()
    if morning_data.empty:
        return None, None
    
    # ì‹œê°„ ì •ë ¬
    morning_data = morning_data.sort_values('date')
    
    # ì—°ì†ëœ í–‰ ê°„ì˜ ì‹œê°„ ì°¨ì´ ê³„ì‚°
    time_diffs = morning_data['date'].diff().dt.total_seconds() / 60
    
    # ê°€ì¥ ë¹ˆë²ˆí•œ ì‹œê°„ ê°„ê²© ì°¾ê¸°
    most_common_interval = time_diffs.mode().iloc[0]
    
    # ì‹œì‘ ì‹œê°„ ì°¾ê¸°
    start_time = morning_data['date'].min().time()
    
    return most_common_interval, start_time

def convert_to_daily(df):
    """
    ë¶„ë´‰ ë°ì´í„°ë¥¼ ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ê¸°ì¡´ ì¼ë´‰(09:00~15:30)ê³¼ ë§¤ë§¤ìš© ì¼ë´‰(09:00~15:10) ì»¬ëŸ¼ì„ ëª¨ë‘ ìƒì„±í•©ë‹ˆë‹¤.
    
    :param df: pandas DataFrame, 'date' ì—´ì´ datetime í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    :return: ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜ëœ DataFrame (15:10 ì»¬ëŸ¼ í¬í•¨)
    """
    # ì‹œê°„ ê°„ê²©ê³¼ ì‹œì‘ ì‹œê°„ ê°ì§€
    interval, detected_start_time = detect_time_interval(df)
    
    if interval is None:
        print("09ì‹œ~10ì‹œ ì‚¬ì´ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    # ê±°ë˜ ì‹œê°„ëŒ€ ì„¤ì •
    market_start = pd.Timestamp('09:00:00').time()
    market_end_full = pd.Timestamp('15:30:00').time()  # ì™„ì „í•œ ì¼ë´‰ìš©
    market_end_1510 = pd.Timestamp('15:10:00').time()  # ë§¤ë§¤ìš© ì¼ë´‰
    
    # ì „ì²´ ê±°ë˜ ì‹œê°„ëŒ€ ë°ì´í„° (09:00~15:30)
    df_full = df[
        (df['date'].dt.time >= market_start) & 
        (df['date'].dt.time <= market_end_full)
    ].copy()
    
    # 15:10ê¹Œì§€ ë°ì´í„° (09:00~15:10)  
    df_1510 = df[
        (df['date'].dt.time >= market_start) & 
        (df['date'].dt.time <= market_end_1510)
    ].copy()
    
    # ë°ì´í„°ê°€ ìˆëŠ”ì§€ë§Œ ê°„ë‹¨íˆ í™•ì¸
    if df_full.empty or df_1510.empty:
        print("ê±°ë˜ ì‹œê°„ëŒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    print(f"ì „ì²´ ë°ì´í„°: {len(df_full)}ê±´, 15:10ê¹Œì§€ ë°ì´í„°: {len(df_1510)}ê±´")
    
    # ì™„ì „í•œ ì¼ë´‰ ë°ì´í„° ìƒì„± (09:00~15:30)
    daily_df_full = df_full.groupby(df_full['date'].dt.date).agg({
        'open': 'first',    # ì‹œê°€: í•´ë‹¹ ë‚ ì§œì˜ ì²« ê°€ê²©
        'high': 'max',      # ê³ ê°€: í•´ë‹¹ ë‚ ì§œì˜ ìµœê³  ê°€ê²©
        'low': 'min',       # ì €ê°€: í•´ë‹¹ ë‚ ì§œì˜ ìµœì € ê°€ê²©
        'close': 'last',    # ì¢…ê°€: í•´ë‹¹ ë‚ ì§œì˜ ë§ˆì§€ë§‰ ê°€ê²©
        'volume': 'sum'     # ê±°ë˜ëŸ‰: í•´ë‹¹ ë‚ ì§œì˜ ì´ ê±°ë˜ëŸ‰
    }).reset_index()
    
    # 15:10ê¹Œì§€ ì¼ë´‰ ë°ì´í„° ìƒì„± (09:00~15:10)
    daily_df_1510 = df_1510.groupby(df_1510['date'].dt.date).agg({
        'open': 'first',    
        'high': 'max',      
        'low': 'min',       
        'close': 'last',    
        'volume': 'sum'     
    }).reset_index()
    
    # 15:10 ì»¬ëŸ¼ëª… ë³€ê²½
    daily_df_1510 = daily_df_1510.rename(columns={
        'open': 'open_1510',
        'high': 'high_1510',
        'low': 'low_1510',
        'close': 'close_1510',
        'volume': 'volume_1510'
    })
    
    # ë‘ ë°ì´í„°í”„ë ˆì„ ë³‘í•©
    daily_df = pd.merge(daily_df_full, daily_df_1510, on='date', how='inner')
    
    # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
    daily_df['date'] = pd.to_datetime(daily_df['date'])
    
    # ê±°ë˜ëŸ‰ì´ 0ì¸ ë‚ ì§œ ì œì™¸ (ì „ì²´ ê±°ë˜ëŸ‰ ê¸°ì¤€)
    daily_df = daily_df[daily_df['volume'] > 0]
    
    # ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬
    daily_df = daily_df.sort_values('date')
    
    print(f"ì¼ë´‰ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(daily_df)}ì¼")
    
    return daily_df

def calculate_ema(data, period):
    """
    ì§€ìˆ˜ì´ë™í‰ê· (EMA)ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    
    :param data: ê°€ê²© ë°ì´í„° Series
    :param period: EMA ê¸°ê°„
    :return: EMA Series
    """
    return data.ewm(span=period, adjust=False).mean()

def check_conditions(daily_df, condition_set=1):
    """
    ìˆ˜ì •ëœ ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜ (ë‹¹ì¼ì€ 15:10 ë°ì´í„° ì‚¬ìš©)
    
    :param daily_df: ì¼ë´‰ ë°ì´í„° DataFrame (15:10 ì»¬ëŸ¼ í¬í•¨)
    :param condition_set: ì¡°ê±´ ì„¸íŠ¸ ì„ íƒ (1: ê¸°ì¡´, 2: ì¶”ê°€1, 3: ì¶”ê°€2)
    :return: ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë‚ ì§œ ë¦¬ìŠ¤íŠ¸
    """
    # EMA ê³„ì‚° (ì „ë‚ ê¹Œì§€ëŠ” ì¼ë°˜ ì¢…ê°€, ë‹¹ì¼ì€ 15:10 ì¢…ê°€ ì‚¬ìš©)
    daily_df['EMA22'] = calculate_ema(daily_df['close'], 22)
    daily_df['EMA60'] = calculate_ema(daily_df['close'], 60)
    daily_df['EMA120'] = calculate_ema(daily_df['close'], 120)
    daily_df['MA22'] = daily_df['close'].rolling(window=22).mean()
    daily_df['MA50'] = daily_df['close'].rolling(window=50).mean()  # 50ì¼ì„  ì¶”ê°€
    
    # 15:10 ê¸°ì¤€ MA ê³„ì‚° (ë‹¹ì¼ ì¡°ê±´ í™•ì¸ìš©)
    daily_df['MA22_1510'] = daily_df['close_1510'].rolling(window=22).mean()
    
    # ìµœê·¼ Në´‰ ìµœê³ ê°€ ê³„ì‚° (ë‹¹ì¼ì€ 15:10 ê¸°ì¤€)
    daily_df['recent_high_1510'] = daily_df['close_1510'].rolling(window=10).max()
    
    # ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë‚ ì§œ ì°¾ê¸°
    valid_dates = []
    
    print(f"\n=== ì¡°ê±´ ì„¸íŠ¸ {condition_set} ì ìš© ===")
    if condition_set == 1:
        print("ê¸°ì¡´ ì¡°ê±´: 8~2ë´‰ì „ ìƒìŠ¹ì„¸, 2ë´‰ì „/1ë´‰ì „ êµì°¨ íŒ¨í„´")
    elif condition_set == 2:
        print("ì¶”ê°€1 ì¡°ê±´: 9~3ë´‰ì „ ìƒìŠ¹ì„¸, 3ë´‰ì „/2-1ë´‰ì „ êµì°¨ íŒ¨í„´")
    elif condition_set == 3:
        print("ì¶”ê°€2 ì¡°ê±´: 10~4ë´‰ì „ ìƒìŠ¹ì„¸, 4ë´‰ì „/3-1ë´‰ì „ êµì°¨ íŒ¨í„´")
    
    for idx in range(120, len(daily_df)):  # ìµœì†Œ 120ì¼ ë°ì´í„° í•„ìš”
        current_row = daily_df.iloc[idx]
        prev_row = daily_df.iloc[idx-1]
        
        try:
            # ì¡°ê±´ ì„¸íŠ¸ì— ë”°ë¥¸ ì¡°ê±´ 1: ê³¼ê±° ìƒìŠ¹ì„¸ í™•ì¸
            if condition_set == 1:
                # ê¸°ì¡´: 8ë´‰ì „ë¶€í„° 2ë´‰ì „ê¹Œì§€ ì¢…ê°€ > EMA22
                condition_1 = all(
                    daily_df.iloc[idx-i]['close'] > daily_df.iloc[idx-i]['EMA22']
                    for i in range(2, 9)  # 2ë´‰ì „ë¶€í„° 8ë´‰ì „ê¹Œì§€
                )
            elif condition_set == 2:
                # ì¶”ê°€1: 9ë´‰ì „ë¶€í„° 3ë´‰ì „ê¹Œì§€ ì¢…ê°€ > EMA22
                condition_1 = all(
                    daily_df.iloc[idx-i]['close'] > daily_df.iloc[idx-i]['EMA22']
                    for i in range(3, 10)  # 3ë´‰ì „ë¶€í„° 9ë´‰ì „ê¹Œì§€
                )
            elif condition_set == 3:
                # ì¶”ê°€2: 10ë´‰ì „ë¶€í„° 4ë´‰ì „ê¹Œì§€ ì¢…ê°€ > EMA22
                condition_1 = all(
                    daily_df.iloc[idx-i]['close'] > daily_df.iloc[idx-i]['EMA22']
                    for i in range(4, 11)  # 4ë´‰ì „ë¶€í„° 10ë´‰ì „ê¹Œì§€
                )
            
            # ì¡°ê±´ 2: 1ë´‰ì „ EMA22 > EMA60 > EMA120 (ëª¨ë“  ì¡°ê±´ ì„¸íŠ¸ ê³µí†µ)
            condition_2 = (
                prev_row['EMA22'] > prev_row['EMA60'] > prev_row['EMA120']
            )
            
            # ì¡°ê±´ 3: êµì°¨ íŒ¨í„´ (ì¡°ê±´ ì„¸íŠ¸ë³„ë¡œ ë‹¤ë¦„)
            if condition_set == 1:
                # ê¸°ì¡´: 2ë´‰ì „(ì¢…ê°€>EMA22>EMA120) & 1ë´‰ì „(EMA22>ì¢…ê°€>EMA120)
                prev2_row = daily_df.iloc[idx-2]
                condition_3a = (
                    prev2_row['close'] > prev2_row['EMA22'] > prev2_row['EMA120']
                )
                condition_3b = (
                    prev_row['EMA22'] > prev_row['close'] > prev_row['EMA120']
                )
                condition_3 = condition_3a and condition_3b
                
            elif condition_set == 2:
                # ì¶”ê°€1: 3ë´‰ì „(ì¢…ê°€>EMA22>EMA120) & 2-1ë´‰ì „(EMA22>ì¢…ê°€>EMA120)
                prev3_row = daily_df.iloc[idx-3]
                prev2_row = daily_df.iloc[idx-2]
                condition_3a = (
                    prev3_row['close'] > prev3_row['EMA22'] > prev3_row['EMA120']
                )
                condition_3b = (
                    prev2_row['EMA22'] > prev2_row['close'] > prev2_row['EMA120']
                )
                condition_3c = (
                    prev_row['EMA22'] > prev_row['close'] > prev_row['EMA120']
                )
                condition_3 = condition_3a and condition_3b and condition_3c
                
            elif condition_set == 3:
                # ì¶”ê°€2: 4ë´‰ì „(ì¢…ê°€>EMA22>EMA120) & 3-1ë´‰ì „(EMA22>ì¢…ê°€>EMA120)
                prev4_row = daily_df.iloc[idx-4]
                prev3_row = daily_df.iloc[idx-3]
                prev2_row = daily_df.iloc[idx-2]
                condition_3a = (
                    prev4_row['close'] > prev4_row['EMA22'] > prev4_row['EMA120']
                )
                condition_3b = (
                    prev3_row['EMA22'] > prev3_row['close'] > prev3_row['EMA120']
                )
                condition_3c = (
                    prev2_row['EMA22'] > prev2_row['close'] > prev2_row['EMA120']
                )
                condition_3d = (
                    prev_row['EMA22'] > prev_row['close'] > prev_row['EMA120']
                )
                condition_3 = condition_3a and condition_3b and condition_3c and condition_3d
            
            # ì¡°ê±´ 4: ê¸°ì¤€ì¼ close_1510 > MA22_1510 (ëŒíŒŒ) - ëª¨ë“  ì¡°ê±´ ì„¸íŠ¸ ê³µí†µ
            condition_4 = (
                current_row['close_1510'] > current_row['MA22_1510']
            )
            
            # ì¡°ê±´ 5: ê¸°ì¤€ì¼ ìµœê·¼10ë´‰ìµœê³ ê°€ < (close_1510 * 1.3) - ëª¨ë“  ì¡°ê±´ ì„¸íŠ¸ ê³µí†µ
            condition_5 = (
                current_row['recent_high_1510'] < (current_row['close_1510'] * 1.3)
            )
            
            # ì¡°ê±´ 6: ê¸°ì¤€ì¼ ìƒìŠ¹ë¥  5%-15% (ë‹¹ì¼ 15:10 vs ì „ë‚  15:30) - ëª¨ë“  ì¡°ê±´ ì„¸íŠ¸ ê³µí†µ
            price_increase = (current_row['close_1510'] / prev_row['close'] - 1) * 100
            condition_6 = 5 <= price_increase <= 15
            
            # ì¡°ê±´ 7: ìµì ˆê°€ê°€ ë§¤ìˆ˜ê°€ë³´ë‹¤ 8% ì´ìƒ ë†’ìŒ - ëª¨ë“  ì¡°ê±´ ì„¸íŠ¸ ê³µí†µ
            # ìµì ˆê°€ ê³„ì‚° (calculate_exit_prices ë¡œì§ê³¼ ë™ì¼)
            candle_center = (current_row['open_1510'] + current_row['close_1510']) / 2
            buy_price = current_row['close_1510']
            stop_loss = current_row['MA50']
            
            # 50ì¼ì„  ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
            if pd.isna(stop_loss):
                continue
                
            # ìµì ˆê°€ ê³„ì‚°
            if candle_center > stop_loss:
                take_profit = candle_center + ((candle_center - stop_loss) * 1.5)
            else:
                take_profit = buy_price * 1.05
                
            # ìµì ˆê°€ê°€ ë§¤ìˆ˜ê°€ë³´ë‹¤ ë‚®ìœ¼ë©´ 5% ìµì ˆë¡œ ì¡°ì •
            if take_profit <= buy_price:
                take_profit = buy_price * 1.05
                
            # ìµì ˆê°€ê°€ ë§¤ìˆ˜ê°€ë³´ë‹¤ 8% ì´ìƒ ë†’ì€ì§€ í™•ì¸
            condition_7 = take_profit >= buy_price * 1.08
            
            # ëª¨ë“  ì¡°ê±´ ë§Œì¡± ì‹œ í•´ë‹¹ ë‚ ì§œ ì¶”ê°€
            if (condition_1 and condition_2 and condition_3 and 
                condition_4 and condition_5 and condition_6 and condition_7):
                valid_dates.append(current_row['date'].strftime('%Y-%m-%d'))
                
        except Exception as e:
            print(f"ë‚ ì§œ {current_row['date']} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            continue
    
    return valid_dates

def process_single_file(file, selected_folder, condition_set=1):
    """
    ë‹¨ì¼ íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ (ì¡°ê±´ ê²€ìƒ‰ + ë°±í…ŒìŠ¤íŒ…)
    """
    try:
        # JSON íŒŒì¼ ì½ê¸°
        with open(file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # JSON êµ¬ì¡° í™•ì¸
        if 'meta' not in data or 'data' not in data:
            return {
                'code': file.name,
                'error': 'JSON íŒŒì¼ êµ¬ì¡° ì˜¤ë¥˜: meta ë˜ëŠ” data ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None
            }
        
        # ì¢…ëª© ì½”ë“œ ì¶”ì¶œ (meta ì„¹ì…˜ì—ì„œ)
        code = data['meta'].get('code', file.name)
        
        # ì°¨íŠ¸ ë°ì´í„°ë§Œ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        chart_data = data['data']
        if not chart_data:
            return {
                'code': code,
                'error': 'ì°¨íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None
            }
        
        df = pd.DataFrame(chart_data)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return {
                'code': code,
                'error': f'í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None
            }
        
        # date ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        try:
            df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d%H%M')
        except Exception as date_error:
            # ë‹¤ë¥¸ ë‚ ì§œ í˜•ì‹ ì‹œë„
            try:
                df['date'] = pd.to_datetime(df['date'])
            except Exception:
                return {
                    'code': code,
                    'error': f'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì˜¤ë¥˜: {str(date_error)}. ì²« ë²ˆì§¸ date ê°’: {df["date"].iloc[0] if len(df) > 0 else "ì—†ìŒ"}',
                    'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'backtest_result': None
                }
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        df = df[required_columns]
        
        # ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜
        daily_df = convert_to_daily(df)
        
        if daily_df.empty:
            return {
                'code': code,
                'valid_dates': [],
                'file_name': file.name,
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None
            }
        
        # ì¡°ê±´ ê²€ìƒ‰ ì‹¤í–‰ (ì¡°ê±´ ì„¸íŠ¸ ì „ë‹¬)
        valid_dates = check_conditions(daily_df, condition_set)
        
        # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ (ì¡°ê±´ ë§Œì¡± ë‚ ì§œê°€ ìˆì„ ë•Œë§Œ)
        backtest_result = None
        if valid_dates:
            # ì¢…ëª© ì½”ë“œë¥¼ daily_dfì— ì¶”ê°€ (ë°±í…ŒìŠ¤íŒ…ì—ì„œ ì‚¬ìš©)
            daily_df['code'] = code
            
            # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
            backtest_df = backtest_strategy(daily_df, df, valid_dates)
            
            if not backtest_df.empty:
                # ì¢…ëª©ë²ˆí˜¸ ì»¬ëŸ¼ ì—…ë°ì´íŠ¸
                backtest_df['ì¢…ëª©ë²ˆí˜¸'] = code
                
                # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ì €ì¥
                backtest_file = save_backtest_results(backtest_df, selected_folder, code, condition_set)
                
                backtest_result = {
                    'total_trades': len(backtest_df),
                    'win_rate': len(backtest_df[backtest_df['ìˆ˜ìµë¥ '] > 0]) / len(backtest_df) * 100 if len(backtest_df) > 0 else 0,
                    'avg_return': backtest_df['ìˆ˜ìµë¥ '].mean() if len(backtest_df) > 0 else 0,
                    'file_saved': backtest_file.name if backtest_file else None
                }
        
        result = {
            'code': code,
            'valid_dates': valid_dates if valid_dates else [],
            'file_name': file.name,
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'backtest_result': backtest_result
        }
        return result
        
    except Exception as e:
        return {
            'code': file.name,
            'error': f'íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}',
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'backtest_result': None
        }

def process_chunk(chunk_files, selected_folder, condition_set=1):
    """
    íŒŒì¼ ì²­í¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    """
    chunk_results = []
    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_file = {
            executor.submit(process_single_file, file, selected_folder, condition_set): file 
            for file in chunk_files
        }
        
        for future in future_to_file:
            result = future.result()
            if result:
                chunk_results.append(result)
    
    return chunk_results

def compare_daily_data(minute_df, daily_df):
    """
    ë¶„ë´‰ ë°ì´í„°ë¥¼ ì¼ë´‰ìœ¼ë¡œ ë³€í™˜í•œ ê²°ê³¼ì™€ ì‹¤ì œ ì¼ë´‰ ë°ì´í„°ë¥¼ ë¹„êµí•˜ëŠ” í•¨ìˆ˜ (ê±°ë˜ëŸ‰ ì œì™¸)
    
    :param minute_df: ë¶„ë´‰ ë°ì´í„° DataFrame
    :param daily_df: ì¼ë´‰ ë°ì´í„° DataFrame
    :return: ë¹„êµ ê²°ê³¼ë¥¼ ë‹´ì€ DataFrame
    """
    # ë¶„ë´‰ ë°ì´í„°ë¥¼ ì¼ë´‰ìœ¼ë¡œ ë³€í™˜
    converted_daily = convert_to_daily(minute_df)
    
    # ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‘ ë°ì´í„°í”„ë ˆì„ ë³‘í•©
    merged_df = pd.merge(
        converted_daily,
        daily_df,
        on='date',
        suffixes=('_converted', '_original')
    )
    
    # ê° ì»¬ëŸ¼ë³„ ì°¨ì´ ê³„ì‚° (ê±°ë˜ëŸ‰ ì œì™¸)
    merged_df['open_diff'] = abs(merged_df['open_converted'] - merged_df['open_original'])
    merged_df['high_diff'] = abs(merged_df['high_converted'] - merged_df['high_original'])
    merged_df['low_diff'] = abs(merged_df['low_converted'] - merged_df['low_original'])
    merged_df['close_diff'] = abs(merged_df['close_converted'] - merged_df['close_original'])
    
    # ì°¨ì´ê°€ ìˆëŠ” í–‰ë§Œ í•„í„°ë§ (ê±°ë˜ëŸ‰ ì œì™¸)
    diff_df = merged_df[
        (merged_df['open_diff'] > 0) |
        (merged_df['high_diff'] > 0) |
        (merged_df['low_diff'] > 0) |
        (merged_df['close_diff'] > 0)
    ]
    
    return diff_df

def test_daily_conversion(folder_path):
    """
    í´ë” ë‚´ì˜ ë¶„ë´‰/ì¼ë´‰ ë°ì´í„°ë¥¼ ë¹„êµí•˜ëŠ” í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
    
    :param folder_path: í…ŒìŠ¤íŠ¸í•  í´ë” ê²½ë¡œ
    """
    print(f"\n=== {folder_path.name} í´ë”ì˜ ë¶„ë´‰/ì¼ë´‰ ë°ì´í„° í…ŒìŠ¤íŠ¸ ===")
    
    # í´ë” ë‚´ì˜ ëª¨ë“  JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    json_files = list(folder_path.glob('*.json'))
    if not json_files:
        print("í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë¶„ë´‰ê³¼ ì¼ë´‰ íŒŒì¼ ë¶„ë¥˜
    minute_files = [f for f in json_files if 'ë¶„ë´‰' in f.name]
    daily_files = [f for f in json_files if 'ì¼ë´‰' in f.name]
    
    print(f"\në¶„ë´‰ íŒŒì¼ ìˆ˜: {len(minute_files)}")
    print(f"ì¼ë´‰ íŒŒì¼ ìˆ˜: {len(daily_files)}")
    
    # ê° íŒŒì¼ ìŒì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    for minute_file in minute_files:
        # í•´ë‹¹ ë¶„ë´‰ íŒŒì¼ì— ëŒ€ì‘í•˜ëŠ” ì¼ë´‰ íŒŒì¼ ì°¾ê¸°
        code = minute_file.name.split('_')[0]
        daily_file = next((f for f in daily_files if f.name.startswith(code)), None)
        
        if not daily_file:
            print(f"\n{minute_file.name}ì— ëŒ€ì‘í•˜ëŠ” ì¼ë´‰ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        print(f"\n=== {code} ì¢…ëª© í…ŒìŠ¤íŠ¸ ===")
        print(f"ë¶„ë´‰ íŒŒì¼: {minute_file.name}")
        print(f"ì¼ë´‰ íŒŒì¼: {daily_file.name}")
        
        try:
            # ë¶„ë´‰ ë°ì´í„° ë¡œë“œ
            with open(minute_file, 'r', encoding='utf-8') as f:
                minute_data = json.load(f)
            minute_df = pd.DataFrame(minute_data['data'])
            minute_df['date'] = pd.to_datetime(minute_df['date'].astype(str), format='%Y%m%d%H%M')
            
            # ì¼ë´‰ ë°ì´í„° ë¡œë“œ
            with open(daily_file, 'r', encoding='utf-8') as f:
                daily_data = json.load(f)
            daily_df = pd.DataFrame(daily_data['data'])
            daily_df['date'] = pd.to_datetime(daily_df['date'].astype(str), format='%Y%m%d')
            
            # ë°ì´í„° ë¹„êµ
            diff_df = compare_daily_data(minute_df, daily_df)
            
            if diff_df.empty:
                print("âœ“ ë³€í™˜ëœ ì¼ë´‰ ë°ì´í„°ê°€ ì›ë³¸ ì¼ë´‰ ë°ì´í„°ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤.")
            else:
                print("\nâš ï¸ ë°ì´í„° ë¶ˆì¼ì¹˜ ë°œê²¬:")
                print(f"ì´ {len(diff_df)}ì¼ì˜ ë°ì´í„°ê°€ ë¶ˆì¼ì¹˜í•©ë‹ˆë‹¤.")
                print("\në¶ˆì¼ì¹˜ ë°ì´í„° ìƒ˜í”Œ:")
                print(diff_df[['date', 'open_diff', 'high_diff', 'low_diff', 'close_diff']].head())
                
                # ë¶ˆì¼ì¹˜ ë°ì´í„°ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥
                excel_file = folder_path / f"{code}_daily_comparison.xlsx"
                diff_df.to_excel(excel_file, index=False)
                print(f"\nìƒì„¸ ë¹„êµ ê²°ê³¼ê°€ {excel_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def test_resample_candles(file, target_interval):
    """
    ë‹¨ì¼ íŒŒì¼ì˜ ë¶„ë´‰ ë°ì´í„°ë¥¼ ì§€ì •ëœ ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ëŠ” í•¨ìˆ˜
    
    :param file: í…ŒìŠ¤íŠ¸í•  JSON íŒŒì¼ ê²½ë¡œ
    :param target_interval: ëª©í‘œ ì‹œê°„ ê°„ê²© (ë¶„)
    :return: í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # JSON íŒŒì¼ ì½ê¸°
        with open(file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # JSON êµ¬ì¡° í™•ì¸
        if 'meta' not in data or 'data' not in data:
            return {
                'code': file.name,
                'status': 'error',
                'message': 'JSON íŒŒì¼ êµ¬ì¡° ì˜¤ë¥˜: meta ë˜ëŠ” data ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤'
            }
        
        # ì¢…ëª© ì½”ë“œ ì¶”ì¶œ
        code = data['meta'].get('code', file.name)
        
        # ì°¨íŠ¸ ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        chart_data = data['data']
        if not chart_data:
            return {
                'code': code,
                'status': 'error',
                'message': 'ì°¨íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤'
            }
        
        df = pd.DataFrame(chart_data)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return {
                'code': code,
                'status': 'error',
                'message': f'í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}'
            }
        
        # date ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        try:
            df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d%H%M')
        except Exception as date_error:
            # ë‹¤ë¥¸ ë‚ ì§œ í˜•ì‹ ì‹œë„
            try:
                df['date'] = pd.to_datetime(df['date'])
            except Exception:
                return {
                    'code': code,
                    'status': 'error',
                    'message': f'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì˜¤ë¥˜: {str(date_error)}. ì²« ë²ˆì§¸ date ê°’: {df["date"].iloc[0] if len(df) > 0 else "ì—†ìŒ"}'
                }
        
        df = df[required_columns]
        
        # í˜„ì¬ ë°ì´í„°ì˜ ì‹œê°„ ê°„ê²© ê°ì§€
        current_interval, start_time = detect_time_interval(df)
        
        if current_interval is None:
            return {
                'code': code,
                'status': 'error',
                'message': 'ì‹œê°„ ê°„ê²©ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }
        
        # ëª©í‘œ ê°„ê²©ì´ í˜„ì¬ ê°„ê²©ì˜ ë°°ìˆ˜ì¸ì§€ í™•ì¸
        if target_interval % current_interval != 0:
            return {
                'code': code,
                'status': 'invalid',
                'current_interval': int(current_interval),
                'target_interval': target_interval,
                'message': f'í˜„ì¬ ê²€ìƒ‰ëœ ë°ì´í„°ê°€ {int(current_interval)}ë¶„ ì°¨íŠ¸ ë°ì´í„°ì…ë‹ˆë‹¤. {int(current_interval)}ë¶„ ê¸°ì¤€ ë°°ìˆ˜ë¡œë§Œ ë°ì´í„° ìˆ˜ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.'
            }
        
        # ë¦¬ìƒ˜í”Œë§ ì‹¤í–‰ ì „ ì›ë³¸ ë°ì´í„° ì •ë³´ ìˆ˜ì§‘
        original_count = len(df)
        original_first_time = df['date'].min()
        original_last_time = df['date'].max()
        
        # ë¦¬ìƒ˜í”Œë§ ì‹¤í–‰
        multiplier = int(target_interval / current_interval)
        resampled_df = resample_candles(df.copy(), multiplier)
        
        # ê²°ê³¼ í†µê³„
        resampled_count = len(resampled_df)
        removed_count = original_count - (resampled_count * multiplier)
        
        # ë¦¬ìƒ˜í”Œë§ í›„ ë°ì´í„° ì •ë³´
        resampled_first_time = resampled_df['date'].min() if not resampled_df.empty else None
        resampled_last_time = resampled_df['date'].max() if not resampled_df.empty else None
        
        # ë¶ˆì™„ì „í•œ ë´‰ ê°ì§€ ì •ë³´
        incomplete_info = ""
        if removed_count > 0:
            incomplete_info = f" (ë¶ˆì™„ì „í•œ ë´‰ {removed_count}ê°œ ì œê±°ë¨)"
        
        return {
            'code': code,
            'status': 'success',
            'current_interval': int(current_interval),
            'target_interval': target_interval,
            'multiplier': multiplier,
            'original_count': original_count,
            'resampled_count': resampled_count,
            'removed_count': removed_count,
            'original_time_range': f"{original_first_time.strftime('%Y-%m-%d %H:%M')} ~ {original_last_time.strftime('%Y-%m-%d %H:%M')}",
            'resampled_time_range': f"{resampled_first_time.strftime('%Y-%m-%d %H:%M')} ~ {resampled_last_time.strftime('%Y-%m-%d %H:%M')}" if resampled_first_time else "ì—†ìŒ",
            'incomplete_info': incomplete_info,
            'data_sample': resampled_df.head(3).to_dict('records') if not resampled_df.empty else []
        }
        
    except Exception as e:
        return {
            'code': file.name,
            'status': 'error',
            'message': f'ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}'
        }

def test_resample_with_analysis(selected_folder, target_interval, condition_set=1):
    """
    ë¦¬ìƒ˜í”Œë§ëœ ë°ì´í„°ë¡œ ì¡°ê±´ ê²€ìƒ‰ê³¼ ë°±í…ŒìŠ¤íŒ…ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    :param selected_folder: ì„ íƒëœ í´ë” ê²½ë¡œ
    :param target_interval: ëª©í‘œ ì‹œê°„ ê°„ê²© (ë¶„)
    :param condition_set: ì¡°ê±´ ì„¸íŠ¸ ë²ˆí˜¸
    :return: ë¶„ì„ ê²°ê³¼
    """
    # í´ë” ë‚´ì˜ JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    json_files = list(selected_folder.glob('*.json'))
    if not json_files:
        print("ì„ íƒí•œ í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    print(f"\n=== {target_interval}ë¶„ë´‰ ë¦¬ìƒ˜í”Œë§ ë¶„ì„ ì‹œì‘ ===")
    print(f"ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(json_files)}")
    
    results = []
    valid_files = []
    invalid_files = []
    
    # 1ë‹¨ê³„: ë¦¬ìƒ˜í”Œë§ ê°€ëŠ¥ì„± í™•ì¸
    print("\n1ë‹¨ê³„: ë¦¬ìƒ˜í”Œë§ ê°€ëŠ¥ì„± í™•ì¸ ì¤‘...")
    
    for file in tqdm(json_files, desc="íŒŒì¼ ê²€ì¦"):
        test_result = test_resample_candles(file, target_interval)
        
        if test_result['status'] == 'success':
            valid_files.append(file)
            # ë¶ˆì™„ì „í•œ ë´‰ì´ ì œê±°ëœ ê²½ìš° ì •ë³´ ì¶œë ¥
            if test_result.get('removed_count', 0) > 0:
                print(f"\nğŸ“Š {test_result['code']}: {test_result['incomplete_info']}")
                print(f"   ì›ë³¸: {test_result['original_time_range']}")
                print(f"   ë³€í™˜: {test_result['resampled_time_range']}")
        elif test_result['status'] == 'invalid':
            invalid_files.append(test_result)
            if len(invalid_files) == 1:  # ì²« ë²ˆì§¸ ì˜¤ë¥˜ë§Œ ì¶œë ¥
                print(f"\nâš ï¸ {test_result['message']}")
        else:
            print(f"\nâŒ {test_result['code']}: {test_result['message']}")
    
    print(f"\nê²€ì¦ ì™„ë£Œ: ì²˜ë¦¬ ê°€ëŠ¥ íŒŒì¼ {len(valid_files)}ê°œ, ë¶ˆê°€ëŠ¥ íŒŒì¼ {len(invalid_files)}ê°œ")
    
    if not valid_files:
        print("ì²˜ë¦¬ ê°€ëŠ¥í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    if invalid_files:
        print(f"ì²˜ë¦¬ ë¶ˆê°€ëŠ¥í•œ íŒŒì¼ì´ {len(invalid_files)}ê°œ ìˆìŠµë‹ˆë‹¤.")
        print("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
        user_input = input().lower()
        if user_input != 'y':
            print("ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return []
    
    # 2ë‹¨ê³„: ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
    print(f"\n2ë‹¨ê³„: {len(valid_files)}ê°œ íŒŒì¼ë¡œ ì¡°ê±´ ê²€ìƒ‰ ë° ë°±í…ŒìŠ¤íŒ… ìˆ˜í–‰...")
    
    # íŒŒì¼ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
    file_chunks = [valid_files[i:i + CHUNK_SIZE] for i in range(0, len(valid_files), CHUNK_SIZE)]
    
    # ë¦¬ìƒ˜í”Œë§ ë²„ì „ì˜ í”„ë¡œì„¸ìŠ¤ í•¨ìˆ˜ ì‚¬ìš©
    with tqdm(total=len(valid_files), desc="ë¶„ì„ ì§„í–‰") as pbar:
        for chunk in file_chunks:
            chunk_results = process_chunk_with_resampling(chunk, selected_folder, target_interval, condition_set)
            results.extend(chunk_results)
            pbar.update(len(chunk))
    
    return results

def process_single_file_with_resampling(file, selected_folder, target_interval, condition_set=1):
    """
    ë¦¬ìƒ˜í”Œë§ì„ ì ìš©í•œ ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
    """
    try:
        # JSON íŒŒì¼ ì½ê¸°
        with open(file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # JSON êµ¬ì¡° í™•ì¸
        if 'meta' not in data or 'data' not in data:
            return {
                'code': file.name,
                'error': 'JSON íŒŒì¼ êµ¬ì¡° ì˜¤ë¥˜: meta ë˜ëŠ” data ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None
            }
        
        # ì¢…ëª© ì½”ë“œ ì¶”ì¶œ
        code = data['meta'].get('code', file.name)
        
        # ì°¨íŠ¸ ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        chart_data = data['data']
        if not chart_data:
            return {
                'code': code,
                'error': 'ì°¨íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None,
                'resample_info': ''
            }
        
        df = pd.DataFrame(chart_data)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return {
                'code': code,
                'error': f'í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None,
                'resample_info': ''
            }
        
        # date ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        try:
            df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d%H%M')
        except Exception as date_error:
            # ë‹¤ë¥¸ ë‚ ì§œ í˜•ì‹ ì‹œë„
            try:
                df['date'] = pd.to_datetime(df['date'])
            except Exception:
                return {
                    'code': code,
                    'error': f'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì˜¤ë¥˜: {str(date_error)}. ì²« ë²ˆì§¸ date ê°’: {df["date"].iloc[0] if len(df) > 0 else "ì—†ìŒ"}',
                    'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'backtest_result': None,
                    'resample_info': ''
                }
        
        df = df[required_columns]
        
        # í˜„ì¬ ë°ì´í„°ì˜ ì‹œê°„ ê°„ê²© ê°ì§€
        current_interval, _ = detect_time_interval(df)
        
        # ë¦¬ìƒ˜í”Œë§ (ëª©í‘œ ê°„ê²©ì´ í˜„ì¬ ê°„ê²©ê³¼ ë‹¤ë¥¸ ê²½ìš°ì—ë§Œ)
        if target_interval != current_interval:
            multiplier = int(target_interval / current_interval)
            df = resample_candles(df, multiplier)
        
        # ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜ (15:10 ì»¬ëŸ¼ í¬í•¨)
        daily_df = convert_to_daily(df)
        
        if daily_df.empty:
            return {
                'code': code,
                'valid_dates': [],
                'file_name': file.name,
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'backtest_result': None,
                'resample_info': f"{int(current_interval)}ë¶„ -> {target_interval}ë¶„"
            }
        
        # ì¡°ê±´ ê²€ìƒ‰ ì‹¤í–‰
        valid_dates = check_conditions(daily_df, condition_set)
        
        # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ (ì¡°ê±´ ë§Œì¡± ë‚ ì§œê°€ ìˆì„ ë•Œë§Œ)
        backtest_result = None
        if valid_dates:
            daily_df['code'] = code
            backtest_df = backtest_strategy(daily_df, df, valid_dates)
            
            if not backtest_df.empty:
                backtest_df['ì¢…ëª©ë²ˆí˜¸'] = code
                
                # ë¦¬ìƒ˜í”Œë§ ì •ë³´ë¥¼ í¬í•¨í•œ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backtest_dir = selected_folder / 'backtest_resampled'
                backtest_dir.mkdir(exist_ok=True)
                
                condition_names = {1: "ê¸°ì¡´ì¡°ê±´", 2: "ì¶”ê°€1ì¡°ê±´", 3: "ì¶”ê°€2ì¡°ê±´"}
                condition_name = condition_names.get(condition_set, "ì•Œìˆ˜ì—†ìŒ")
                
                excel_file = backtest_dir / f"backtest_{code}_{target_interval}ë¶„_{condition_name}_{timestamp}.xlsx"
                
                # í†µê³„ ì •ë³´ ìƒì„±
                total_trades = len(backtest_df)
                win_trades = len(backtest_df[backtest_df['ìˆ˜ìµë¥ '] > 0])
                win_rate = (win_trades / total_trades * 100) if total_trades > 0 else 0
                avg_return = backtest_df['ìˆ˜ìµë¥ '].mean() if total_trades > 0 else 0
                
                stats_df = pd.DataFrame({
                    'í•­ëª©': ['ì´ ê±°ë˜ìˆ˜', 'ìˆ˜ìµ ê±°ë˜', 'ì†ì‹¤ ê±°ë˜', 'ìŠ¹ë¥ (%)', 'í‰ê·  ìˆ˜ìµë¥ (%)', 'ì¡°ê±´ì„¸íŠ¸', 'ë¦¬ìƒ˜í”Œë§'],
                    'ê°’': [total_trades, win_trades, total_trades - win_trades, round(win_rate, 2), 
                          round(avg_return, 2), condition_name, f"{int(current_interval)}ë¶„ -> {target_interval}ë¶„"]
                })
                
                # ì—‘ì…€ íŒŒì¼ ì €ì¥
                with pd.ExcelWriter(excel_file) as writer:
                    backtest_df.to_excel(writer, sheet_name='ê±°ë˜ë‚´ì—­', index=False)
                    stats_df.to_excel(writer, sheet_name='í†µê³„', index=False)
                
                backtest_result = {
                    'total_trades': total_trades,
                    'win_rate': win_rate,
                    'avg_return': avg_return,
                    'file_saved': excel_file.name
                }
        
        return {
            'code': code,
            'valid_dates': valid_dates if valid_dates else [],
            'file_name': file.name,
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'backtest_result': backtest_result,
            'resample_info': f"{int(current_interval)}ë¶„ -> {target_interval}ë¶„"
        }
        
    except Exception as e:
        return {
            'code': file.name,
            'error': f'íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}',
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'backtest_result': None
        }

def process_chunk_with_resampling(chunk_files, selected_folder, target_interval, condition_set=1):
    """
    ë¦¬ìƒ˜í”Œë§ì´ ì ìš©ëœ íŒŒì¼ ì²­í¬ ì²˜ë¦¬ í•¨ìˆ˜
    """
    chunk_results = []
    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_file = {
            executor.submit(process_single_file_with_resampling, file, selected_folder, target_interval, condition_set): file 
            for file in chunk_files
        }
        
        for future in future_to_file:
            result = future.result()
            if result:
                chunk_results.append(result)
    
    return chunk_results

def calculate_ma50(daily_df):
    """50ì¼ ì´ë™í‰ê·  ê³„ì‚°"""
    daily_df['MA50'] = daily_df['close'].rolling(window=50).mean()
    return daily_df

def calculate_exit_prices(buy_row):
    """
    ë§¤ìˆ˜ì¼ ê¸°ì¤€ìœ¼ë¡œ ì†ì ˆê°€ì™€ ìµì ˆê°€ ê³„ì‚°
    
    :param buy_row: ë§¤ìˆ˜ì¼ì˜ ë°ì´í„° (Series)
    :return: (ì†ì ˆê°€, ìµì ˆê°€)
    """
    # ë´‰ ì¤‘ì‹¬ê°’ = (ì‹œê°€ + ì¢…ê°€) / 2 (15:10 ê¸°ì¤€)
    candle_center = (buy_row['open_1510'] + buy_row['close_1510']) / 2
    
    # ë§¤ìˆ˜ê°€ (15:10 ì¢…ê°€)
    buy_price = buy_row['close_1510']
    
    # ì†ì ˆê°€ = ë§¤ìˆ˜ì¼ì˜ 50ì¼ì„  (ê³ ì •)
    stop_loss = buy_row['MA50']
    
    # ìµì ˆê°€ ê³„ì‚° ê°œì„ : í•­ìƒ ë§¤ìˆ˜ê°€ë³´ë‹¤ ë†’ë„ë¡ ë³´ì¥
    if candle_center > stop_loss:
        # ì •ìƒì ì¸ ê²½ìš°: ë´‰ì¤‘ì‹¬ê°’ì´ 50ì¼ì„ ë³´ë‹¤ ë†’ìŒ
        take_profit = candle_center + ((candle_center - stop_loss) * 1.5)
    else:
        # ë¹„ì •ìƒì ì¸ ê²½ìš°: ë´‰ì¤‘ì‹¬ê°’ì´ 50ì¼ì„ ë³´ë‹¤ ë‚®ê±°ë‚˜ ê°™ìŒ
        # ë§¤ìˆ˜ê°€ ê¸°ì¤€ìœ¼ë¡œ 5% ìµì ˆë¡œ ì„¤ì •
        take_profit = buy_price * 1.05
        print(f"ê²½ê³ : ë´‰ì¤‘ì‹¬ê°’({candle_center:.0f})ì´ 50ì¼ì„ ({stop_loss:.0f})ë³´ë‹¤ ë‚®ì•„ 5% ìµì ˆë¡œ ì„¤ì •")
    
    # ìµì ˆê°€ê°€ ë§¤ìˆ˜ê°€ë³´ë‹¤ ë‚®ìœ¼ë©´ 5% ìµì ˆë¡œ ì¡°ì •
    if take_profit <= buy_price:
        take_profit = buy_price * 1.05
        print(f"ê²½ê³ : ê³„ì‚°ëœ ìµì ˆê°€ê°€ ë§¤ìˆ˜ê°€ë³´ë‹¤ ë‚®ì•„ 5% ìµì ˆë¡œ ì¡°ì •")
    
    return stop_loss, take_profit

def check_exit_conditions_minute_data(minute_df, buy_date, stop_loss, take_profit, max_hold_days=5):
    """
    5ë¶„ë´‰ ë°ì´í„°ë¡œ ë§¤ë„ ì¡°ê±´ ì²´í¬ (ìµì ˆ ìš°ì„ , ì†ì ˆ í›„ìˆœìœ„)
    
    :param minute_df: 5ë¶„ë´‰ ë°ì´í„° DataFrame
    :param buy_date: ë§¤ìˆ˜ì¼
    :param stop_loss: ì†ì ˆê°€
    :param take_profit: ìµì ˆê°€
    :param max_hold_days: ìµœëŒ€ ë³´ìœ ì¼
    :return: (ë§¤ë„ì¼, ë§¤ë„ê°€, ë§¤ë„ì‚¬ìœ )
    """
    buy_date = pd.to_datetime(buy_date)
    
    # ë§¤ìˆ˜ì¼ ë‹¤ìŒë‚ ë¶€í„° ì²´í¬
    start_date = buy_date + pd.Timedelta(days=1)
    end_date = buy_date + pd.Timedelta(days=max_hold_days)
    
    # ë§¤ë„ ê¸°ê°„ ë°ì´í„° í•„í„°ë§
    sell_period = minute_df[
        (minute_df['date'].dt.date >= start_date.date()) &
        (minute_df['date'].dt.date <= end_date.date())
    ].copy()
    
    if sell_period.empty:
        return None, None, "ë°ì´í„°ì—†ìŒ"
    
    # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì²´í¬
    for day_num, (date, day_data) in enumerate(sell_period.groupby(sell_period['date'].dt.date), 1):
        day_data = day_data.sort_values('date')  # ì‹œê°„ìˆœ ì •ë ¬
        
        # 5ë¶„ë´‰ ë‹¨ìœ„ë¡œ ì²´í¬ (ìµì ˆ ìš°ì„ )
        for _, row in day_data.iterrows():
            # 1. ìµì ˆ ì¡°ê±´ ë¨¼ì € ì²´í¬ (ê³ ê°€ >= ìµì ˆê°€)
            if row['high'] >= take_profit:
                return pd.to_datetime(date), take_profit, "ìµì ˆ"
            
            # 2. ì†ì ˆ ì¡°ê±´ ì²´í¬ (ì €ê°€ <= ì†ì ˆê°€)  
            if row['low'] <= stop_loss:
                return pd.to_datetime(date), stop_loss, "ì†ì ˆ"
        
        # 5ì¼ì§¸ ê°•ì œ ë§¤ë„
        if day_num >= max_hold_days:
            last_close = day_data.iloc[-1]['close']
            return pd.to_datetime(date), last_close, "ê°•ì œë§¤ë„"
    
    # ë§¤ë„ ì¡°ê±´ ë¯¸ì¶©ì¡± (ë°ì´í„° ë¶€ì¡±)
    return None, None, "ë¯¸ë§¤ë„"

def backtest_strategy(daily_df, minute_df, valid_dates):
    """
    ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
    
    :param daily_df: ì¼ë´‰ ë°ì´í„° (15:10 ì»¬ëŸ¼ í¬í•¨)
    :param minute_df: 5ë¶„ë´‰ ë°ì´í„°  
    :param valid_dates: ë§¤ìˆ˜ ì¡°ê±´ ë§Œì¡± ë‚ ì§œ ë¦¬ìŠ¤íŠ¸
    :return: ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ DataFrame
    """
    # 50ì¼ì„  ê³„ì‚°
    daily_df = calculate_ma50(daily_df)
    
    results = []
    
    for date_str in valid_dates:
        try:
            buy_date = pd.to_datetime(date_str)
            
            # ë§¤ìˆ˜ì¼ ë°ì´í„° ì°¾ê¸°
            buy_day_data = daily_df[daily_df['date'].dt.date == buy_date.date()]
            if buy_day_data.empty:
                continue
                
            buy_row = buy_day_data.iloc[0]
            
            # 50ì¼ì„  ë°ì´í„° í™•ì¸
            if pd.isna(buy_row['MA50']):
                continue
            
            # ë§¤ìˆ˜ê°€
            buy_price = buy_row['close_1510']
            
            # ì†ì ˆê°€, ìµì ˆê°€ ê³„ì‚°
            stop_loss, take_profit = calculate_exit_prices(buy_row)
            
            # ë§¤ë„ ì¡°ê±´ ì²´í¬ (5ë¶„ë´‰ ê¸°ì¤€)
            sell_date, sell_price, sell_reason = check_exit_conditions_minute_data(
                minute_df, buy_date, stop_loss, take_profit
            )
            
            if sell_date is not None and sell_price is not None:
                # ë³´ìœ  ê¸°ê°„ ê³„ì‚°
                hold_days = (sell_date - buy_date).days
                
                result = {
                    'ì¢…ëª©ë²ˆí˜¸': buy_row.get('code', 'Unknown'),  # ì¢…ëª© ì½”ë“œê°€ ìˆë‹¤ë©´
                    'ë§¤ìˆ˜ì¼': buy_date.strftime('%Y-%m-%d'),
                    'ë§¤ìˆ˜ê°’': round(buy_price, 0),
                    'ìµì ˆê°€(ëª©í‘œ)': round(take_profit, 0),
                    'ì†ì ˆê°€(ëª©í‘œ)': round(stop_loss, 0),
                    'ë§¤ë„ì¼': sell_date.strftime('%Y-%m-%d'),
                    'ë§¤ë„ê°’': round(sell_price, 0),
                    'ë³´ìœ ê¸°ê°„': hold_days,
                    'ì†ì ˆìµì ˆ': sell_reason,
                    'ìˆ˜ìµë¥ ': round(((sell_price / buy_price) - 1) * 100, 2)
                }
                results.append(result)
                
        except Exception as e:
            print(f"ë°±í…ŒìŠ¤íŒ… ì˜¤ë¥˜ - ë‚ ì§œ {date_str}: {str(e)}")
            continue
    
    return pd.DataFrame(results)

def save_backtest_results(results_df, folder_path, stock_code, condition_set=1):
    """
    ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
    
    :param results_df: ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ DataFrame
    :param folder_path: ì €ì¥ í´ë” ê²½ë¡œ
    :param stock_code: ì¢…ëª© ì½”ë“œ
    :param condition_set: ì‚¬ìš©ëœ ì¡°ê±´ ì„¸íŠ¸ ë²ˆí˜¸
    :return: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    if results_df.empty:
        print(f"{stock_code}: ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ê°€ ì—†ì–´ íŒŒì¼ì„ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ê²°ê³¼ë¥¼ ì €ì¥í•  backtest í´ë” ìƒì„±
    backtest_dir = folder_path / 'backtest'
    backtest_dir.mkdir(exist_ok=True)
    
    # ì¡°ê±´ ì„¸íŠ¸ ì´ë¦„ ë§¤í•‘
    condition_names = {
        1: "ê¸°ì¡´ì¡°ê±´",
        2: "ì¶”ê°€1ì¡°ê±´", 
        3: "ì¶”ê°€2ì¡°ê±´"
    }
    condition_name = condition_names.get(condition_set, "ì•Œìˆ˜ì—†ìŒ")
    
    excel_file = backtest_dir / f"backtest_{stock_code}_{condition_name}_{timestamp}.xlsx"
    
    # í†µê³„ ì •ë³´ ì¶”ê°€
    total_trades = len(results_df)
    win_trades = len(results_df[results_df['ìˆ˜ìµë¥ '] > 0])
    lose_trades = len(results_df[results_df['ìˆ˜ìµë¥ '] <= 0])
    win_rate = (win_trades / total_trades * 100) if total_trades > 0 else 0
    avg_return = results_df['ìˆ˜ìµë¥ '].mean() if total_trades > 0 else 0
    
    # í†µê³„ ì •ë³´ë¥¼ DataFrameìœ¼ë¡œ ìƒì„±
    stats_df = pd.DataFrame({
        'í•­ëª©': ['ì´ ê±°ë˜ìˆ˜', 'ìˆ˜ìµ ê±°ë˜', 'ì†ì‹¤ ê±°ë˜', 'ìŠ¹ë¥ (%)', 'í‰ê·  ìˆ˜ìµë¥ (%)', 'ì¡°ê±´ì„¸íŠ¸'],
        'ê°’': [total_trades, win_trades, lose_trades, round(win_rate, 2), round(avg_return, 2), condition_name]
    })
    
    # ì—‘ì…€ íŒŒì¼ì— ë‘ ê°œ ì‹œíŠ¸ë¡œ ì €ì¥
    with pd.ExcelWriter(excel_file) as writer:
        results_df.to_excel(writer, sheet_name='ê±°ë˜ë‚´ì—­', index=False)
        stats_df.to_excel(writer, sheet_name='í†µê³„', index=False)
    
    print(f"{stock_code}: ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ê°€ {excel_file.name}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ì´ {total_trades}ê±´ ê±°ë˜, ìŠ¹ë¥  {win_rate:.1f}%")
    print(f"í‰ê·  ìˆ˜ìµë¥ : {avg_return:.2f}%")
    
    return excel_file

def combine_all_backtest_results(folder_path, condition_set=1):
    """
    ëª¨ë“  ì¢…ëª©ì˜ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ í•©ì¹˜ëŠ” í•¨ìˆ˜
    
    :param folder_path: ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
    :param condition_set: í•©ì¹  ì¡°ê±´ ì„¸íŠ¸ ë²ˆí˜¸
    :return: í•©ì³ì§„ íŒŒì¼ ê²½ë¡œ
    """
    backtest_dir = folder_path / 'backtest'
    if not backtest_dir.exists():
        print("backtest í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None
    
    # ì¡°ê±´ ì„¸íŠ¸ ì´ë¦„ ë§¤í•‘
    condition_names = {
        1: "ê¸°ì¡´ì¡°ê±´",
        2: "ì¶”ê°€1ì¡°ê±´", 
        3: "ì¶”ê°€2ì¡°ê±´"
    }
    condition_name = condition_names.get(condition_set, "ì•Œìˆ˜ì—†ìŒ")
    
    # í•´ë‹¹ ì¡°ê±´ ì„¸íŠ¸ì˜ ë°±í…ŒìŠ¤íŠ¸ ì—‘ì…€ íŒŒì¼ë§Œ ì°¾ê¸°
    excel_files = list(backtest_dir.glob(f'backtest_A*{condition_name}*.xlsx'))
    if not excel_files:
        print(f"{condition_name} ì¡°ê±´ì˜ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    print(f"ì´ {len(excel_files)}ê°œì˜ {condition_name} ë°±í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ í•©ì¹˜ëŠ” ì¤‘...")
    
    all_trades = []
    all_stats = []
    
    for excel_file in excel_files:
        try:
            # ê±°ë˜ë‚´ì—­ ì‹œíŠ¸ ì½ê¸°
            trades_df = pd.read_excel(excel_file, sheet_name='ê±°ë˜ë‚´ì—­')
            if not trades_df.empty:
                all_trades.append(trades_df)
            
            # í†µê³„ ì‹œíŠ¸ ì½ê¸° (ì¢…ëª©ëª… ì¶”ê°€)
            stats_df = pd.read_excel(excel_file, sheet_name='í†µê³„')
            if not stats_df.empty:
                # íŒŒì¼ëª…ì—ì„œ ì¢…ëª©ì½”ë“œ ì¶”ì¶œ
                filename_parts = excel_file.name.split('_')
                stock_code = filename_parts[1]  # backtest_Aì¢…ëª©ì½”ë“œ_ì¡°ê±´ëª…_timestamp.xlsx
                stats_with_code = stats_df.copy()
                stats_with_code.insert(0, 'ì¢…ëª©ë²ˆí˜¸', stock_code)
                all_stats.append(stats_with_code)
                
        except Exception as e:
            print(f"{excel_file.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue
    
    if not all_trades:
        print("í•©ì¹  ê±°ë˜ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ëª¨ë“  ê±°ë˜ë‚´ì—­ í•©ì¹˜ê¸°
    combined_trades = pd.concat(all_trades, ignore_index=True)
    combined_trades = combined_trades.sort_values(['ì¢…ëª©ë²ˆí˜¸', 'ë§¤ìˆ˜ì¼'])
    
    # ì „ì²´ í†µê³„ ê³„ì‚°
    total_trades = len(combined_trades)
    win_trades = len(combined_trades[combined_trades['ìˆ˜ìµë¥ '] > 0])
    lose_trades = len(combined_trades[combined_trades['ìˆ˜ìµë¥ '] <= 0])
    win_rate = (win_trades / total_trades * 100) if total_trades > 0 else 0
    avg_return = combined_trades['ìˆ˜ìµë¥ '].mean() if total_trades > 0 else 0
    max_return = combined_trades['ìˆ˜ìµë¥ '].max() if total_trades > 0 else 0
    min_return = combined_trades['ìˆ˜ìµë¥ '].min() if total_trades > 0 else 0
    
    # ì „ì²´ í†µê³„ DataFrame
    total_stats = pd.DataFrame({
        'í•­ëª©': ['ì´ ê±°ë˜ìˆ˜', 'ìˆ˜ìµ ê±°ë˜', 'ì†ì‹¤ ê±°ë˜', 'ìŠ¹ë¥ (%)', 'í‰ê·  ìˆ˜ìµë¥ (%)', 'ìµœëŒ€ ìˆ˜ìµë¥ (%)', 'ìµœì†Œ ìˆ˜ìµë¥ (%)', 'ì¡°ê±´ì„¸íŠ¸'],
        'ê°’': [total_trades, win_trades, lose_trades, round(win_rate, 2), 
               round(avg_return, 2), round(max_return, 2), round(min_return, 2), condition_name]
    })
    
    # ì¢…ëª©ë³„ í†µê³„ í•©ì¹˜ê¸° (ìˆëŠ” ê²½ìš°)
    combined_stats_by_stock = pd.concat(all_stats, ignore_index=True) if all_stats else pd.DataFrame()
    
    # ê²°ê³¼ íŒŒì¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    combined_file = backtest_dir / f"combined_backtest_{condition_name}_{timestamp}.xlsx"
    
    with pd.ExcelWriter(combined_file) as writer:
        combined_trades.to_excel(writer, sheet_name='ì „ì²´ê±°ë˜ë‚´ì—­', index=False)
        total_stats.to_excel(writer, sheet_name='ì „ì²´í†µê³„', index=False)
        if not combined_stats_by_stock.empty:
            combined_stats_by_stock.to_excel(writer, sheet_name='ì¢…ëª©ë³„í†µê³„', index=False)
    
    print(f"\n=== {condition_name} ì „ì²´ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ===")
    print(f"ì´ {total_trades}ê±´ ê±°ë˜")
    print(f"ìŠ¹ë¥ : {win_rate:.1f}%")
    print(f"í‰ê·  ìˆ˜ìµë¥ : {avg_return:.2f}%")
    print(f"ìµœëŒ€ ìˆ˜ìµë¥ : {max_return:.2f}%")
    print(f"ìµœì†Œ ìˆ˜ìµë¥ : {min_return:.2f}%")
    print(f"ê²°ê³¼ íŒŒì¼: {combined_file.name}")
    
    return combined_file

def main():
    global MAX_WORKERS, CHUNK_SIZE
    
    while True:
        print("\n=== ì£¼ì‹ ë°ì´í„° ë¶„ì„ í”„ë¡œê·¸ë¨ ===")
        print("1. ì „ì²´ ì¡°ê±´ í†µí•© ë°±í…ŒìŠ¤íŒ…")
        print("2. í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
        
        choice = input("\në©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš” (1,2): ")
        
        if choice == '1':
            # ì „ì²´ ì¡°ê±´ í†µí•© ë°±í…ŒìŠ¤íŒ…
            execute_integrated_backtest()
            
        elif choice == '2':
            print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
            
        else:
            print("\nì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.")

def execute_integrated_backtest():
    """
    3ë²ˆ ë©”ë‰´: ì „ì²´ ì¡°ê±´ í†µí•© ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ í•¨ìˆ˜
    """
    global MAX_WORKERS, CHUNK_SIZE
    
    print("\n=== ì „ì²´ ì¡°ê±´ í†µí•© ë°±í…ŒìŠ¤íŒ… ===")
    
    # json_data í´ë” ë‚´ì˜ í´ë” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    base_dir = Path('json_data')
    if not base_dir.exists():
        print("json_data í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
        
    folders = [f for f in base_dir.iterdir() if f.is_dir()]
    if not folders:
        print("ë¶„ì„í•  ë°ì´í„° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    # í´ë” ëª©ë¡ í‘œì‹œ
    print("\n=== ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° í´ë” ===")
    for idx, folder in enumerate(folders, 1):
        print(f"{idx}. {folder.name}")
    
    # í´ë” ì„ íƒ
    while True:
        try:
            folder_choice = int(input("\në¶„ì„í•  í´ë” ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: "))
            if 1 <= folder_choice <= len(folders):
                selected_folder = folders[folder_choice - 1]
                break
            else:
                print(f"1ë¶€í„° {len(folders)}ê¹Œì§€ì˜ ë²ˆí˜¸ë§Œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        except ValueError:
            print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    # ê²°ê³¼ í´ë”ëª… ìƒì„± (ì„ íƒëœ í´ë”ëª… + íƒ€ì„ìŠ¤íƒ¬í”„ + ë°±í…ŒìŠ¤íŒ…_ê²°ê³¼)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_folder_name = f"{selected_folder.name}_{timestamp}_ë°±í…ŒìŠ¤íŒ…_ê²°ê³¼"
    
    # í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì„¤ì •
    while True:
        try:
            num_workers = int(input(f"\nì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-{multiprocessing.cpu_count()}, ê¸°ë³¸ê°’: {MAX_WORKERS}): ") or MAX_WORKERS)
            if 1 <= num_workers <= multiprocessing.cpu_count():
                MAX_WORKERS = num_workers
                break
            else:
                print(f"1ë¶€í„° {multiprocessing.cpu_count()}ê¹Œì§€ì˜ ìˆ«ìë§Œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        except ValueError:
            print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    # ì„ íƒëœ í´ë” ë‚´ì˜ JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    json_files = list(selected_folder.glob('*.json'))
    if not json_files:
        print("ì„ íƒí•œ í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    print(f"\n=== {selected_folder.name} í´ë” ë¶„ì„ ì‹œì‘ ===")
    print(f"ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(json_files)}")
    print(f"ì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ìˆ˜: {MAX_WORKERS}")
    print(f"ê²€ìƒ‰ ì¡°ê±´: ê¸°ì¡´ì¡°ê±´ + ì¶”ê°€1ì¡°ê±´ + ì¶”ê°€2ì¡°ê±´ (ë™ì‹œ ì²˜ë¦¬)")
    print(f"ì²­í¬ í¬ê¸°: {CHUNK_SIZE}")
    print(f"ê²°ê³¼ ì €ì¥ í´ë”: {result_folder_name}")
    
    # íŒŒì¼ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
    file_chunks = [json_files[i:i + CHUNK_SIZE] for i in range(0, len(json_files), CHUNK_SIZE)]
    
    # ì „ì²´ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    all_results = []
    
    # tqdmì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™© í‘œì‹œ
    with tqdm(total=len(json_files), desc="ì „ì²´ ì¡°ê±´ ë°±í…ŒìŠ¤íŒ… ì¤‘") as pbar:
        for chunk_idx, chunk in enumerate(file_chunks):
            chunk_results = process_chunk_all_conditions(chunk, selected_folder, result_folder_name)
            all_results.extend(chunk_results)
            pbar.update(len(chunk))
    
    # ê²°ê³¼ ë¶„ì„ ë° í†µí•©
    print("\n=== ë¶„ì„ ê²°ê³¼ ===")
    success_count = 0
    error_count = 0
    
    condition_stats = {
        1: {'ì¢…ëª©ìˆ˜': 0, 'ê±°ë˜ìˆ˜': 0, 'ì¡°ê±´ëª…': 'ê¸°ì¡´ì¡°ê±´'},
        2: {'ì¢…ëª©ìˆ˜': 0, 'ê±°ë˜ìˆ˜': 0, 'ì¡°ê±´ëª…': 'ì¶”ê°€1ì¡°ê±´'},
        3: {'ì¢…ëª©ìˆ˜': 0, 'ê±°ë˜ìˆ˜': 0, 'ì¡°ê±´ëª…': 'ì¶”ê°€2ì¡°ê±´'}
    }
    
    for result in all_results:
        if 'error' in result:
            error_count += 1
            print(f"âŒ {result['code']}: {result['error']}")
        else:
            success_count += 1
            
            # ê° ì¡°ê±´ë³„ í†µê³„ ìˆ˜ì§‘
            for condition_set in [1, 2, 3]:
                condition_result = result.get(f'condition_{condition_set}', {})
                if condition_result.get('valid_dates'):
                    condition_stats[condition_set]['ì¢…ëª©ìˆ˜'] += 1
                    backtest_result = condition_result.get('backtest_result')
                    if backtest_result:
                        condition_stats[condition_set]['ê±°ë˜ìˆ˜'] += backtest_result['total_trades']
    
    print(f"\nì²˜ë¦¬ ì™„ë£Œ: ì´ {len(all_results)}ê°œ íŒŒì¼")
    print(f"ì„±ê³µ: {success_count}ê°œ, ì‹¤íŒ¨: {error_count}ê°œ")
    
    print("\n=== ì¡°ê±´ë³„ ê²°ê³¼ ìš”ì•½ ===")
    for condition_set, stats in condition_stats.items():
        print(f"{stats['ì¡°ê±´ëª…']}: {stats['ì¢…ëª©ìˆ˜']}ê°œ ì¢…ëª©, {stats['ê±°ë˜ìˆ˜']}ê±´ ê±°ë˜")
    
    # í†µí•© ê²°ê³¼ íŒŒì¼ ìƒì„±
    if success_count > 0:
        print("\ní†µí•© ê²°ê³¼ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        final_file = combine_integrated_results(all_results, selected_folder, result_folder_name)
        if final_file:
            print(f"âœ… ìµœì¢… í†µí•© ê²°ê³¼: {final_file.name}")
            
            # ì„ì‹œ íŒŒì¼ë“¤ ì •ë¦¬
            cleanup_temp_files(selected_folder, result_folder_name)
            print("ğŸ“ ì„ì‹œ íŒŒì¼ë“¤ì´ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("ìƒì„±í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

def process_single_file_all_conditions(file, selected_folder, result_folder_name):
    """
    ë‹¨ì¼ íŒŒì¼ì„ ëª¨ë“  ì¡°ê±´ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ (3ë²ˆ ë©”ë‰´ìš©)
    """
    try:
        # JSON íŒŒì¼ ì½ê¸°
        with open(file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # JSON êµ¬ì¡° í™•ì¸
        if 'meta' not in data or 'data' not in data:
            return {
                'code': file.name,
                'error': 'JSON íŒŒì¼ êµ¬ì¡° ì˜¤ë¥˜: meta ë˜ëŠ” data ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        
        # ì¢…ëª© ì½”ë“œ ì¶”ì¶œ
        code = data['meta'].get('code', file.name)
        
        # ì°¨íŠ¸ ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        chart_data = data['data']
        if not chart_data:
            return {
                'code': code,
                'error': 'ì°¨íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        
        df = pd.DataFrame(chart_data)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return {
                'code': code,
                'error': f'í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}',
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        
        # date ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        try:
            df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d%H%M')
        except Exception as date_error:
            try:
                df['date'] = pd.to_datetime(df['date'])
            except Exception:
                return {
                    'code': code,
                    'error': f'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì˜¤ë¥˜: {str(date_error)}',
                    'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }
        
        df = df[required_columns]
        
        # ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜
        daily_df = convert_to_daily(df)
        
        if daily_df.empty:
            return {
                'code': code,
                'condition_1': {'valid_dates': []},
                'condition_2': {'valid_dates': []},
                'condition_3': {'valid_dates': []},
                'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        
        # ì¢…ëª© ì½”ë“œ ì¶”ê°€
        daily_df['code'] = code
        
        result = {
            'code': code,
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # ê° ì¡°ê±´ë³„ë¡œ ê²€ìƒ‰ ë° ë°±í…ŒìŠ¤íŒ… ìˆ˜í–‰
        for condition_set in [1, 2, 3]:
            condition_key = f'condition_{condition_set}'
            
            # ì¡°ê±´ ê²€ìƒ‰ ì‹¤í–‰
            valid_dates = check_conditions(daily_df, condition_set)
            
            condition_result = {'valid_dates': valid_dates if valid_dates else []}
            
            # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ (ì¡°ê±´ ë§Œì¡± ë‚ ì§œê°€ ìˆì„ ë•Œë§Œ)
            if valid_dates:
                backtest_df = backtest_strategy(daily_df, df, valid_dates)
                
                if not backtest_df.empty:
                    backtest_df['ì¢…ëª©ë²ˆí˜¸'] = code
                    
                    # ê° ì¡°ê±´ë³„ë¡œ ê°œë³„ íŒŒì¼ ì €ì¥ (ìƒˆë¡œìš´ í´ë”ëª… ì‚¬ìš©)
                    backtest_file = save_backtest_results_integrated(
                        backtest_df, selected_folder, code, condition_set, result_folder_name
                    )
                    
                    condition_result['backtest_result'] = {
                        'total_trades': len(backtest_df),
                        'win_rate': len(backtest_df[backtest_df['ìˆ˜ìµë¥ '] > 0]) / len(backtest_df) * 100 if len(backtest_df) > 0 else 0,
                        'avg_return': backtest_df['ìˆ˜ìµë¥ '].mean() if len(backtest_df) > 0 else 0,
                        'file_saved': backtest_file.name if backtest_file else None
                    }
            
            result[condition_key] = condition_result
        
        return result
        
    except Exception as e:
        return {
            'code': file.name,
            'error': f'íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}',
            'processed_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

def process_chunk_all_conditions(chunk_files, selected_folder, result_folder_name):
    """
    ëª¨ë“  ì¡°ê±´ìœ¼ë¡œ íŒŒì¼ ì²­í¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ (3ë²ˆ ë©”ë‰´ìš©)
    """
    chunk_results = []
    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_file = {
            executor.submit(process_single_file_all_conditions, file, selected_folder, result_folder_name): file 
            for file in chunk_files
        }
        
        for future in future_to_file:
            result = future.result()
            if result:
                chunk_results.append(result)
    
    return chunk_results

def save_backtest_results_integrated(results_df, folder_path, stock_code, condition_set, result_folder_name):
    """
    í†µí•© ë°±í…ŒìŠ¤íŒ…ìš© ê²°ê³¼ ì €ì¥ í•¨ìˆ˜ (3ë²ˆ ë©”ë‰´ìš©)
    """
    if results_df.empty:
        return None
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ê²°ê³¼ë¥¼ ì €ì¥í•  ìƒˆë¡œìš´ í´ë” ìƒì„± (ì„ íƒëœ í´ë”ëª… + íƒ€ì„ìŠ¤íƒ¬í”„ + ë°±í…ŒìŠ¤íŒ…_ê²°ê³¼)
    backtest_dir = folder_path / result_folder_name
    backtest_dir.mkdir(exist_ok=True)
    
    # ì¡°ê±´ ì„¸íŠ¸ ì´ë¦„ ë§¤í•‘
    condition_names = {
        1: "ê¸°ì¡´ì¡°ê±´",
        2: "ì¶”ê°€1ì¡°ê±´", 
        3: "ì¶”ê°€2ì¡°ê±´"
    }
    condition_name = condition_names.get(condition_set, "ì•Œìˆ˜ì—†ìŒ")
    
    excel_file = backtest_dir / f"backtest_{stock_code}_{condition_name}_{timestamp}.xlsx"
    
    # í†µê³„ ì •ë³´ ì¶”ê°€
    total_trades = len(results_df)
    win_trades = len(results_df[results_df['ìˆ˜ìµë¥ '] > 0])
    win_rate = (win_trades / total_trades * 100) if total_trades > 0 else 0
    avg_return = results_df['ìˆ˜ìµë¥ '].mean() if total_trades > 0 else 0
    
    stats_df = pd.DataFrame({
        'í•­ëª©': ['ì´ ê±°ë˜ìˆ˜', 'ìˆ˜ìµ ê±°ë˜', 'ì†ì‹¤ ê±°ë˜', 'ìŠ¹ë¥ (%)', 'í‰ê·  ìˆ˜ìµë¥ (%)', 'ì¡°ê±´ì„¸íŠ¸'],
        'ê°’': [total_trades, win_trades, total_trades - win_trades, round(win_rate, 2), round(avg_return, 2), condition_name]
    })
    
    # ì—‘ì…€ íŒŒì¼ì— ë‘ ê°œ ì‹œíŠ¸ë¡œ ì €ì¥
    with pd.ExcelWriter(excel_file) as writer:
        results_df.to_excel(writer, sheet_name='ê±°ë˜ë‚´ì—­', index=False)
        stats_df.to_excel(writer, sheet_name='í†µê³„', index=False)
    
    return excel_file

def combine_integrated_results(all_results, folder_path, result_folder_name):
    """
    ëª¨ë“  ì¡°ê±´ì˜ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ì—‘ì…€ íŒŒì¼ë¡œ í†µí•©í•˜ëŠ” í•¨ìˆ˜ (3ë²ˆ ë©”ë‰´ìš©)
    """
    backtest_dir = folder_path / result_folder_name
    if not backtest_dir.exists():
        print(f"{result_folder_name} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None
    
    # ì¡°ê±´ë³„ë¡œ ì—‘ì…€ íŒŒì¼ë“¤ ì°¾ê¸°
    condition_names = {
        1: "ê¸°ì¡´ì¡°ê±´",
        2: "ì¶”ê°€1ì¡°ê±´", 
        3: "ì¶”ê°€2ì¡°ê±´"
    }
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    final_file = backtest_dir / f"TOTAL_í†µí•©ë°±í…ŒìŠ¤íŒ…ê²°ê³¼_{timestamp}.xlsx"
    
    all_condition_data = {}
    
    for condition_set in [1, 2, 3]:
        condition_name = condition_names[condition_set]
        
        # í•´ë‹¹ ì¡°ê±´ì˜ ì—‘ì…€ íŒŒì¼ë“¤ ì°¾ê¸°
        excel_files = list(backtest_dir.glob(f'backtest_*{condition_name}*.xlsx'))
        
        combined_trades = []
        total_stats = {
            'total_trades': 0,
            'win_trades': 0,
            'total_return': 0,
            'stock_count': 0
        }
        
        for excel_file in excel_files:
            try:
                # ê±°ë˜ë‚´ì—­ ì½ê¸°
                trades_df = pd.read_excel(excel_file, sheet_name='ê±°ë˜ë‚´ì—­')
                if not trades_df.empty:
                    combined_trades.append(trades_df)
                    
                    # í†µê³„ ì§‘ê³„
                    total_stats['total_trades'] += len(trades_df)
                    total_stats['win_trades'] += len(trades_df[trades_df['ìˆ˜ìµë¥ '] > 0])
                    total_stats['total_return'] += trades_df['ìˆ˜ìµë¥ '].sum()
                    total_stats['stock_count'] += 1
                    
            except Exception as e:
                print(f"íŒŒì¼ {excel_file.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        if combined_trades:
            # ëª¨ë“  ê±°ë˜ë‚´ì—­ í•©ì¹˜ê¸°
            condition_trades = pd.concat(combined_trades, ignore_index=True)
            condition_trades = condition_trades.sort_values(['ì¢…ëª©ë²ˆí˜¸', 'ë§¤ìˆ˜ì¼'])
            
            # ì¡°ê±´ë³„ ì „ì²´ í†µê³„ ê³„ì‚°
            win_rate = (total_stats['win_trades'] / total_stats['total_trades'] * 100) if total_stats['total_trades'] > 0 else 0
            avg_return = total_stats['total_return'] / total_stats['total_trades'] if total_stats['total_trades'] > 0 else 0
            
            condition_summary = pd.DataFrame({
                'í•­ëª©': ['ì¢…ëª© ìˆ˜', 'ì´ ê±°ë˜ìˆ˜', 'ìˆ˜ìµ ê±°ë˜', 'ì†ì‹¤ ê±°ë˜', 'ìŠ¹ë¥ (%)', 'í‰ê·  ìˆ˜ìµë¥ (%)'],
                'ê°’': [
                    total_stats['stock_count'],
                    total_stats['total_trades'], 
                    total_stats['win_trades'],
                    total_stats['total_trades'] - total_stats['win_trades'],
                    round(win_rate, 2),
                    round(avg_return, 2)
                ]
            })
            
            all_condition_data[condition_name] = {
                'trades': condition_trades,
                'summary': condition_summary
            }
    
    # ìµœì¢… ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
    if all_condition_data:
        with pd.ExcelWriter(final_file) as writer:
            # ê° ì¡°ê±´ë³„ ì‹œíŠ¸ ìƒì„±
            for condition_name, data in all_condition_data.items():
                data['trades'].to_excel(writer, sheet_name=f'{condition_name}_ê±°ë˜ë‚´ì—­', index=False)
                data['summary'].to_excel(writer, sheet_name=f'{condition_name}_ìš”ì•½', index=False)
            
            # ì „ì²´ ìš”ì•½ ì‹œíŠ¸
            overall_summary = []
            for condition_name, data in all_condition_data.items():
                summary_data = data['summary']
                row_data = {'ì¡°ê±´': condition_name}
                for _, row in summary_data.iterrows():
                    row_data[row['í•­ëª©']] = row['ê°’']
                overall_summary.append(row_data)
            
            if overall_summary:
                overall_df = pd.DataFrame(overall_summary)
                overall_df.to_excel(writer, sheet_name='ì „ì²´ìš”ì•½', index=False)
        
        print(f"ìµœì¢… í†µí•© ê²°ê³¼ê°€ {final_file.name}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return final_file
    else:
        print("í†µí•©í•  ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

def cleanup_temp_files(folder_path, result_folder_name):
    """
    ì„ì‹œ íŒŒì¼ë“¤ì„ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜ (3ë²ˆ ë©”ë‰´ìš©)
    """
    backtest_dir = folder_path / result_folder_name
    if not backtest_dir.exists():
        return
    
    # TOTALë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ” íŒŒì¼ë“¤ ì‚­ì œ
    temp_files = [f for f in backtest_dir.glob('*.xlsx') if not f.name.startswith('TOTAL_')]
    
    deleted_count = 0
    for temp_file in temp_files:
        try:
            temp_file.unlink()
            deleted_count += 1
        except Exception as e:
            print(f"íŒŒì¼ {temp_file.name} ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    print(f"ì„ì‹œ íŒŒì¼ {deleted_count}ê°œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()

